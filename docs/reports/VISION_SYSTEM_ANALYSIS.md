# AI 비전(카메라) 분석 및 평가 시스템 분석 보고서

**작성일자:** 2026년 2월 24일  
**대상 주요 파일:** 
- `frontend/src/composables/useVisionAnalysis.js` (상태 관리 및 분석 로직)
- `frontend/public/workers/visionWorker.js` (비동기 추론 워커)
- `frontend/src/features/interview/components/VisionAnalysisReport.vue` (결과 UI)
---

## 0. 사용 기술 스택 (Tech Stack)

비전 분석 시스템은 브라우저 환경에서 고성능의 AI 추론을 실시간으로 수행하기 위해 다음과 같은 현대적인 웹 기술을 혼합하여 구축되었습니다.

- **Google MediaPipe Tasks Vision:** 클라이언트 사이드(브라우저)에서 기계학습 모델을 돌리기 위한 핵심 프레임워크입니다.
  - 별도의 백엔드 서버 비용이나 통신 지연시간(Latency) 없이, 사용자 기기의 자원을 활용하여 얼굴(FaceLandmarker) 및 자세(PoseLandmarker)의 핵심 특징점(Landmarks)과 안면 구조(Blendshapes)를 실시간 추출합니다.
- **Web Workers API:** 자바스크립트는 기본적으로 메인(UI) 스레드에서 싱글 스레드로 동작하므로, 무거운 행렬 연산 시 브라우저가 버벅이거나 멈출 수 있습니다. 이를 방지하고자 MediaPipe 추론 과정을 전용 백그라운드 워커 스레드로 완전히 분리하여 부드러운 화면 갱신을 보장합니다.
- **WebGL 2.0 / WASM (WebAssembly):** MediaPipe가 브라우저 내에서 가속 처리되기 위해 GPU 연산을 보조하는 필수적인 기술로, 사용자의 하드웨어 그래픽 가속을 적극 활용합니다.
- **Vue 3 (Composition API):** 자체 제작한 `useVisionAnalysis` 추상화 컴포저블을 통해, 다루기 까다로운 비동기 비전 워커의 상태(로딩 완료, 현재 분석 중 여부, 집계된 통계 결과, 에러 메시지)를 반응형(Reactivity) 데이터로 손쉽게 UI와 연결합니다.

---
## 1. 시스템 개요 및 아키텍처

현재 구현된 카메라 기반 AI 비전 분석 시스템은 사용자의 면접 태도(시선, 표정, 자세)를 실시간으로 분석하여 점수화하고 피드백을 제공하는 기능을 수행합니다. 

메인 브라우저(UI 스레드)의 끊김 현상을 방지하고 부드러운 화면을 유지하기 위해, 모든 무거운 모델 추론 연산은 **Web Worker (`visionWorker.js`)**로 분리되어 비동기로 처리됩니다.
CDN 차단 환경을 우회하기 위해 **MediaPipe 태스크 라이브러리(로컬 파일)**를 로드하여 FaceLandmarker 및 PoseLandmarker 모델을 가동합니다.

### 1-1. 최적화된 샘플링 
- 초당 무수히 많은 카메라 프레임을 전부 검사하지 않고, 자체 타이머를 통해 **500ms마다 한 번(2 FPS)** 영상을 캡처하여 워커에 전송합니다.
- 홀수 번째와 짝수 번째 프레임을 각각 `FACE`(얼굴/표정) 분석과 `POSE`(자세) 분석 태스크로 번갈아 할당하여 연산 부하를 절반으로 줄인 최적화가 적용되어 있습니다.

---

## 2. 주요 분석 로직 (휴리스틱)

### 2-1. 시선 및 고개 유지 분석 (Head Orientation)
얼굴 인식 결과(Landmarks) 도출 시, 양쪽 눈과 코의 위치(X, Y 좌표)를 기반으로 고개의 각도를 판별합니다.
- **좌우 회전 (Yaw Offset):** 코가 두 눈 사이의 중앙에서 얼마나 벗어났는지 계산하여 `0.15` 미만일 때만 정면 응시로 판별합니다.
- **상하 숙임 (Pitch Offset):** 양 눈의 Y축 평균 선 기준 코가 얼마나 아래에 위치하는지 계산하여, `0.4` ~ `0.95` 범위 안에 들어와야 정상적인 정면을 바라보는 것으로 간주합니다. 고개를 너무 푹 숙이거나 치켜들면 조건을 벗어납니다.
- **예외 처리 (이탈 페널티):** 화면에서 이탈하여 얼굴이 아예 보이지 않는 경우, 분석 모수(분모)는 증가하지만 정면 응시 횟수(분자)는 누적되지 않아 점수가 깎이는 방식이 적용되어 정확도가 높습니다.

### 2-2. 표정 분석 (Emotion Mapping)
MediaPipe의 `Face Blendshapes`(안면 근육 추적) 기능을 활용하여, 찡그림과 미소를 수치로 변환합니다.
- **긍정 (Smile):** 입꼬리 근육 수치(`mouthSmileLeft`와 `mouthSmileRight`의 평균)를 분석. 면접 특성상 활짝 웃기 힘든 환경을 고려해 **0.15 이상**의 옅은 미소도 긍정 요소로 감지하도록 임계값을 대폭 완화하는 방향으로 설계되었습니다.
- **긴장 (Tension):** 입술을 꽉 다무는 행동(`mouthPress` > `0.2`)을 강하게 감지하면 굳어있거나 긴장한 상태로 분류하여 카운트합니다.
- **중립 (Neutral):** 위 두 가지에 해당하지 않으면 중립(무표정)으로 집계됩니다.

### 2-3. 자세 유지 분석 (Posture Stabilization)
머리를 제외한 상체 관절(Landmarks) 추첨 시 양쪽 어깨 라인과 코를 활용해 복합적인 자세 안정성을 측정합니다.
- **어깨 수평 (Y축 분석):** 양쪽 어깨의 상하 높이 차이가 `0.10` 미만이어야 수평으로 인정합니다. 웹캠의 미세한 왜곡을 감안해 유연한 범위를 갖고 있습니다.
- **어깨 틀어짐 (Z축 분석):** 양 어깨의 깊이(카메라와의 거리) 차이가 `0.15` 미만이어야 하명, 한쪽으로 비스듬하게 몸을 돌려 앉은 자세를 걸러냅니다.
- **거북목 및 앞뒤 쏠림 분석:** 양쪽 어깨 중앙을 기준으로 코의 상대적 깊이를 계산, 코가 카메라 방향으로 지나치게 돌출(`> -0.05`)되거나 지나치게 뒤로 빠질(`<-0.4`) 경우를 불량 자세로 잡아냅니다.

---

## 3. 실시간 피드백 및 최종 평가 산출

### 3-1. 실시간 토스트 경고 (Cooldown System)
사용자가 면접 중 좋지 않은 행동이 반복되면 실시간 경고 메시지를 보냅니다.
- 시선 분산이나 삐딱한 자세가 누적될 때 토스트 UI를 발동합니다.
- 너무 빈번한 알람으로 면접자가 당황하는 것을 방지하기 위해, 동일한 종류의 알람은 **최소 10초(10000ms)의 쿨다운** 타이머를 거치도록 설계되었습니다.

### 3-2. 최종 평가 점수화 로직
면접 종료 후 총 누적된 통계 데이터를 백분율(100%) 기준으로 정교하게 변환합니다.
- 전체 샘플 수 대비 정면 응시/바른 자세 유지 카운트 비율 수식을 통해 최종 **자세 안정성 스코어**와 **시선 집중도 스코어**가 계산됩니다.
- 합산 100%가 초과되는 오류 방지를 위해, 분모가 없는 초기 상태이거나 올림/내림 오차가 발생하더라도 `Math.min` 및 `Math.max`를 활용해 비율이 무조건 100 이내로 맞춰지도록 방어 로직이 적용되어 안정적입니다.
- 결과물 객체는 UI 페이지로 리턴되며, `VisionAnalysisReport.vue` 컴포넌트 내 다양한 애니메이션 바 차트와 도넛 차트로 아름답게 시각화됩니다.
