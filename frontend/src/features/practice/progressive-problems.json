{
  "progressiveProblems": [
    {
      "id": "P5",
      "project_title": "ì •í™”ê°€ ì‹œê¸‰í•œ ì˜¤ì—¼ëœ ë°ì´í„° ì„¹í„°",
      "scenario": "ë§ˆë” ì„œë²„ì˜ íŠ¹ì • ì„¹í„°ì—ì„œ ì •í™•ë„ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ê²Œ ë³´ê³ ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì „í˜•ì ì¸ 'ë°ì´í„° ì˜¤ì—¼(Hallucination)' ì¦ìƒì…ë‹ˆë‹¤. {username}ë‹˜, íŒŒíŠ¸ë„ˆ Coduckê³¼ í•¨ê»˜ ì˜¤ì—¼ëœ íŒŒì´í”„ë¼ì¸ì˜ ë²„ê·¸ë¥¼ ìˆœì„œëŒ€ë¡œ ì°¾ì•„ ì •í™”í•´ì•¼ í•©ë‹ˆë‹¤.",
      "difficulty": 1,
      "totalSteps": 3,
      "steps": [
        {
          "step": 1,
          "title": "ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì€ ê²€ì¦ ì„±ëŠ¥ (Data Leakage)",
          "bug_type": "A",
          "bug_type_name": "Data Leakage",
          "questions": {
            "text": "ì „ì²˜ë¦¬ ì½”ë“œì—ì„œ ì´ìƒí•œ ë¶€ë¶„ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤:\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, ...)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X)  \nX_test = scaler.transform(X_test)\n\nTrain 0.98 vs Test 0.65ë¡œ ì°¨ì´ê°€ í½ë‹ˆë‹¤. ë¬´ì—‡ì´ ë¬¸ì œì¼ê¹Œìš”?",
            "options": [
              "scalerë¥¼ ì „ì²´ ë°ì´í„° Xë¡œ fití•´ì„œ",
              "train_test_splitì˜ test_sizeê°€ ë„ˆë¬´ ì‘ì•„ì„œ",
              "StandardScaler ëŒ€ì‹  MinMaxScalerë¥¼ ì¨ì•¼ í•´ì„œ",
              "random_stateë¥¼ ê³ ì •í•˜ì§€ ì•Šì•„ì„œ"
            ],
            "answer": 0
          },
          "buggy_code": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\ndef prepare_data(df):\n    X = df.drop('churn', axis=1)\n    y = df['churn']\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n    )\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X)\n    X_test = scaler.transform(X_test)\n    \n    return X_train, X_test, y_train, y_test",
          "correct_code": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\ndef prepare_data(df):\n    X = df.drop('churn', axis=1)\n    y = df['churn']\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    \n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    \n    return X_train, X_test, y_train, y_test",
          "hint": "scalerê°€ ì „ì²´ ë°ì´í„° Xë¡œ fití•˜ë©´, X_testì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ì •ë³´ë„ í•¨ê»˜ í•™ìŠµë©ë‹ˆë‹¤. ì´ê²Œ ì™œ ë¬¸ì œì¼ê¹Œìš”?",
          "solution_check": {
            "type": "multi_condition",
            "required_any": [
              "fit_transform(X_train)",
              "fit(X_train)"
            ],
            "forbidden": [
              "fit_transform(X)",
              "fit(X)"
            ]
          },
          "coaching": "ğŸ¯ í˜„ì—…: Data LeakageëŠ” ëª¨ë¸ì´ 'ë„ˆë¬´ ì˜ ë‚˜ì˜¬ ë•Œ' ì˜ì‹¬í•´ì•¼ í•˜ëŠ” 1ìˆœìœ„ ë²„ê·¸ì…ë‹ˆë‹¤. ì „ì²˜ë¦¬ëŠ” ë°˜ë“œì‹œ train/test ë¶„í•  í›„ì— trainìœ¼ë¡œë§Œ fití•˜ê³ , testëŠ” transformë§Œ í•´ì•¼ í•©ë‹ˆë‹¤."
        },
        {
          "step": 2,
          "title": "ë¶ˆì•ˆì •í•œ í‰ê°€ ê²°ê³¼ (Imbalanced Sampling)",
          "bug_type": "B",
          "bug_type_name": "Sampling Bug",
          "questions": {
            "text": "Step 1ì„ ê³ ì³¤ë”ë‹ˆ test ì •í™•ë„ê°€ 0.85ë¡œ ë‚´ë ¤ê°”ìŠµë‹ˆë‹¤.\n\nê·¸ëŸ°ë° í˜„ì¬ splitì˜ test setì„ í™•ì¸í•´ë³´ë‹ˆ ì´íƒˆë¥ ì´ 3% ì •ë„ì…ë‹ˆë‹¤. ì›ë˜ ì „ì²´ ë°ì´í„°ì˜ ì´íƒˆë¥ ì€ 5%ì¸ë°, test setì˜ ë¹„ìœ¨ì´ ë‹¬ë¼ì¡ŒìŠµë‹ˆë‹¤.\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\në¬´ì—‡ì„ ì˜ì‹¬í•´ì•¼ í• ê¹Œìš”?",
            "options": [
              "random_state ê°’ì´ ì˜ëª»ë¨",
              "test_sizeë¥¼ 0.3 ì´ìƒìœ¼ë¡œ",
              "train/testì˜ í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ë‹¬ë¼ì„œ",
              "shuffle=Falseë¡œ ë³€ê²½"
            ],
            "answer": 2
          },
          "buggy_code": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\ndef prepare_data(df):\n    X = df.drop('churn', axis=1)\n    y = df['churn']\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    \n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    \n    return X_train, X_test, y_train, y_test",
          "correct_code": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\ndef prepare_data(df):\n    X = df.drop('churn', axis=1)\n    y = df['churn']\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42, stratify=y\n    )\n    \n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    \n    return X_train, X_test, y_train, y_test",
          "hint": "ë¶ˆê· í˜• ë°ì´í„°ì—ì„  split í›„ train/testì˜ í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ê°•ì œë¡œ ìœ ì§€í•˜ëŠ” ì˜µì…˜ì´ ìˆìŠµë‹ˆë‹¤.",
          "solution_check": {
            "type": "regex",
            "value": "stratify\\s*=\\s*y\\s*(?=,\\s*\\w|\\))",
            "flags": ""
          },
          "coaching": "ğŸ¯ í˜„ì—…: ë¶ˆê· í˜• ë°ì´í„°(ì´íƒˆ ì˜ˆì¸¡, ì‚¬ê¸° íƒì§€ ë“±)ì—ì„œ stratify ì—†ì´ splití•˜ë©´ train/testì˜ í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ë‹¬ë¼ì ¸ í‰ê°€ê°€ ë¶ˆì•ˆì •í•´ì§‘ë‹ˆë‹¤. íŠ¹íˆ testì— positive ìƒ˜í”Œì´ ì ìœ¼ë©´ í‰ê°€ ìì²´ê°€ ë¬´ì˜ë¯¸í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        },
        {
          "step": 3,
          "title": "ì˜ëª»ëœ í‰ê°€ ë°ì´í„° ì‚¬ìš© (Train Data Evaluation)",
          "bug_type": "C",
          "bug_type_name": "Evaluation Error",
          "questions": {
            "text": "Step 1, 2ë¥¼ ê³ ì³¤ìŠµë‹ˆë‹¤. ì´ì œ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í–ˆìŠµë‹ˆë‹¤:\n\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_train) \naccuracy = accuracy_score(y_train, y_pred)\nprint(f'ì •í™•ë„: {accuracy}')  # 0.95\n\nê·¸ëŸ°ë° testë¡œ í™•ì¸í•˜ë‹ˆ 0.60ì´ ë‚˜ì˜µë‹ˆë‹¤. ë¬´ì—‡ì´ ë¬¸ì œì¼ê¹Œìš”?",
            "options": [
              "accuracy_score ëŒ€ì‹  f1_scoreë¥¼ ì¨ì•¼ í•¨",
              "train ë°ì´í„°ë¡œ í‰ê°€í•´ì„œ ì„±ëŠ¥ì´ ê³¼ëŒ€í‰ê°€ë¨",
              "predict ëŒ€ì‹  predict_probaë¥¼ ì¨ì•¼ í•¨",
              "y_trainê³¼ y_pred ìˆœì„œê°€ ë°”ë€œ"
            ],
            "answer": 1
          },
          "buggy_code": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\ndef train_and_evaluate(df):\n    X = df.drop('churn', axis=1)\n    y = df['churn']\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42, stratify=y\n    )\n    \n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    \n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    \n    y_pred = model.predict(X_train)\n    accuracy = accuracy_score(y_train, y_pred)\n    \n    return accuracy",
          "correct_code": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\ndef train_and_evaluate(df):\n    X = df.drop('churn', axis=1)\n    y = df['churn']\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42, stratify=y\n    )\n    \n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    \n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    \n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    \n    return accuracy",
          "hint": "í•™ìŠµì— ì‚¬ìš©í•œ ë°ì´í„°ë¡œ í‰ê°€í•˜ë©´ ëª¨ë¸ ì„±ëŠ¥ì´ ê³¼ëŒ€í‰ê°€ë©ë‹ˆë‹¤. ëª¨ë¸ì´ í•™ìŠµ ì¤‘ ë³´ì§€ ëª»í•œ ë°ì´í„°ë¡œ í‰ê°€í•´ì•¼ í•©ë‹ˆë‹¤.",
          "solution_check": {
            "type": "multi_condition",
            "required_all": [
              "predict(X_test)",
              "accuracy_score(y_test"
            ],
            "forbidden": [
              "predict(X_train)",
              "accuracy_score(y_train, y_pred)"
            ]
          },
          "coaching": "ğŸ¯ í˜„ì—…: train ë°ì´í„°ë¡œ í‰ê°€í•˜ë©´ ëª¨ë¸ì´ 'ì´ë¯¸ ë³¸' ë°ì´í„°ì— ëŒ€í•œ ì„±ëŠ¥ë§Œ ì¸¡ì •ë˜ì–´ ê³¼ëŒ€í‰ê°€ë©ë‹ˆë‹¤. ë°˜ë“œì‹œ í•™ìŠµì— ì‚¬ìš©í•˜ì§€ ì•Šì€ test ë°ì´í„°ë¡œ í‰ê°€í•´ì•¼ ì‹¤ì œ ì„±ëŠ¥ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì´ train/test splitì„ í•˜ëŠ” ì´ìœ ì…ë‹ˆë‹¤."
        }
      ]
    },
    {
      "id": "P2",
      "project_title": "ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ê¸°ë³¸ ë°©ì–´",
      "scenario": "ì‚¬ìš©ì í–‰ë™ ë¡œê·¸ë¡œ ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì´ ì¢…ì¢… ì˜ˆì™¸ë¡œ í„°ì§€ê±°ë‚˜, í•™ìŠµì´ 'ë˜ëŠ” ê²ƒì²˜ëŸ¼' ë³´ì´ì§€ë§Œ ê²°ê³¼ê°€ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤.",
      "difficulty": 2,
      "totalSteps": 3,
      "steps": [
        {
          "step": 1,
          "title": "ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ëˆ„ë½ (NaN Handling)",
          "bug_type": "A",
          "bug_type_name": "Null Handling",
          "questions": {
            "text": "ëª¨ë¸ í•™ìŠµ ì§ì „ì— 'Input contains NaN' ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì›ì¸ì€?",
            "options": [
              "í•™ìŠµ ë°ì´í„°ê°€ ë„ˆë¬´ ì»¤ì„œ",
              "ì „ì²˜ë¦¬ ê³¼ì •ì—ì„œ ê²°ì¸¡ì¹˜(NaN)ê°€ ë‚¨ì•„ ìˆì–´ì„œ",
              "ëª¨ë¸ì´ ë„ˆë¬´ ë‹¨ìˆœí•´ì„œ",
              "ì •ê·œí™”ë¥¼ í•´ì„œ"
            ],
            "answer": 1
          },
          "buggy_code": "import pandas as pd\n\ndef preprocess(df):\n    df = df.copy()\n    df['age'] = df['age'].astype(int)\n    return df",
          "correct_code": "import pandas as pd\n\ndef preprocess(df):\n    df = df.copy()\n    df['age'] = df['age'].fillna(0).astype(int)\n    return df",
          "hint": "NaNì´ ìˆìœ¼ë©´ astype()ì´ ì‹¤íŒ¨í•©ë‹ˆë‹¤. ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•˜ì„¸ìš”.",
          "solution_check": {
            "type": "regex",
            "value": "(fillna\\(\\s*(0)?\\s*\\)|dropna\\(\\s*\\))",
            "flags": ""
          },
          "coaching": "ğŸ¯ í˜„ì—…: ì‹¤ë¬´ ë°ì´í„°ëŠ” í•­ìƒ ê²°ì¸¡ì¹˜ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. fillna(0), fillna(í‰ê· ), fillna(ì¤‘ì•™ê°’) ì¤‘ ë„ë©”ì¸ì— ë§ëŠ” ì „ëµì„ ì„ íƒí•˜ì„¸ìš”."
        },
        {
          "step": 2,
          "title": "0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì–´ (Zero Division Guard)",
          "bug_type": "B",
          "bug_type_name": "Null Guard",
          "questions": {
            "text": "ì‚¬ìš©ìë³„ í‰ê·  êµ¬ë§¤ì•¡ ê³„ì‚° ì‹œ 'division by zero' ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ìƒí™©ì¼ê¹Œìš”?",
            "options": [
              "êµ¬ë§¤ì•¡ì´ ë„ˆë¬´ ì»¤ì„œ",
              "íŠ¹ì • ì‚¬ìš©ìì˜ êµ¬ë§¤ íšŸìˆ˜(count)ê°€ 0ì´ì–´ì„œ",
              "CSV ì¸ì½”ë”©ì´ ê¹¨ì ¸ì„œ",
              "ë°ì´í„°ê°€ ë„ˆë¬´ ì ì–´ì„œ"
            ],
            "answer": 1
          },
          "buggy_code": "def avg_spend(total_spend, count):\n    return total_spend / count",
          "correct_code": "def avg_spend(total_spend, count):\n    if count == 0:\n        return 0\n    return total_spend / count",
          "hint": "countê°€ 0ì¼ ë•Œë¥¼ ë°©ì–´í•´ì•¼ í•©ë‹ˆë‹¤.",
          "solution_check": {
            "type": "multi_condition",
            "required_all": [
              "if count == 0"
            ],
            "forbidden": []
          },
          "coaching": "ğŸ¯ í˜„ì—…: ì‹ ê·œ ê°€ì…ìë‚˜ ë¹„í™œì„± ì‚¬ìš©ìëŠ” countê°€ 0ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°©ì–´ ì½”ë“œëŠ” ì„ íƒì´ ì•„ë‹ˆë¼ í•„ìˆ˜ì…ë‹ˆë‹¤."
        },
        {
          "step": 3,
          "title": "ì›ë³¸ ë°ì´í„° ë³´ì¡´ (State Leak)",
          "bug_type": "C",
          "bug_type_name": "State Leak",
          "questions": {
            "text": "ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•œ ë’¤ ì›ë³¸ ë°ì´í„°í”„ë ˆì„ê¹Œì§€ í•¨ê»˜ ë°”ë€Œì—ˆìŠµë‹ˆë‹¤. ì™œì¼ê¹Œìš”?",
            "options": [
              "ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•´ì„œ",
              "ë°ì´í„°í”„ë ˆì„ì´ ì°¸ì¡°ë¡œ ì „ë‹¬ë˜ì–´ ì›ë³¸ì´ ìˆ˜ì •ë˜ì—ˆê¸° ë•Œë¬¸ì—",
              "Pandas ë²„ê·¸ë¼ì„œ",
              "ì „ì—­ ë³€ìˆ˜ê°€ ìë™ ìƒì„±ë˜ì–´ì„œ"
            ],
            "answer": 1
          },
          "buggy_code": "def add_feature(df):\n    df['is_vip'] = df['spend'] > 100\n    return df",
          "correct_code": "def add_feature(df):\n    df = df.copy()\n    df['is_vip'] = df['spend'] > 100\n    return df",
          "hint": "DataFrameì€ ì°¸ì¡°ë¡œ ì „ë‹¬ë˜ë¯€ë¡œ ì›ë³¸ì´ ìˆ˜ì •ë©ë‹ˆë‹¤. ë³µì‚¬ë³¸ì„ ë§Œë“¤ì–´ ì‘ì—…í•˜ì„¸ìš”.",
          "solution_check": {
            "type": "multi_condition",
            "required_all": [
              ".copy()"
            ],
            "forbidden": [
              "inplace=True"
            ]
          },
          "coaching": "ğŸ¯ í˜„ì—…: State LeakëŠ” ì¬í˜„ ë¶ˆê°€ëŠ¥í•œ ë²„ê·¸ì˜ ì£¼ìš” ì›ì¸ì…ë‹ˆë‹¤. í•¨ìˆ˜ëŠ” ì…ë ¥ì„ ë³€ê²½í•˜ì§€ ì•Šê³  ìƒˆë¡œìš´ ê°ì²´ë¥¼ ë°˜í™˜í•˜ì„¸ìš”."
        }
      ]
    },
    {
      "id": "P3",
      "project_title": "í‰ê°€ íŒŒì´í”„ë¼ì¸ ì‹ ë¢°ì„± í™•ë³´",
      "scenario": "ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸ì„ ë°°í¬í•˜ê¸° ì „ ì„±ëŠ¥ ë¦¬í¬íŠ¸ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ë¦¬í¬íŠ¸ ìˆ˜ì¹˜ê°€ ê³¼ë„í•˜ê²Œ ì¢‹ê±°ë‚˜, ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ê²°ê³¼ê°€ ë‹¬ë¼ì§‘ë‹ˆë‹¤.",
      "difficulty": 3,
      "totalSteps": 3,
      "steps": [
        {
          "step": 1,
          "title": "ë¶ˆê· í˜• ë°ì´í„° ë¶„í•  ì˜¤ë¥˜ (Stratify ëˆ„ë½)",
          "bug_type": "A",
          "bug_type_name": "Sampling Bug",
          "questions": {
            "text": "ì´íƒˆë¥  5%ì¸ ë°ì´í„°ì—ì„œ ë§¤ë²ˆ í‰ê°€ ê²°ê³¼ê°€ í¬ê²Œ í”ë“¤ë¦½ë‹ˆë‹¤. ê°€ì¥ ë¨¼ì € ì˜ì‹¬í•´ì•¼ í•  ê²ƒì€?",
            "options": [
              "ëª¨ë¸ì´ ë„ˆë¬´ ë‹¨ìˆœí•´ì„œ",
              "train/test ë¶„í•  ì‹œ í´ë˜ìŠ¤ ë¹„ìœ¨ì´ ê¹¨ì¡Œì„ ê°€ëŠ¥ì„±",
              "ì „ì²˜ë¦¬ ì‹œê°„ì´ ë„ˆë¬´ ê¸¸ì–´ì„œ",
              "íŠ¹ì„±ì´ ë„ˆë¬´ ë§ì•„ì„œ"
            ],
            "answer": 1
          },
          "buggy_code": "from sklearn.model_selection import train_test_split\n\ndef split(df):\n    X = df.drop('churn', axis=1)\n    y = df['churn']\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, X_test, y_train, y_test",
          "correct_code": "from sklearn.model_selection import train_test_split\n\ndef split(df):\n    X = df.drop('churn', axis=1)\n    y = df['churn']\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42, stratify=y\n    )\n    return X_train, X_test, y_train, y_test",
          "hint": "ë°ì´í„°ê°€ ë¶ˆê· í˜•í•©ë‹ˆë‹¤. train_test_splitì˜ íŠ¹ì • íŒŒë¼ë¯¸í„°ë¥¼ í™œìš©í•´ y í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ì„¸ìš”.",
          "solution_check": {
            "type": "regex",
            "value": "stratify\\s*=\\s*y\\s*(?=,\\s*\\w|\\))",
            "flags": ""
          },
          "coaching": "ğŸ¯ í˜„ì—…: ë¶ˆê· í˜• ë°ì´í„°(ì‚¬ê¸° íƒì§€, ì´íƒˆ ì˜ˆì¸¡)ì—ì„œ stratify ì—†ì´ splití•˜ë©´ testì— positive ìƒ˜í”Œì´ ê±°ì˜ ì—†ì–´ í‰ê°€ê°€ ë¬´ì˜ë¯¸í•´ì§‘ë‹ˆë‹¤."
        },
        {
          "step": 2,
          "title": "ì¬í˜„ì„±(Seed) ëˆ„ë½",
          "bug_type": "B",
          "bug_type_name": "Non-determinism",
          "questions": {
            "text": "ê°™ì€ ì½”ë“œë¡œ í•™ìŠµí–ˆëŠ”ë° ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ì ìˆ˜ê°€ ë‹¤ë¦…ë‹ˆë‹¤. ê°€ì¥ ê·¸ëŸ´ë“¯í•œ ì›ì¸ì€?",
            "options": [
              "CPU ì„±ëŠ¥ì´ ë‹¬ë¼ì„œ",
              "ë‚œìˆ˜ ì‹œë“œê°€ ê³ ì •ë˜ì§€ ì•Šì•„ì„œ",
              "ë°ì´í„°ê°€ ë„ˆë¬´ ë§ì•„ì„œ",
              "ëª¨ë¸ì´ ë„ˆë¬´ ë‹¨ìˆœí•´ì„œ"
            ],
            "answer": 1
          },
          "buggy_code": "import numpy as np\nimport random\n\ndef train(model, X_train, y_train):\n    random.seed(42)\n    model.fit(X_train, y_train)\n    return model",
          "correct_code": "import numpy as np\nimport random\n\ndef train(model, X_train, y_train):\n    random.seed(42)\n    np.random.seed(42)\n    model.fit(X_train, y_train)\n    return model",
          "hint": "ê²°ê³¼ë¥¼ ì¬í˜„í•˜ë ¤ë©´ Numpyì˜ ë‚œìˆ˜ ì‹œë“œë¥¼ í•™ìŠµ ì „ì— ê³ ì •í•˜ì„¸ìš”.",
          "solution_check": {
            "type": "multi_condition",
            "required_all": [
              "np.random.seed(",
              "random.seed("
            ],
            "forbidden": []
          },
          "coaching": "ğŸ¯ í˜„ì—…: ì¬í˜„ ë¶ˆê°€ëŠ¥í•˜ë©´ A/B í…ŒìŠ¤íŠ¸, ë””ë²„ê¹…, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì´ ëª¨ë‘ ë¬´ì˜ë¯¸í•´ì§‘ë‹ˆë‹¤. ì‹œë“œ ê³ ì •ì€ í•„ìˆ˜ì…ë‹ˆë‹¤."
        },
        {
          "step": 3,
          "title": "ë¶ˆê· í˜• ë°ì´í„° ì§€í‘œ ì„ íƒ ì˜¤ë¥˜ (Accuracy í•¨ì •)",
          "bug_type": "C",
          "bug_type_name": "Metric Choice",
          "questions": {
            "text": "ì´íƒˆë¥  5%ì¸ ë°ì´í„°ì—ì„œ accuracy 95%ê°€ ë‚˜ì™”ì§€ë§Œ ì´íƒˆ ê³ ê°ì„ í•˜ë‚˜ë„ ëª» ì¡ìŠµë‹ˆë‹¤. ì´ìœ ëŠ”?",
            "options": [
              "accuracyê°€ ë¶ˆê· í˜• ë°ì´í„°ì—ì„œ ë‹¤ìˆ˜ í´ë˜ìŠ¤ì— í¸í–¥ë˜ì–´ ì˜¤í•´ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì–´ì„œ",
              "ëª¨ë¸ì´ ë„ˆë¬´ ë³µì¡í•´ì„œ",
              "ë°ì´í„°ê°€ ë„ˆë¬´ ì»¤ì„œ",
              "ì „ì²˜ë¦¬ë¥¼ í•´ì„œ"
            ],
            "answer": 0
          },
          "buggy_code": "from sklearn.metrics import accuracy_score\n\ndef evaluate(model, X_test, y_test):\n    y_pred = model.predict(X_test)\n    return accuracy_score(y_test, y_pred)",
          "correct_code": "from sklearn.metrics import f1_score\n\ndef evaluate(model, X_test, y_test):\n    y_pred = model.predict(X_test)\n    return f1_score(y_test, y_pred)",
          "hint": "ë¶ˆê· í˜• ë°ì´í„°ì—ì„œëŠ” accuracy ëŒ€ì‹  ì¬í˜„ìœ¨ê³¼ ì •ë°€ë„ë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ëŠ” ì§€í‘œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
          "solution_check": {
            "type": "multi_condition",
            "required_all": [],
            "required_any": [
              "f1_score"
            ],
            "forbidden": [
              "accuracy_score"
            ]
          },
          "coaching": "ğŸ¯ í˜„ì—…: ëª¨ë“  ê²ƒì„ 'ìœ ì§€'ë¡œ ì˜ˆì¸¡í•´ë„ 95% accuracyê°€ ë‚˜ì˜µë‹ˆë‹¤. F1-scoreëŠ” recallê³¼ precisionê³¼ ì¡°í™”í‰ê· ìœ¼ë¡œ ë¶ˆê· í˜• ë°ì´í„°ì— ì í•©í•©ë‹ˆë‹¤."
        }
      ]
    },
    {
      "id": "P4",
      "project_title": "ë°°í¬ ì „ ë§ˆì§€ë§‰ í•¨ì • ì œê±°",
      "scenario": "ëª¨ë¸ì€ ì¶©ë¶„íˆ í•™ìŠµë˜ì—ˆê³  í‰ê°€ë„ í†µê³¼í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë°°í¬ ì§ì „ ì ê²€ì—ì„œ ìš´ì˜ í™˜ê²½ì—ì„œë§Œ í„°ì§€ëŠ” ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
      "difficulty": 4,
      "totalSteps": 3,
      "steps": [
        {
          "step": 1,
          "title": "í•™ìŠµ/ì„œë¹™ í”¼ì²˜ ë¶ˆì¼ì¹˜ (Feature Mismatch)",
          "bug_type": "A",
          "bug_type_name": "Schema Drift",
          "questions": {
            "text": "ì˜¤í”„ë¼ì¸ì—ì„œëŠ” í†µê³¼í–ˆëŠ”ë° ìš´ì˜ì—ì„œ 'Feature names mismatch' ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì›ì¸ì€?",
            "options": [
              "ëª¨ë¸ì´ ë„ˆë¬´ ì»¤ì„œ",
              "í•™ìŠµ ì‹œ ì‚¬ìš©í•œ í”¼ì²˜ ì»¬ëŸ¼ê³¼ ì„œë¹™ ì…ë ¥ ì»¬ëŸ¼ì˜ ìˆœì„œë‚˜ ê°œìˆ˜ê°€ ë‹¬ë¼ì„œ",
              "ë°ì´í„°ê°€ ë„ˆë¬´ ì ì–´ì„œ",
              "ë‚œìˆ˜ ì‹œë“œë¥¼ ê³ ì •í•´ì„œ"
            ],
            "answer": 1
          },
          "buggy_code": "def serve(model, input_df):\n    return model.predict(input_df)",
          "correct_code": "def serve(model, input_df, feature_cols):\n    X = input_df[feature_cols]\n    return model.predict(X)",
          "hint": "í•™ìŠµ ì‹œ ì‚¬ìš©í•œ feature ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ì €ì¥í•´ë‘ê³ , ì„œë¹™ ì‹œ ê·¸ ì»¬ëŸ¼ë§Œ ì„ íƒí•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”.",
          "solution_check": {
            "type": "multi_condition",
            "required_all": [
              "input_df[feature_cols]"
            ],
            "forbidden": []
          },
          "coaching": "ğŸ¯ í˜„ì—…: Train-Serve SkewëŠ” ML ì‹œìŠ¤í…œ ì¥ì• ì˜ 70% ì´ìƒì„ ì°¨ì§€í•©ë‹ˆë‹¤. Feature ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ ë©”íƒ€ë°ì´í„°ë¡œ ì €ì¥í•˜ì„¸ìš”."
        },
        {
          "step": 2,
          "title": "ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ëˆ„ë½ (Unseen Category)",
          "bug_type": "B",
          "bug_type_name": "Unseen Category",
          "questions": {
            "text": "ìš´ì˜ ë°ì´í„°ì— í•™ìŠµ ë•Œ ì—†ë˜ ì‹ ê·œ êµ­ê°€ ì½”ë“œê°€ ë“¤ì–´ì˜¤ë©´ì„œ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ë¬¸ì œì¼ê¹Œìš”?",
            "options": [
              "ì†ë„ê°€ ë¹¨ë¼ì§„ë‹¤",
              "ì¸ì½”ë”ê°€ í•™ìŠµ ì‹œ ë³´ì§€ ëª»í•œ ì¹´í…Œê³ ë¦¬ë¥¼ ì²˜ë¦¬í•˜ì§€ ëª»í•´ ì—ëŸ¬ë¥¼ ë‚¸ë‹¤",
              "ë©”ëª¨ë¦¬ê°€ ì¤„ì–´ë“ ë‹¤",
              "ì •í™•ë„ê°€ ìë™ìœ¼ë¡œ ì˜¬ë¼ê°„ë‹¤"
            ],
            "answer": 1
          },
          "buggy_code": "from sklearn.preprocessing import OneHotEncoder\n\ndef fit_encoder(train_cat):\n    enc = OneHotEncoder()\n    enc.fit(train_cat)\n    return enc",
          "correct_code": "from sklearn.preprocessing import OneHotEncoder\n\ndef fit_encoder(train_cat):\n    enc = OneHotEncoder(handle_unknown='ignore')\n    enc.fit(train_cat)\n    return enc",
          "hint": "OneHotEncoderì— handle_unknown='_ _ _ _ _ _' ì˜µì…˜ì„ ì„¤ì •í•˜ì„¸ìš”.",
          "solution_check": {
            "type": "multi_condition",
            "required_all": [
              "handle_unknown='ignore'"
            ],
            "forbidden": []
          },
          "coaching": "ğŸ¯ í˜„ì—…: ìš´ì˜ ë°ì´í„°ëŠ” í•­ìƒ í•™ìŠµ ë°ì´í„°ë³´ë‹¤ ë‹¤ì–‘í•©ë‹ˆë‹¤. ìƒˆ ìƒí’ˆ, ì‹ ê·œ êµ­ê°€ ë“±ì´ ê³„ì† ì¶”ê°€ë˜ë¯€ë¡œ ë°©ì–´ ì½”ë“œê°€ í•„ìˆ˜ì…ë‹ˆë‹¤."
        },
        {
          "step": 3,
          "title": "ì „ì²˜ë¦¬ê¸°/ëª¨ë¸ ë²ˆë“¤ ì €ì¥ ëˆ„ë½",
          "bug_type": "C",
          "bug_type_name": "Artifact Drift",
          "questions": {
            "text": "ëª¨ë¸ì„ ì¬ë°°í¬í–ˆëŠ”ë° ì„±ëŠ¥ì´ ê°‘ìê¸° ë‚˜ë¹ ì¡ŒìŠµë‹ˆë‹¤. ëª¨ë¸ ì½”ë“œëŠ” ì•ˆ ë°”ê¿¨ëŠ”ë° ì™œì¼ê¹Œìš”?",
            "options": [
              "ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ë³€í•´ì„œ",
              "ì „ì²˜ë¦¬ê¸°ê°€ ì¬í•™ìŠµë˜ì–´ ì´ì „ê³¼ ë‹¤ë¥¸ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜í•˜ê¸° ë•Œë¬¸ì—",
              "CPUê°€ ëŠë ¤ì ¸ì„œ",
              "ë°ì´í„°ê°€ ì¤„ì–´ì„œ"
            ],
            "answer": 1
          },
          "buggy_code": "import joblib\n\ndef save_model(model, scaler, encoder, path):\n    joblib.dump(model, path)\n    return path",
          "correct_code": "import joblib\n\ndef save_model(model, scaler, encoder, path):\n    bundle = {\n        'model': model,\n        'scaler': scaler,\n        'encoder': encoder\n    }\n    joblib.dump(bundle, path)\n    return path",
          "hint": "ëª¨ë¸ë¿ ì•„ë‹ˆë¼ scaler, encoderë„ í•¨ê»˜ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤. ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ì–´ì„œ bundle í˜•íƒœë¡œ ë§Œë“  í›„ dumpí•˜ì„¸ìš”.",
          "solution_check": {
            "type": "multi_condition",
            "required_all": [
              "'model':",
              "'scaler':",
              "'encoder':"
            ],
            "forbidden": []
          },
          "coaching": "ğŸ¯ í˜„ì—…: ëª¨ë¸ë§Œ ì €ì¥í•˜ë©´ ì „ì²˜ë¦¬ ê¸°ì¤€ì´ ë‹¬ë¼ì ¸ì„œ ì„±ëŠ¥ì´ ë¬´ë„ˆì§‘ë‹ˆë‹¤. ëª¨ë¸+ì „ì²˜ë¦¬ê¸°ë¥¼ í•˜ë‚˜ì˜ ë²ˆë“¤ë¡œ ê´€ë¦¬í•˜ì„¸ìš”."
        }
      ]
    },
    {
      "id": "P1",
      "project_title": "AI ì—”ì§€ë‹ˆì–´ë§ í•µì‹¬ ë””ë²„ê¹…",
      "scenario": "AI ëª¨ë¸ ê°œë°œ íŒŒì´í”„ë¼ì¸ì—ì„œ ë°œìƒí•˜ëŠ” ì‹¤ì œ ì—ëŸ¬ë“¤ì„ í•´ê²°í•˜ë©° ì—”ì§€ë‹ˆì–´ë§ ì—­ëŸ‰ì„ í‚¤ì›ë‹ˆë‹¤.",
      "difficulty": 2,
      "totalSteps": 3,
      "steps": [
        {
          "step": 1,
          "title": "ë°ì´í„° ë°°ì¹˜ ë³‘í•© ì˜¤ë¥˜ (Batch Stacking)",
          "file_name": "dataset.py",
          "description": "ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì„ í•™ìŠµì— ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë¯¸ë‹ˆ ë°°ì¹˜(Mini-batch)ë¡œ ë¬¶ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ í•´ìƒë„ì˜ ì›ë³¸ ì´ë¯¸ì§€ë“¤ì´ ìˆ˜ì§‘ë˜ì—ˆê³ , ì´ë¥¼ í•˜ë‚˜ì˜ í…ì„œë¡œ í•©ì³ì•¼ í•©ë‹ˆë‹¤.\n\ní˜„ì¬ `create_batch` í•¨ìˆ˜ëŠ” ë‹¨ìˆœíˆ ì´ë¯¸ì§€ë“¤ì„ ë¦¬ìŠ¤íŠ¸ì— ëª¨ì€ í›„ `torch.stack`ìœ¼ë¡œ ë³€í™˜í•˜ë ¤ê³  í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ë°ì´í„° ë¡œë”ë¥¼ ì‹¤í–‰í•˜ë©´ ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n\n**ëª©í‘œ:**\n1. ì…ë ¥ëœ ì´ë¯¸ì§€ë“¤ì˜ í¬ê¸°ê°€ ì„œë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆìŒì„ ì¸ì§€í•©ë‹ˆë‹¤.\n2. ëª¨ë“  ì´ë¯¸ì§€ë¥¼ í•™ìŠµ ëª¨ë¸ì˜ ì…ë ¥ í¬ê¸°ì¸ `(224, 224)`í•´ìƒë„ë¡œ í†µì¼í•©ë‹ˆë‹¤.\n3. ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë“¤ì„ í•˜ë‚˜ì˜ ë°°ì¹˜ í…ì„œ `(B, C, H, W)` í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.",
          "objectives": [
            "ê°€ë³€ í¬ê¸° ë°ì´í„° ì²˜ë¦¬ ì „ëµ ìˆ˜ë¦½",
            "Torchvision Transforms í™œìš©",
            "Tensor Shape ë””ë²„ê¹…"
          ],
          "buggy_code": "import torch\nimport numpy as np\n\ndef create_batch(images):\n    \"\"\"\n    ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ë°°ì¹˜ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n    images: list of numpy arrays (H, W, C)\n    \"\"\"\n    tensor_images = []\n    \n    for img in images:\n        # numpy arrayë¥¼ tensorë¡œ ë³€í™˜\n        tensor_img = torch.from_numpy(img).permute(2, 0, 1).float()\n        tensor_images.append(tensor_img)\n    \n    # ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë°°ì¹˜ í…ì„œë¡œ ë³€í™˜\n    return torch.stack(tensor_images)",
          "correct_code": "import torch\nimport numpy as np\nfrom torchvision import transforms\n\ndef create_batch(images):\n    \"\"\"\n    ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ë°°ì¹˜ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n    images: list of numpy arrays (H, W, C)\n    \"\"\"\n    processed_images = []\n    resize = transforms.Resize((224, 224))\n    \n    for img in images:\n        # numpy -> tensor [C, H, W]\n        tensor_img = torch.from_numpy(img).permute(2, 0, 1).float()\n        \n        # Resize ì ìš©\n        resized_img = resize(tensor_img)\n        processed_images.append(resized_img)\n        \n    return torch.stack(processed_images)",
          "hints": [
            "ì—ëŸ¬ ë¡œê·¸ì˜ 'sizes of tensors must match' ë©”ì‹œì§€ì— ì£¼ëª©í•˜ì„¸ìš”.",
            "ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ê³ ì •ëœ ì…ë ¥ í¬ê¸°ë¥¼ ìš”êµ¬í•©ë‹ˆë‹¤.",
            "torchvision.transforms ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
          ],
          "error_log": "Traceback (most recent call last):\n  File \"dataset.py\", line 14, in create_batch\n    return torch.stack(tensor_images)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 224, 224] at entry 0 and [3, 500, 300] at entry 1",
          "success_log": "[INFO] Batch processing started...\n[INFO] Image 0 original shape: (224, 224, 3)\n[INFO] Image 1 original shape: (500, 300, 3)\n[INFO] Resizing images to (224, 224)...\n[SUCCESS] Batch created successfully. Output tensor shape: torch.Size([32, 3, 224, 224])",
          "solution_check": {
            "type": "multi_condition",
            "required_any": [
              "Resize",
              "resize"
            ],
            "required_all": [
              "stack"
            ]
          },
          "error_info": {
            "type": "RuntimeError (Shape Mismatch)",
            "description": "ì„œë¡œ ë‹¤ë¥¸ ì°¨ì›(Resolution)ì„ ê°€ì§„ í…ì„œë“¤ì€ í•˜ë‚˜ë¡œ ìŒ“ì„(Stack) ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "suggestion": "ëª¨ë“  ì…ë ¥ ì´ë¯¸ì§€ë¥¼ transforms.Resize ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë™ì¼í•œ í¬ê¸°ë¡œ ë§ì¶˜ í›„ stack í•˜ì„¸ìš”."
          }
        },
        {
          "step": 2,
          "title": "ì—°ì‚° ì¥ì¹˜ ë¶ˆì¼ì¹˜ (Device Mismatch)",
          "file_name": "inference.py",
          "description": "í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê³ ì„±ëŠ¥ ì¶”ë¡ (Inference)ì„ ìˆ˜í–‰í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ì„œë²„ì—ëŠ” CUDAë¥¼ ì§€ì›í•˜ëŠ” GPUê°€ ì¥ì°©ë˜ì–´ ìˆì–´, ëª¨ë¸ì„ GPUë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\n\ní•˜ì§€ë§Œ ì¶”ë¡  í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ìë§ˆì ëŸ°íƒ€ì„ ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤. PyTorchì˜ í…ì„œ ì—°ì‚° ê·œì¹™ì„ ê³ ë ¤í•˜ì—¬ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.\n\n**ëª©í‘œ:**\n1. GPU(cuda)ì™€ CPU í…ì„œ ê°„ì˜ ì—°ì‚° ì œì•½ ì‚¬í•­ì„ ì´í•´í•©ë‹ˆë‹¤.\n2. ì…ë ¥ ë°ì´í„°ë„ ëª¨ë¸ê³¼ ë™ì¼í•œ ì—°ì‚° ì¥ì¹˜ë¡œ ì´ë™ì‹œí‚µë‹ˆë‹¤.\n3. ì¶”ë¡  ê²°ê³¼ë¥¼ ë‹¤ì‹œ CPUë¡œ ê°€ì ¸ì˜¤ëŠ”ì§€, í˜¹ì€ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ëŠ”ì§€ ê²°ì •í•©ë‹ˆë‹¤ (ì¼ë°˜ì ìœ¼ë¡œ ê²°ê³¼ëŠ” CPUë¡œ ë°˜í™˜í•˜ê±°ë‚˜ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤).",
          "objectives": [
            "PyTorch Device ê´€ë¦¬ ì „ëµ",
            "Tensor.to() ë©”ì„œë“œ í™œìš©",
            "ì´ì¢… ì¥ì¹˜ ê°„ ì—°ì‚° ì—ëŸ¬ ë””ë²„ê¹…"
          ],
          "buggy_code": "import torch\nimport torch.nn as nn\n\ndef run_inference(model, inputs):\n    # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Processing on: {device}\")\n    \n    # ëª¨ë¸ì„ í•´ë‹¹ ì¥ì¹˜ë¡œ ì´ë™\n    model = model.to(device)\n    model.eval()\n    \n    with torch.no_grad():\n        # ëª¨ë¸ ì¶”ë¡  ìˆ˜í–‰\n        output = model(inputs)\n        \n    return output",
          "correct_code": "import torch\nimport torch.nn as nn\n\ndef run_inference(model, inputs):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Processing on: {device}\")\n    \n    model = model.to(device)\n    \n    # ì…ë ¥ ë°ì´í„°ë„ ë™ì¼í•œ deviceë¡œ ì´ë™\n    inputs = inputs.to(device)\n    \n    model.eval()\n    \n    with torch.no_grad():\n        output = model(inputs)\n        \n    return output",
          "hints": [
            "ë¡œê·¸ì˜ 'Expected all tensors to be on the same device' ë©”ì‹œì§€ê°€ í•µì‹¬ì…ë‹ˆë‹¤.",
            "ëª¨ë¸ì´ GPUì— ìˆë‹¤ë©´, ê·¸ ëª¨ë¸ì— ë“¤ì–´ê°€ëŠ” ì…ë ¥(Input) í…ì„œë„ ì–´ë””ì— ìˆì–´ì•¼ í• ê¹Œìš”?",
            "inputs ë³€ìˆ˜ì— .to(device)ë¥¼ ì ìš©í•´ë³´ì„¸ìš”."
          ],
          "error_log": "Processing on: cuda:0\nTraceback (most recent call last):\n  File \"inference.py\", line 13, in run_inference\n    output = model(inputs)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "success_log": "Processing on: cuda:0\n[INFO] Model loaded on cuda:0\n[INFO] Input tensor moved to cuda:0\n[SUCCESS] Inference completed successfully. Output shape: torch.Size([1, 1000])",
          "solution_check": {
            "type": "multi_condition",
            "required_all": [
              "inputs.to(device)"
            ]
          },
          "error_info": {
            "type": "RuntimeError (Device Mismatch)",
            "description": "ì´ì¢… ì¥ì¹˜(GPU ëª¨ë¸ + CPU ë°ì´í„°) ê°„ì—ëŠ” ì§ì ‘ì ì¸ í…ì„œ ì—°ì‚°ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.",
            "suggestion": "ëª¨ë¸ê³¼ ì…ë ¥ ë°ì´í„°ê°€ ëª¨ë‘ ê°™ì€ ì¥ì¹˜(ex: cuda:0)ì— ì¡´ì¬í•˜ë„ë¡ inputs.to(device)ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”."
          }
        },
        {
          "step": 3,
          "title": "ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤/í­ë°œ (Gradient Accumulation)",
          "file_name": "trainer.py",
          "description": "ëª¨ë¸ í•™ìŠµ ë£¨í”„(Training Loop)ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° í•™ìŠµì„ ì§„í–‰í• ìˆ˜ë¡ Loss ê°’ì´ ì¤„ì–´ë“¤ê¸°ëŠ”ì»¤ë…• ë¹„ì •ìƒì ìœ¼ë¡œ ì»¤ì§€ê±°ë‚˜(Exploding), ì „í˜€ í•™ìŠµì´ ë˜ì§€ ì•ŠëŠ” í˜„ìƒì´ ë°œìƒí•©ë‹ˆë‹¤.\n\në¡œê·¸ë¥¼ ë¶„ì„í•´ë³´ë‹ˆ, ê·¸ë˜ë””ì–¸íŠ¸(Gradient) ê°’ì´ ìŠ¤í…ë§ˆë‹¤ ê³„ì† ëˆ„ì ë˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. PyTorchì˜ ê¸°ë³¸ì ì¸ í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜ì„ ìƒê°í•˜ë©° ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.\n\n**ëª©í‘œ:**\n1. PyTorchì˜ `backward()` ë™ì‘ ë°©ì‹ì„ ì´í•´í•©ë‹ˆë‹¤ (ê¸°ë³¸ì ìœ¼ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ë”í•¨).\n2. ë§¤ í•™ìŠµ ìŠ¤í…ë§ˆë‹¤ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•´ì•„ í•˜ëŠ” ì´ìœ ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.\n3. `optimizer.zero_grad()`ë¥¼ ì ì ˆí•œ ìœ„ì¹˜ì— ë°°ì¹˜í•©ë‹ˆë‹¤.",
          "objectives": [
            "Training Loopì˜ ì •ì„ì ì¸ êµ¬ì¡° ìˆ™ì§€",
            "Optimizerì˜ ì—­í• ê³¼ zero_grad ì´í•´",
            "í•™ìŠµ ë¶ˆì•ˆì •ì„± ë””ë²„ê¹…"
          ],
          "buggy_code": "import torch\n\ndef train_step(model, inputs, targets, optimizer, criterion):\n    model.train()\n    \n    # 1. Forward Pass: ì˜ˆì¸¡ê°’ ê³„ì‚°\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\n    \n    # 2. Backward Pass: ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°\n    loss.backward()\n    \n    # 3. Optimizer Step: ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n    optimizer.step()\n    \n    return loss.item()",
          "correct_code": "import torch\n\ndef train_step(model, inputs, targets, optimizer, criterion):\n    model.train()\n    \n    # 0. Gradient ì´ˆê¸°í™” (í•„ìˆ˜)\n    # ìƒˆë¡œìš´ ë°°ì¹˜ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ê¸° ì „ì— ì´ì „ ê°’ì„ ë¹„ì›Œì¤Œ\n    optimizer.zero_grad()\n    \n    # 1. Forward Pass\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\n    \n    # 2. Backward Pass\n    loss.backward()\n    \n    # 3. Optimizer Step\n    optimizer.step()\n    \n    return loss.item()",
          "hints": [
            "PyTorchì—ì„œëŠ” loss.backward()ë¥¼ í˜¸ì¶œí•  ë•Œë§ˆë‹¤ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ê¸°ì¡´ ê°’ì— 'ë”í•´ì§‘ë‹ˆë‹¤(Accumulate)'.",
            "ì´ì „ ë°°ì¹˜ì˜ ê·¸ë˜ë””ì–¸íŠ¸ê°€ í˜„ì¬ ë°°ì¹˜ì˜ ì—…ë°ì´íŠ¸ì— ì˜í–¥ì„ ì£¼ë©´ ì•ˆ ë©ë‹ˆë‹¤.",
            "ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸(step)í•˜ê¸° ì „, í˜¹ì€ ì—­ì „íŒŒ(backward)ë¥¼ ì‹œì‘í•˜ê¸° ì „ì— ë¬´ì—‡ì„ í•´ì•¼ í• ê¹Œìš”?"
          ],
          "error_log": "[Epoch 1] Step 1 - Loss: 2.302\n[Epoch 1] Step 2 - Loss: 45.120 (Warning: Loss Increased!)\n[Epoch 1] Step 3 - Loss: 912.441 (Error: Loss Exploding)\n[DEBUG] Gradient Norm Check:\n - Step 1: 0.5\n - Step 2: 12.8 (Suspiciously High)\n - Step 3: 154.2 (Exploding)",
          "success_log": "[Epoch 1] Step 1 - Loss: 2.302\n[Epoch 1] Step 2 - Loss: 2.150\n[Epoch 1] Step 3 - Loss: 1.980\n[SUCCESS] Loss is decreasing steadily.\n[DEBUG] Gradient Norm is stable (around 0.5 ~ 0.8).",
          "solution_check": {
            "type": "multi_condition",
            "required_all": [
              "zero_grad()"
            ]
          },
          "error_info": {
            "type": "Logic Error (Gradient Accumulation)",
            "description": "zero_grad()ë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šìœ¼ë©´ ì´ì „ ìŠ¤í…ì˜ ê·¸ë˜ë””ì–¸íŠ¸ê°€ ê³„ì† ëˆ„ì ë˜ì–´, ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ê°€ ì—‰ë§ì´ ë©ë‹ˆë‹¤.",
            "suggestion": "ë§¤ í•™ìŠµ ìŠ¤í…ì˜ ì‹œì‘ ë¶€ë¶„(ë˜ëŠ” backward ì „)ì— optimizer.zero_grad()ë¥¼ ë°˜ë“œì‹œ í˜¸ì¶œí•˜ì„¸ìš”."
          }
        }
      ]
    }
  ]
}