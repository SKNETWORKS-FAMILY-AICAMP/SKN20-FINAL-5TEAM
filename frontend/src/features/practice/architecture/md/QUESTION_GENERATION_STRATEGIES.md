# 아키텍처 질문 생성 품질 개선 전략 분석

> 현재 버전(v2)과 향상된 방식들을 비교 분석하여 **최적의 질문 생성 품질**을 달성하기 위한 가이드

---

## 목차
1. [현재 버전(v2) 평가](#현재-버전v2-평가)
2. [대안적 전략들](#대안적-전략들)
3. [전략별 비교 분석](#전략별-비교-분석)
4. [최적 조합 제안](#최적-조합-제안)
5. [평가 메트릭스](#평가-메트릭스)

---

## 현재 버전(v2) 평가

### ✅ 강점
- **구조화된 파이프라인**: 기둥 선별 → 역할 분류 → 질문 생성 → 선별
- **다층 필터링**: 관련성 높은 4개 기둥만 사용 (토큰 절약)
- **Role-based 분류**: 컴포넌트를 Entry/Compute/Storage/Security/Monitoring으로 체계화
- **안티패턴 지시**: 일반적인 설계 문제 명시
- **CoT 강제**: "생각 프로세스" 섹션으로 추론 구조화

### ⚠️ 약점
- **단순한 품질 평가**: 컴포넌트 언급 여부, 상황 기반 표현, 성공 여부만 체크 (3가지 차원)
- **고정된 안티패턴**: 모든 문제에 동일한 체크리스트 적용
- **일회성 생성**: 생성 후 개선 루프 없음
- **제한된 컨텍스트**: 문제의 decision points 미활용
- **평면적 점수 매김**: 모든 질문에 동일 가중치 적용

---

## 대안적 전략들

### 전략 1️⃣: **Few-Shot Prompting (예시 기반 학습)**

**개념**: 프롬프트에 고품질 질문 예시를 포함하여 AI가 패턴을 학습하도록 유도

```
좋은 질문 예시:
1. [신뢰성] 상황: "동시 사용자 10배 증가"
   → "DB가 단일 인스턴스라면, 읽기 부하 증가 시 어떻게 대응하나요?"

2. [성능] 상황: "캐시 계층 부재"
   → "모든 읽기가 DB를 거친다면, 응답 지연이 누적되는 구조 아닌가요?"
```

**구현 방식**:
- 각 기둥별 3-5개의 고품질 질문 예시 정의
- 프롬프트 In-Context Learning 섹션에 포함
- 모델이 예시의 패턴을 따르도록 유도

**장점**:
- ⭐ 질문 품질 일관성 향상
- ⭐ 프롬프트 토큰 추가 필요 (소소함)
- ⭐ 구현이 간단함

**단점**:
- ❌ 예시를 잘못 만들면 역효과
- ❌ 문제별 다양성 제한 가능
- 상대적 효과: **중간**

---

### 전략 2️⃣: **다층 평가 메커니즘 (Multi-Dimensional Scoring)**

**개념**: 질문 품질을 3개 차원이 아닌 **8-10개 차원**으로 평가

**평가 차원**:
1. **컴포넌트 구체성** (40점): 실제 컴포넌트 언급 정도
2. **상황 적절성** (30점): 문제 시나리오와의 연관성
3. **의도 파악도** (30점): 설계자의 선택 이유 질문 여부
4. **안티패턴 감지** (20점): 실제 문제점 지적 여부
5. **개방형 정도** (20점): Yes/No가 아닌 설명 유도 정도
6. **전문성 수준** (15점): 표면적 vs 심화 분석
7. **기술적 정확도** (15점): 오류/오해 가능성
8. **실행 가능성** (10점): 답변할 수 있는 질문인가

**구현 방식**:
```javascript
// 각 차원별 점수 계산 후 가중합
totalScore =
  specificityScore * 0.20 +
  relevanceScore * 0.20 +
  intentScore * 0.20 +
  antipatternScore * 0.15 +
  opennessScore * 0.10 +
  expertiseScore * 0.10 +
  accuracyScore * 0.05;
```

**장점**:
- ⭐⭐ 정교한 품질 평가 가능
- ⭐⭐ 가중치 조정으로 우선순위 반영
- ⭐ 약점 식별 용이

**단점**:
- ❌ 각 차원의 점수 계산 로직 복잡
- ❌ 점수 검증 필요
- 상대적 효과: **높음** (15-20% 개선)

---

### 전략 3️⃣: **반복적 개선 루프 (Iterative Refinement)**

**개념**: 초기 질문 생성 후 "이 질문을 더 좋게 개선할 수 있나?"라는 후속 프롬프트 실행

**프로세스**:
1. AI가 질문 1차 생성
2. "위 질문의 문제점은? 어떻게 개선할 수 있나?"라는 메타 평가 프롬프트 실행
3. AI가 개선된 질문 제시
4. 2-3회 반복

**구현 방식**:
```javascript
// 1차 생성
const initialQuestion = await generateQuestionForPillar(...);

// 메타 평가 및 개선
const refinedQuestion = await refineQuestion(initialQuestion, context);

// 2차 개선 (필요시)
const finalQuestion = await refineQuestion(refinedQuestion, context);
```

**장점**:
- ⭐⭐⭐ 가장 큰 품질 향상 가능 (20-30%)
- ⭐⭐ 자동으로 약점 보정
- ⭐⭐ 다양한 각도의 질문 생성

**단점**:
- ❌❌ API 호출 3배 증가 (비용 3배)
- ❌ 응답 시간 3배 증가 (UX 저하)
- ❌ 무한 루프 가능성
- 상대적 효과: **매우 높음** (단, 비용 높음)

---

### 전략 4️⃣: **문제 컨텍스트 심화 (Enhanced Context Extraction)**

**개념**: 현재는 미활용하는 **decision_points**, **axis_weights** 등의 정보를 더 활용

**추가 컨텍스트**:
- Decision points의 트레이드오프 명시 (신뢰성 vs 성능?)
- axis_weights를 기반으로 우선순위 강조
- 문제의 제약조건을 더 구체적으로 해석
- 지원자의 설명에서 암묵적 가정 추출

**구현 방식**:
```javascript
// Decision points를 "트레이드오프 분석" 섹션으로 프롬프트에 삽입
const tradeoffAnalysis = problem.decision_points.map(dp => `
  선택지: ${dp.decision}
  고민점: ${dp.tension}
  → 이 선택에서 무엇을 우선했는가?
`).join('\n');
```

**장점**:
- ⭐⭐ 문제의 핵심을 더 정확히 파악
- ⭐ 추가 API 호출 없음 (토큰만 증가)
- ⭐ 질문의 타당성 향상

**단점**:
- ❌ 프롬프트 길이 증가 (토큰 20-30% 증가)
- ❌ 데이터 품질에 의존
- 상대적 효과: **중상** (10-15% 개선)

---

### 전략 5️⃣: **기둥별 특화 프롬프트 (Pillar-Specific Templates)**

**개념**: 각 기둥마다 **고유한 질문 생성 전략** 정의

**예시**:
- **신뢰성**: "최악의 시나리오" 중심 질문 (SPOF, 데이터 손실 등)
- **성능**: "부하 증가 시" 동작 중심 질문 (스케일링, 병목 등)
- **운영**: "자동화 정도" 중심 질문 (모니터링, 배포 등)
- **보안**: "공격 시나리오" 중심 질문 (침투, 접근 제어 등)
- **비용**: "리소스 낭비" 탐지 중심 질문 (중복, 유휴 등)
- **지속성**: "에너지 효율" 중심 질문 (리소스, Scale to zero 등)

**구현 방식**:
```javascript
const PILLAR_QUESTION_STRATEGIES = {
  reliability: {
    focus: '최악 시나리오 복구 능력',
    questionPattern: '~이 발생하면 어떻게 대응하나요?',
    keywords: ['SPOF', '장애 감지', '자동 복구']
  },
  // ...
};
```

**장점**:
- ⭐⭐⭐ 각 기둥의 특성을 정확히 반영
- ⭐ 질문의 일관성과 관련성 극대화
- ⭐ 프롬프트 구조 재사용 가능

**단점**:
- ❌ 각 기둥별 전략 개발 필요 (시간 소요)
- ❌ 기둥별 프롬프트 유지보수 필요
- 상대적 효과: **높음** (15-20% 개선)

---

### 전략 6️⃣: **자동 검증 및 필터링 (Automated Quality Gate)**

**개념**: 생성된 질문이 실제로 "좋은 질문"인지 **자동 검증**

**검증 체크리스트**:
1. ✅ 실제 배치된 컴포넌트만 언급했나?
2. ✅ Yes/No로 답할 수 있는 질문은 아닌가?
3. ✅ 문제 시나리오와 관련 있나?
4. ✅ 기술적으로 정확한가?
5. ✅ 지원자가 답변할 수 있나?

**구현 방식**:
```javascript
async function validateQuestion(question, context) {
  const checks = [
    hasValidComponent(question, context.components),
    isOpenEnded(question),
    isRelevant(question, context.problem),
    isTechnicallySound(question),
    isAnswerable(question)
  ];

  return checks.every(c => c === true);
}
```

**장점**:
- ⭐⭐ 불량 질문 자동 필터링
- ⭐ 일관된 품질 보장
- ⭐ 추가 API 호출 작음 (검증용 간단한 프롬프트)

**단점**:
- ❌ 검증 로직 개발 필요
- ❌ False positive 가능성
- 상대적 효과: **중상** (10-15% 개선)

---

### 전략 7️⃣: **멀티 모델 앙상블 (Multi-Model Ensemble)**

**개념**: 여러 모델의 결과를 조합하여 **가장 좋은 질문** 선택

**프로세스**:
1. GPT-4o-mini로 질문 생성 (빠름, 저비용)
2. Claude로 질문 생성 (사고 깊이)
3. 두 결과를 비교하여 더 좋은 것 선택

**장점**:
- ⭐⭐⭐ 모델별 장점 활용 가능
- ⭐⭐ 다양한 관점의 질문 확보

**단점**:
- ❌❌ API 호출 2배 (비용 2배)
- ❌ 응답 시간 2배 증가
- ❌ 모델 간 일관성 문제
- 상대적 효과: **높음** (단, 비용 높음)

---

### 전략 8️⃣: **동적 난이도 조절 (Adaptive Difficulty)**

**개념**: 지원자 수준에 맞춘 **동적 질문 난이도** 조정

**난이도 레벨**:
- **Level 1** (기초): "이 구조에서 SPOF가 있나요?"
- **Level 2** (중급): "트래픽 급증 시 어느 부분이 먼저 병목이 될까요?"
- **Level 3** (고급): "이 아키텍처의 복원력(Resilience)을 극대화하려면 어떤 기술 트레이드오프를 고려했나요?"

**구현 방식**:
```javascript
function generateQuestionByLevel(problem, difficulty = 'medium') {
  const levelPrompts = {
    easy: '기초적인 수준의 단순한 질문',
    medium: '중간 수준의 설계 의도 확인 질문',
    hard: '깊이 있는 아키텍처 철학 질문'
  };

  return generateQuestion(problem, levelPrompts[difficulty]);
}
```

**장점**:
- ⭐⭐ 모든 수준의 지원자에게 적합
- ⭐ UX 개선 (좌절감 감소)

**단점**:
- ❌ 난이도 평가 로직 필요
- ❌ 추가 복잡도
- 상대적 효과: **중상** (UX 개선, 평가 정확도는 미미)

---

### 전략 9️⃣: **메타 분석 및 최적화 (Meta-Analysis)**

**개념**: 생성된 모든 질문의 특성을 분석하여 **패턴 도출 및 최적화**

**분석 지표**:
- 질문 길이 vs 품질 상관관계
- 컴포넌트 언급 수 vs 답변 깊이
- 키워드 분포 분석
- 성공률 높은 질문의 공통 패턴

**구현 방식**:
```javascript
function analyzeQuestionMetrics(questions) {
  return {
    avgLength: avg(q => q.question.length),
    componentMentionRate: percent(q => hasComponentRef(q)),
    situationalRate: percent(q => hasSituation(q)),
    successRate: percent(q => q.success),
    // 패턴 도출...
  };
}
```

**장점**:
- ⭐⭐ 시간이 지날수록 최적화 향상
- ⭐ 데이터 기반 의사결정
- ⭐ 지속적 개선 가능

**단점**:
- ❌ 초기 데이터 필요
- ❌ 분석 인프라 구축 필요
- 상대적 효과: **높음** (장기적으로 20-30%)

---

### 전략 🔟: **실제 답변 피드백 루프 (Answer Feedback Loop)**

**개념**: 지원자의 실제 답변을 분석하여 **질문 생성 모델 개선**

**프로세스**:
1. 질문 생성 및 지원자 답변 수집
2. 답변 품질 평가 (깊이, 관련성, 기술 정확도)
3. "좋은 답변을 유도한 질문"의 특성 분석
4. 이런 특성을 가진 프롬프트 템플릿 개선

**장점**:
- ⭐⭐⭐ 가장 현실적인 개선
- ⭐⭐ 실제 데이터 기반

**단점**:
- ❌❌ 장기간 데이터 수집 필요
- ❌ 초기 개선 어려움
- 상대적 효과: **매우 높음** (장기: 30-40%)

---

## 전략별 비교 분석

### 📊 종합 비교표

| 전략 | 효과 | 비용 | 복잡도 | 구현 시간 | 비고 |
|------|------|------|--------|---------|------|
| 1. Few-Shot | ⭐⭐⭐ (10%) | 낮음 | 낮음 | 2시간 | 빠른 개선 |
| 2. 다층 평가 | ⭐⭐⭐⭐ (15%) | 낮음 | 중간 | 1일 | 안정적 |
| 3. 반복 개선 | ⭐⭐⭐⭐⭐ (25%) | 높음 | 높음 | 3시간 | 비용 최고 |
| 4. 컨텍스트 심화 | ⭐⭐⭐ (12%) | 낮음 | 낮음 | 4시간 | 토큰 증가 |
| 5. 특화 프롬프트 | ⭐⭐⭐⭐ (18%) | 낮음 | 중간 | 2일 | 기둥별 최적화 |
| 6. 자동 검증 | ⭐⭐⭐ (12%) | 중간 | 중간 | 1일 | 안정성 |
| 7. 멀티 모델 | ⭐⭐⭐⭐ (20%) | 높음 | 낮음 | 2시간 | 비용 높음 |
| 8. 동적 난이도 | ⭐⭐ (5%) | 낮음 | 중간 | 2일 | UX만 개선 |
| 9. 메타 분석 | ⭐⭐⭐⭐ (20% 이상) | 낮음 | 높음 | 3일 | 장기 효과 |
| 10. 답변 피드백 | ⭐⭐⭐⭐⭐ (30% 이상) | 낮음 | 높음 | 지속 | 최고 효과 |

---

## 최적 조합 제안

### 🏆 Phase 1: 즉시 구현 (1주일)

**목표**: 현재 대비 **15-20% 품질 개선**

```
1. Few-Shot Prompting 추가 (2시간)
   - 각 기둥별 3개 고품질 예시 작성

2. 다층 평가 메커니즘 도입 (1일)
   - 8개 차원으로 확장
   - 가중치 설정 및 테스트

3. 자동 검증 필터 추가 (1일)
   - 기본 5가지 체크리스트 구현
   - Fallback 처리
```

**기대 효과**: +15-20%
**비용**: 낮음
**구현 난이도**: 중간

---

### 🚀 Phase 2: 심화 개선 (2주일)

**목표**: 현재 대비 **25-30% 품질 개선**

```
1. 기둥별 특화 프롬프트 (2일)
   - 각 기둥마다 고유한 질문 생성 전략
   - 신뢰성: 최악 시나리오
   - 성능: 부하 증가 상황
   - 운영: 자동화 정도
   - 보안: 공격 시나리오
   - 비용: 리소스 낭비
   - 지속성: 에너지 효율

2. 문제 컨텍스트 심화 (2일)
   - decision_points 활용
   - axis_weights 강조
   - 제약조건 구체화

3. 메타 분석 대시보드 (2일)
   - 질문 특성 분석
   - 패턴 도출
   - 최적화 지표
```

**기대 효과**: +25-30%
**비용**: 중간
**구현 난이도**: 높음

---

### 💎 Phase 3: 장기 최적화 (3주일 이상)

**목표**: 현재 대비 **30-40% 이상 품질 개선**

```
1. 반복적 개선 루프 (3-4시간)
   - 1차 생성 후 메타 평가
   - 2-3회 반복으로 정련

2. 답변 피드백 루프 구축
   - 실제 답변 데이터 수집
   - 품질 평가 기준 개발
   - 지속적 개선 파이프라인

3. 실험 관리 프레임워크
   - A/B 테스트 인프라
   - 효과 측정 및 비교
```

**기대 효과**: +30-40%
**비용**: 높음
**구현 난이도**: 매우 높음

---

## 평가 메트릭스

### 질문 품질 평가 기준

#### 1️⃣ 구조적 평가 (Structural)
- **컴포넌트 언급 정확도**: 실제 배치된 컴포넌트만 언급 (0-100%)
- **개방형 정도**: Yes/No 가능성 (0-100%)
- **길이 적절성**: 350-450 문자 범위 (0-100%)

#### 2️⃣ 관련성 평가 (Relevance)
- **시나리오 연결**: 문제의 시나리오와 얼마나 연결되었는가 (0-100%)
- **기둥 적절성**: 해당 기둥의 핵심을 짚었는가 (0-100%)
- **의도 파악**: 지원자의 설계 선택 의도를 묻는가 (0-100%)

#### 3️⃣ 기술적 평가 (Technical)
- **정확도**: 기술적으로 오류가 없는가 (0-100%)
- **실현 가능성**: 지원자가 답변할 수 있는 질문인가 (0-100%)
- **깊이**: 표면적/심화 분석 수준 (1-5 단계)

#### 4️⃣ 효과성 평가 (Effectiveness)
- **답변 길이**: 질문에 대한 답변이 충분히 깊은가 (글자 수)
- **답변 정확도**: 지원자 답변의 기술 정확도 (0-100%)
- **통찰력**: 지원자가 숨겨진 설계 의도를 드러내는가 (0-100%)

---

### 비교 평가 시나리오

#### ✏️ 테스트 케이스

**문제 1: 고가용성 전자상거래 플랫폼**
```
시나리오: 동시 사용자 10배 증가 가능
미션: 데이터 손실 방지, 가용성 99.99%
제약: AWS 단일 리전만 사용 가능

현재 질문: "동시 사용자가 10배로 늘어나면, 이 아키텍처가 자동으로 성능을 유지할 수 있나요?"
점수: 65점

개선 질문 (Phase 1): "AWS 단일 리전에서 10배 트래픽을 감당하려면, RDS가 읽기 복제본을 자동으로 추가할 수 있는 구조인가요?"
점수: 80점

개선 질문 (Phase 2): "AWS 단일 리전 제약에서 10배 사용자 증가 시, 현재 설계의 어느 부분(LB/AS/DB/Cache)이 먼저 한계에 도달할 것으로 예상하고, 각각 어떻게 대응했나요?"
점수: 92점
```

**문제 2: 보안이 중요한 금융 시스템**
```
시나리오: 클라이언트가 시스템 접근 권한 침해 우려
미션: 데이터 암호화, 접근 제어, 감사 추적
제약: 온프레미스만 사용

현재 질문: "외부 공격자가 시스템에 접근하려고 할 때, 어떤 계층에서 차단되나요?"
점수: 58점

개선 질문 (Phase 2): "온프레미스 환경에서 데이터 유출을 방지하기 위해, (1) 저장 시 암호화, (2) 전송 시 암호화, (3) 접근 제어, (4) 감사 추적 중 어떤 부분에 가장 신경 썼으며, 각각의 구현 방식은?"
점수: 95점
```

---

## 구현 로드맵

### 📅 추천 순서

```
Week 1-2: Phase 1 (즉시 구현)
  ├─ Few-Shot 예시 수집 및 작성
  ├─ 다층 평가 메커니즘 개발
  └─ 자동 검증 필터 구현

Week 3-4: Phase 2 (심화 개선)
  ├─ 기둥별 특화 프롬프트 개발
  ├─ 문제 컨텍스트 심화
  └─ 메타 분석 대시보드

Month 2+: Phase 3 (장기 최적화)
  ├─ 반복적 개선 루프
  ├─ 답변 피드백 수집 체계 구축
  └─ 지속적 A/B 테스팅
```

---

## 최종 권장사항

### 🎯 현재 상황에서 최선의 선택

**당장 구현할 것** (효과 높음, 난이도 낮음):
1. ✅ **Few-Shot Prompting** (+10%)
2. ✅ **다층 평가 메커니즘** (+15%)
3. ✅ **기둥별 특화 프롬프트** (+18%)

**조합 기대 효과**: **+40% 이상** (중복 제거 후 ~35-40%)

**총 구현 시간**: 3-4일
**총 비용**: 낮음
**난이도**: 중간

---

**이 전략들을 순차적으로 구현하고, 각 단계 후 실제 평가 메트릭으로 검증하면, 현재 대비 **30-40% 이상의 질문 생성 품질 향상**을 달성할 수 있습니다.**
