[
  {
    "sample_id": "jr_001_url_shortener_excellent",
    "problem_id": "jr_001_url_shortener",
    "problem": {
      "title": "축제 홍보용 단축 URL 생성기",
      "scenario": "학생회에서 축제 홍보용 긴 구글 폼 링크를 짧은 URL로 변환하여 배포하려고 합니다. 홍보 문자가 발송되는 시점에 대량의 클릭이 발생합니다.",
      "missions": [
        "초당 수천 건의 읽기 요청을 처리하면서 DB 부하를 최소화하는 구조를 설계하세요.",
        "단축 URL 생성 및 원본 리다이렉션의 데이터 흐름을 다이어그램으로 나타내세요."
      ],
      "constraints": [
        "하루 평균 1,000개 생성, 읽기 요청 초당 최대 1,000건(TPS)",
        "리다이렉션 응답 속도 100ms 이내",
        "생성된 링크는 1년간 영구 보존"
      ]
    },
    "quality_level": "excellent",
    "expected_score_range": [
      85,
      100
    ],
    "architecture_context": "1. **클라이언트 애플리케이션**: 학생회에서 사용하는 웹 애플리케이션, 사용자 입력을 받고 단축 URL 요청을 처리.\n2. **API 게이트웨이**: 모든 요청을 수집하고 각 서비스로 라우팅, 부하 분산 기능 제공.\n3. **URL 생성 서비스**: 긴 URL을 받아 단축 URL을 생성, 데이터베이스에 저장.\n4. **데이터베이스 (PostgreSQL)**: 단축 URL과 원본 URL 매핑 저장. 1년간 데이터 보존을 위한 설정.\n5. **캐시 시스템 (Redis)**: 단축 URL에 대한 읽기 요청을 처리하기 위한 캐시. TTL: 1시간 설정.\n6. **리다이렉션 서비스**: 사용자가 단축 URL을 클릭할 때 원본 URL로 리다이렉트.\n7. **메시지 큐 (Kafka)**: URL 생성 요청을 비동기적으로 처리하여 DB 부하를 줄임.\n8. **모니터링 및 로깅 (Prometheus, ELK Stack)**: 시스템 성능 및 오류 모니터링, 로그 수집.\n\n데이터 흐름:\n1. 사용자가 클라이언트 애플리케이션을 통해 긴 URL을 입력.\n2. 클라이언트는 API 게이트웨이를 통해 URL 생성 요청을 API에 전달.\n3. API는 URL 생성 서비스로 요청을 라우팅.\n4. URL 생성 서비스는 Kafka에 비동기적으로 요청을 보내고, URL을 생성하여 PostgreSQL에 저장.\n5. Redis 캐시에 단축 URL을 저장하여 이후 읽기 요청에 대비.\n6. 사용자가 단축 URL을 클릭하면 리다이렉션 서비스가 Redis에서 캐시된 URL을 확인.\n7. 캐시에 해당 URL이 없으면 PostgreSQL에서 조회 후 Redis에 저장하고 원본 URL로 리다이렉트.",
    "user_explanation": "이 설계는 고가용성과 높은 성능을 목표로 하고 있습니다. API 게이트웨이는 모든 요청을 중앙에서 관리하여 부하 분산과 보안 기능을 제공합니다. URL 생성 서비스는 긴 URL을 단축 URL로 변환하고, Kafka를 사용하여 비동기적으로 요청을 처리함으로써 데이터베이스에 대한 부하를 줄입니다. \n\nPostgreSQL은 관계형 데이터베이스로, 데이터의 영구 저장에 유리합니다. 1년간 데이터를 보존하기 위해 적절한 데이터 모델링과 인덱싱을 사용할 수 있습니다. Redis는 메모리 기반 캐시로, 단축 URL에 대한 읽기 요청을 초당 최대 1,000건 처리할 수 있도록 지원합니다. TTL 설정을 통해 캐시된 데이터의 유효성을 관리합니다.\n\n리다이렉션 서비스는 사용자가 단축 URL을 클릭 시 100ms 이내의 응답 속도를 제공해야 하므로, Redis 캐시로의 접근을 우선시합니다. 장애 발생 시 Kafka를 사용하여 요청을 다시 처리할 수 있으며, 모니터링 및 로깅 시스템을 통해 시스템의 상태를 지속적으로 확인하고 문제를 조기에 발견할 수 있습니다. \n\n이러한 구성 요소들은 전체 시스템의 부하를 분산시키고, 장애 발생 시 신속한 복구를 가능하게 하여 안정적인 서비스를 제공합니다.",
    "deep_dive_qna": [
      {
        "category": "performance_optimization",
        "question": "초당 1,000건의 리다이렉션 요청에서 캐시 히트율을 높이려면 어떤 전략을 사용해야 할까요?",
        "gap": "캐시 계층의 역할과 위치 이해",
        "answer": "캐시 히트율을 높이기 위해 URL 생성 서비스에서 생성된 단축 URL을 Redis에 저장할 때, TTL(Time to Live) 설정을 통해 자주 요청되는 URL을 장기적으로 캐시할 수 있습니다. 예를 들어, 인기 있는 축제 URL은 1주일의 TTL을 설정하여 자주 접근되는 경우 캐시에서 빠르게 반환되도록 합니다. 또한, URL 요청 패턴을 분석하여 자주 사용되는 URL을 사전 캐싱하거나, LRU(Least Recently Used) 알고리즘을 적용하여 캐시에 자주 접근되는 URL을 우선 유지하는 방법도 있습니다. 이러한 전략은 캐시의 메모리 사용량과 관리 복잡성을 증가시킬 수 있지만, 전체 시스템의 응답 속도를 개선하는 데 기여할 것입니다."
      },
      {
        "category": "reliability",
        "question": "캐시 서버가 다운되었을 때 서비스가 어떻게 유지되어야 하나요?",
        "gap": "장애 시 폴백 전략",
        "answer": "캐시 서버가 다운되었을 때 서비스의 신뢰성을 유지하기 위해, 애플리케이션은 캐시 미스 시 데이터베이스에 직접 접근하여 단축 URL을 조회하도록 구현해야 합니다. 이를 위해 API 게이트웨이에서 캐시 서버의 가용성을 체크하고, 캐시가 다운된 경우에도 요청을 자동으로 데이터베이스로 포워딩하는 로직을 추가할 수 있습니다. 이 경우 데이터베이스의 부하가 증가할 수 있으므로, 데이터베이스의 성능을 높이기 위해 인덱스를 최적화하거나 읽기 전용 복제본을 설정하는 것이 필요합니다. 이러한 접근 방식은 캐시의 이점을 잃게 되지만, 서비스의 가용성을 보장하는 데 효과적입니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "RDBMS",
      "Cache",
      "Redis"
    ],
    "_key_flows": [
      "캐시 → DB 미스 시 조회",
      "Read-through 캐시"
    ]
  },
  {
    "sample_id": "jr_001_url_shortener_good",
    "problem_id": "jr_001_url_shortener",
    "problem": {
      "title": "축제 홍보용 단축 URL 생성기",
      "scenario": "학생회에서 축제 홍보용 긴 구글 폼 링크를 짧은 URL로 변환하여 배포하려고 합니다. 홍보 문자가 발송되는 시점에 대량의 클릭이 발생합니다.",
      "missions": [
        "초당 수천 건의 읽기 요청을 처리하면서 DB 부하를 최소화하는 구조를 설계하세요.",
        "단축 URL 생성 및 원본 리다이렉션의 데이터 흐름을 다이어그램으로 나타내세요."
      ],
      "constraints": [
        "하루 평균 1,000개 생성, 읽기 요청 초당 최대 1,000건(TPS)",
        "리다이렉션 응답 속도 100ms 이내",
        "생성된 링크는 1년간 영구 보존"
      ]
    },
    "quality_level": "good",
    "expected_score_range": [
      72,
      84
    ],
    "architecture_context": "1. 사용자 인터페이스(UI): 축제 홍보용 URL을 생성하고 배포하는 웹 페이지\n2. API 서버: URL 생성 요청을 처리하고, 데이터베이스와 상호작용하는 RESTful API\n3. 데이터베이스: 단축 URL과 원본 URL 매핑 정보를 저장하는 NoSQL 데이터베이스 (예: MongoDB)\n4. 캐시 서버: 자주 조회되는 단축 URL을 저장하여 읽기 성능을 향상시키는 인메모리 캐시 (예: Redis)\n5. 로드 밸런서: API 서버에 대한 요청을 분산 처리하여 초당 최대 1,000건의 요청을 처리\n\n구성도:\n[UI] <-> [API 서버] <-> [로드 밸런서] <-> [캐시 서버]\n                                          |\n                                     [데이터베이스]",
    "user_explanation": "이 아키텍처는 축제 홍보용 단축 URL 생성 및 관리 시스템의 신뢰성과 확장성을 고려하여 설계되었습니다. \n\n1. 사용자 인터페이스(UI): 사용자가 직관적으로 URL을 입력하고 단축 URL을 생성할 수 있는 웹 페이지로, 사용자 경험을 중요시합니다.\n2. API 서버: URL 생성 및 리다이렉션 요청을 처리하는 핵심 컴포넌트입니다. RESTful API를 통해 클라이언트와 통신하며, 데이터베이스와의 상호작용을 담당합니다.\n3. 데이터베이스: 단축 URL과 원본 URL을 효율적으로 저장하기 위해 NoSQL 데이터베이스를 선택했습니다. 이는 유연한 스키마와 높은 쓰기/읽기 성능을 제공하여 하루 평균 1,000개의 URL 생성 요구를 충족합니다.\n4. 캐시 서버: 리다이렉션 요청이 빈번하게 발생하는 단축 URL을 인메모리에 저장하여 응답 속도를 100ms 이내로 유지합니다. Redis와 같은 캐시 서버를 사용하면 DB 부하를 최소화하면서도 빠른 응답이 가능합니다.\n5. 로드 밸런서: API 서버에 대한 요청을 분산하여 초당 최대 1,000건의 트랜잭션을 처리할 수 있도록 설계되었습니다. 이를 통해 시스템의 가용성을 높이고 과부하를 방지합니다.\n\n이와 같은 구조를 통해 우리는 대량의 읽기 요청을 효율적으로 처리하고, DB의 부하를 최소화하면서도 안정적인 서비스를 제공할 수 있습니다.",
    "deep_dive_qna": [
      {
        "category": "performance_optimization",
        "question": "초당 1,000건의 리다이렉션 요청에서 캐시 히트율을 높이려면 어떤 전략을 사용해야 할까요?",
        "gap": "캐시 계층의 역할과 위치 이해",
        "answer": "캐시 히트율을 높이기 위해 자주 사용되는 단축 URL을 우선적으로 캐시에 저장하고, 사용자 행동 분석을 통해 인기 있는 URL을 예측하여 미리 캐시하는 전략을 사용할 수 있습니다. 또한, 캐시 만료 시간을 적절히 설정하여 최신 데이터를 유지하면서도 자주 조회되는 URL이 캐시에서 제거되지 않도록 하는 것이 중요합니다. 마지막으로, 전체 URL 요청 패턴을 모니터링하여 비정상적인 트래픽이나 사용 패턴을 감지하고, 이에 따른 캐시 전략을 조정하는 것도 효과적입니다."
      },
      {
        "category": "reliability",
        "question": "캐시 서버가 다운되었을 때 서비스가 어떻게 유지되어야 하나요?",
        "gap": "장애 시 폴백 전략",
        "answer": "캐시 서버가 다운되었을 때 서비스의 지속성을 위해 API 서버는 직접 데이터베이스에서 원본 URL을 조회하여 요청을 처리하도록 설계되어야 합니다. 이를 통해 캐시가 없는 상태에서도 기본적인 기능이 유지되며, 사용자에게 정상적으로 단축 URL을 제공할 수 있습니다. 또한, 캐시 서버의 복구 후에는 데이터베이스에서 가져온 정보를 캐시에 다시 저장하여 성능을 회복할 수 있습니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "RDBMS",
      "Cache",
      "Redis"
    ],
    "_key_flows": [
      "캐시 → DB 미스 시 조회",
      "Read-through 캐시"
    ]
  },
  {
    "sample_id": "jr_001_url_shortener_average",
    "problem_id": "jr_001_url_shortener",
    "problem": {
      "title": "축제 홍보용 단축 URL 생성기",
      "scenario": "학생회에서 축제 홍보용 긴 구글 폼 링크를 짧은 URL로 변환하여 배포하려고 합니다. 홍보 문자가 발송되는 시점에 대량의 클릭이 발생합니다.",
      "missions": [
        "초당 수천 건의 읽기 요청을 처리하면서 DB 부하를 최소화하는 구조를 설계하세요.",
        "단축 URL 생성 및 원본 리다이렉션의 데이터 흐름을 다이어그램으로 나타내세요."
      ],
      "constraints": [
        "하루 평균 1,000개 생성, 읽기 요청 초당 최대 1,000건(TPS)",
        "리다이렉션 응답 속도 100ms 이내",
        "생성된 링크는 1년간 영구 보존"
      ]
    },
    "quality_level": "average",
    "expected_score_range": [
      55,
      71
    ],
    "architecture_context": "1. 사용자 인터페이스 (UI): 사용자 입력을 통해 긴 URL을 짧은 URL로 변환하는 웹 페이지.\n2. API 서버: URL 생성 및 리다이렉션 요청을 처리하는 서버.\n3. 데이터베이스: 생성된 URL과 원본 URL의 매핑을 저장하는 데이터베이스.\n4. 캐시 시스템: 자주 조회되는 단축 URL에 대한 응답 속도를 높이기 위한 캐시.\n5. 로드 밸런서: 들어오는 요청을 여러 API 서버에 분산시키기 위한 로드 밸런서.\n\n구성도:\n사용자 인터페이스 <-> API 서버 <-> (캐시 시스템) <-> 데이터베이스\n                |\n            로드 밸런서",
    "user_explanation": "이 시스템 아키텍처는 축제 홍보용 단축 URL 생성기라는 특정 요구 사항을 충족하기 위해 설계되었습니다. 사용자 인터페이스는 학생회가 긴 URL을 입력할 수 있는 직관적인 웹 페이지로 구성되어, 사용자 경험을 용이하게 합니다. API 서버는 모든 URL 생성 및 리다이렉션 요청을 처리하며, 이 서버는 로드 밸런서와 함께 작동하여 많은 동시 요청을 효율적으로 처리할 수 있습니다. \n\n데이터베이스는 생성된 URL과 원본 URL 간의 매핑 정보를 영구적으로 저장하는 역할을 합니다. 데이터베이스의 안정성과 영구성을 고려하여 설계되었습니다. 캐시 시스템은 자주 조회되는 단축 URL에 대한 응답 시간을 단축시켜, 초당 수천 건의 요청을 처리할 때 성능을 향상시키는 데 기여합니다.\n\n마지막으로, 로드 밸런서는 들어오는 트래픽을 여러 API 서버에 균등하게 분산시켜 서버 부하를 최소화하고, 시스템 전반의 신뢰성을 높이는 역할을 합니다. 이러한 구성 요소들은 모두 시스템의 요구 사항을 충족하기 위해 선택되었으며, 신뢰성 있는 URL 생성 및 리다이렉션 서비스를 제공하는 데 적합합니다.",
    "deep_dive_qna": [
      {
        "category": "performance_optimization",
        "question": "초당 1,000건의 리다이렉션 요청에서 캐시 히트율을 높이려면 어떤 전략을 사용해야 할까요?",
        "gap": "캐시 계층의 역할과 위치 이해",
        "answer": "캐시 히트율을 높이기 위해 자주 사용되는 단축 URL을 우선적으로 캐싱하고, 빈번하게 요청되는 URL에 대한 TTL(Time-To-Live)을 적절히 설정하여 캐시의 유효성을 유지하는 전략을 사용할 수 있습니다. 또한, 사용자 행동 분석을 통해 인기 있는 URL 패턴을 예측하고 캐시에 미리 로딩하는 것도 도움이 될 수 있습니다."
      },
      {
        "category": "reliability",
        "question": "캐시 서버가 다운되었을 때 서비스가 어떻게 유지되어야 하나요?",
        "gap": "장애 시 폴백 전략",
        "answer": "캐시 서버가 다운되었을 경우, API 서버는 데이터베이스에 직접 접근하여 원본 URL을 조회할 수 있어야 합니다. 이러한 방식으로 캐시 서버의 의존성을 줄이면서도 서비스의 안정성을 유지할 수 있습니다. 또한, 캐시 서버가 복구되면 데이터베이스에서 가져온 데이터를 다시 캐시에 저장하여 성능을 개선할 수 있습니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "RDBMS",
      "Cache",
      "Redis"
    ],
    "_key_flows": [
      "캐시 → DB 미스 시 조회",
      "Read-through 캐시"
    ]
  },
  {
    "sample_id": "jr_001_url_shortener_poor",
    "problem_id": "jr_001_url_shortener",
    "problem": {
      "title": "축제 홍보용 단축 URL 생성기",
      "scenario": "학생회에서 축제 홍보용 긴 구글 폼 링크를 짧은 URL로 변환하여 배포하려고 합니다. 홍보 문자가 발송되는 시점에 대량의 클릭이 발생합니다.",
      "missions": [
        "초당 수천 건의 읽기 요청을 처리하면서 DB 부하를 최소화하는 구조를 설계하세요.",
        "단축 URL 생성 및 원본 리다이렉션의 데이터 흐름을 다이어그램으로 나타내세요."
      ],
      "constraints": [
        "하루 평균 1,000개 생성, 읽기 요청 초당 최대 1,000건(TPS)",
        "리다이렉션 응답 속도 100ms 이내",
        "생성된 링크는 1년간 영구 보존"
      ]
    },
    "quality_level": "poor",
    "expected_score_range": [
      40,
      54
    ],
    "architecture_context": "- 컴포넌트 목록:\n  1. 웹 서버: 사용자의 요청을 처리하는 서버.\n  2. 데이터베이스: 단축 URL과 원본 URL을 저장하는 데이터 저장소.\n  3. 캐시 서버: 자주 요청되는 URL 정보를 임시로 저장하는 서버.\n  \n- 구성도:\n  사용자 -> 웹 서버 -> 데이터베이스\n                 -> 캐시 서버",
    "user_explanation": "이 설계는 축제 홍보용 단축 URL 생성기 기능을 구현하기 위한 기본적인 구조를 제안합니다. 웹 서버는 사용자의 요청을 처리하는 주체로, 모든 읽기 요청과 URL 생성 요청을 받아들입니다. 데이터베이스는 생성된 단축 URL과 원본 URL을 저장하는 역할을 하며, 사용자가 요청한 단축 URL을 찾기 위해 데이터베이스에 직접 접근해야 합니다.\n\n캐시 서버는 성능 향상을 위해 도입하였으나, 실제로는 사용하지 않을 것입니다. 초당 최대 1,000건의 읽기 요청을 처리하기에는 적절한 캐시 전략이나 TTL 설정이 없기 때문에 캐시 서버의 존재가 오히려 성능 저하를 초래할 것입니다. 또한, 리다이렉션 응답 속도 요구사항인 100ms 이내를 충족하기 위해 필요한 최적화 기법이 구현되어 있지 않습니다. \n\n결과적으로, 이 설계는 핵심 컴포넌트를 포함하고 있지만, 성능 요구사항을 고려하지 않은 비효율적인 구조로 인해 실질적인 요구를 충족하지 못합니다.",
    "deep_dive_qna": [
      {
        "category": "performance_optimization",
        "question": "초당 1,000건의 리다이렉션 요청에서 캐시 히트율을 높이려면 어떤 전략을 사용해야 할까요?",
        "gap": "캐시 계층의 역할과 위치 이해",
        "answer": "캐시 히트율을 높이기 위해 캐시 서버에 더 많은 데이터를 저장해야 합니다. 또한, 사용자가 요청하는 URL을 더 많이 복사해서 캐시 서버에 넣으면 좋을 것 같습니다. 이렇게 하면 자주 요청되는 URL을 빠르게 찾을 수 있을 거예요. 결국, 모든 URL을 캐시에 넣는 것이 가장 좋은 방법일 것 같습니다."
      },
      {
        "category": "reliability",
        "question": "캐시 서버가 다운되었을 때 서비스가 어떻게 유지되어야 하나요?",
        "gap": "장애 시 폴백 전략",
        "answer": "캐시 서버가 다운되면 웹 서버는 데이터베이스에 직접 접근하여 URL 정보를 가져오면 됩니다. 이 경우 성능이 저하될 수 있지만, 서비스 자체는 계속 유지될 것입니다. 캐시 서버가 없더라도 사용자는 여전히 단축 URL을 생성하고 사용할 수 있습니다. 결국 데이터베이스가 항상 작동하고 있기 때문에 큰 문제는 없을 것입니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "RDBMS",
      "Cache",
      "Redis"
    ],
    "_key_flows": [
      "캐시 → DB 미스 시 조회",
      "Read-through 캐시"
    ]
  },
  {
    "sample_id": "jr_001_url_shortener_very_poor",
    "problem_id": "jr_001_url_shortener",
    "problem": {
      "title": "축제 홍보용 단축 URL 생성기",
      "scenario": "학생회에서 축제 홍보용 긴 구글 폼 링크를 짧은 URL로 변환하여 배포하려고 합니다. 홍보 문자가 발송되는 시점에 대량의 클릭이 발생합니다.",
      "missions": [
        "초당 수천 건의 읽기 요청을 처리하면서 DB 부하를 최소화하는 구조를 설계하세요.",
        "단축 URL 생성 및 원본 리다이렉션의 데이터 흐름을 다이어그램으로 나타내세요."
      ],
      "constraints": [
        "하루 평균 1,000개 생성, 읽기 요청 초당 최대 1,000건(TPS)",
        "리다이렉션 응답 속도 100ms 이내",
        "생성된 링크는 1년간 영구 보존"
      ]
    },
    "quality_level": "very_poor",
    "expected_score_range": [
      0,
      39
    ],
    "architecture_context": "1. 웹 서버  \n2. 데이터베이스  \n3. 클라이언트  \n\n구성도:  \n클라이언트 → 웹 서버 → 데이터베이스",
    "user_explanation": "웹 서버는 클라이언트의 요청을 처리하고 데이터베이스는 모든 정보를 저장합니다. 하지만 데이터베이스는 읽기 요청이 많아지면 느려질 수 있으므로, 그냥 기본적인 구조로만 구성했습니다. 별도의 캐시나 부하 분산 장치는 고려하지 않았습니다. 초당 수천 건의 요청을 처리하기 위한 최적화는 하지 않았고, 리다이렉션 속도에 대한 요구사항도 무시했습니다.",
    "deep_dive_qna": [
      {
        "category": "performance_optimization",
        "question": "초당 1,000건의 리다이렉션 요청에서 캐시 히트율을 높이려면 어떤 전략을 사용해야 할까요?",
        "gap": "캐시 계층의 역할과 위치 이해",
        "answer": "캐시를 사용하지 않으면 히트율이 높아질 것입니다. 리다이렉션 요청을 직접 처리하는 것보다 웹 서버를 여러 대 두는 것이 좋습니다. 또한, 데이터베이스의 성능을 무시하고 모든 요청을 데이터베이스로 보내는 것이 효율적입니다."
      },
      {
        "category": "reliability",
        "question": "캐시 서버가 다운되었을 때 서비스가 어떻게 유지되어야 하나요?",
        "gap": "장애 시 폴백 전략",
        "answer": "캐시 서버가 다운되면 서비스가 중단될 것입니다. 클라이언트는 웹 서버에 접근할 수 없게 되고, 데이터베이스도 제대로 작동하지 않을 것입니다. 따라서 사용자는 아무것도 할 수 없게 됩니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "RDBMS",
      "Cache",
      "Redis"
    ],
    "_key_flows": [
      "캐시 → DB 미스 시 조회",
      "Read-through 캐시"
    ]
  },
  {
    "sample_id": "jr_002_pastebin_excellent",
    "problem_id": "jr_002_pastebin",
    "problem": {
      "title": "동아리 에러 로그 공유함 (Pastebin)",
      "scenario": "개발 동아리에서 긴 에러 로그를 텍스트로 업로드하고 링크로 공유하는 서비스를 만듭니다. 텍스트 본문이 매우 커서 일반적인 DB 저장 방식은 한계가 있습니다.",
      "missions": [
        "대용량 텍스트 데이터와 메타데이터의 저장소를 분리하여 설계하세요.",
        "만료된 데이터를 효율적으로 정리하는 컴포넌트를 배치하세요."
      ],
      "constraints": [
        "일일 업로드 5,000건, 조회 50,000건",
        "텍스트 본문 최대 10MB",
        "7일 후 자동 만료 및 삭제 처리"
      ]
    },
    "quality_level": "excellent",
    "expected_score_range": [
      85,
      100
    ],
    "architecture_context": "1. 사용자 인터페이스 (Web Application)\n   - 사용자 로그인을 위한 인증 서비스 (OAuth2)\n   - 에러 로그 업로드 및 조회 화면\n   \n2. API 서버 (Node.js/Express)\n   - 에러 로그 업로드 API\n   - 에러 로그 조회 API\n   \n3. 대용량 텍스트 저장소 (Amazon S3)\n   - 업로드된 에러 로그 텍스트 파일 저장\n   \n4. 메타데이터 저장소 (PostgreSQL)\n   - 에러 로그 메타데이터 저장 (ID, URL, 생성일, 만료일 등)\n   \n5. 메시지 큐 (Apache Kafka)\n   - 업로드된 로그 메타데이터 처리 및 비동기 처리를 위한 큐\n   \n6. 데이터 만료 및 삭제 처리 컴포넌트 (AWS Lambda)\n   - 7일 후 자동 만료 및 삭제 작업 수행\n   \n7. 캐시 서버 (Redis)\n   - 최근 조회된 로그 메타데이터 캐싱 (TTL 1시간)\n   \n8. 모니터링 및 로깅 (Prometheus, Grafana)\n   - 시스템 상태 및 성능 모니터링\n   \n데이터 흐름:\n1. 사용자는 웹 애플리케이션을 통해 에러 로그를 업로드함.\n2. API 서버는 로그를 S3에 저장하고 메타데이터를 PostgreSQL에 기록.\n3. 메타데이터는 Kafka를 통해 비동기적으로 처리됨.\n4. 최근 조회된 메타데이터는 Redis에 캐시됨.\n5. AWS Lambda가 주기적으로 PostgreSQL에서 만료된 데이터를 삭제함.\n6. 사용자는 로그를 조회할 수 있으며, Redis 캐시를 통해 빠른 응답을 받을 수 있음.",
    "user_explanation": "이 아키텍처는 대용량 텍스트 데이터 저장 및 메타데이터 처리를 분리하여 성능과 확장성을 극대화하기 위해 설계되었습니다. Amazon S3는 대규모 파일 저장에 최적화되어 있어 텍스트 로그를 안전하게 저장할 수 있으며, PostgreSQL은 ACID 트랜잭션을 지원하여 메타데이터의 무결성을 보장합니다.\n\nAPI 서버와 메시지 큐인 Kafka를 활용하여 비동기 처리를 통해 업로드와 조회 요청의 성능을 향상시킵니다. Redis 캐시는 최근 조회된 메타데이터를 저장하여 사용자 요청에 대한 응답 속도를 높이고, TTL을 통해 캐시 관리가 용이합니다.\n\nAWS Lambda를 사용하여 만료된 데이터를 자동으로 정리하는 기능은 서버 리소스를 절약하고 관리의 복잡성을 줄입니다. 이 컴포넌트는 주기적으로 PostgreSQL에서 만료된 메타데이터를 삭제하여 데이터베이스의 크기를 유지합니다.\n\n장애 시나리오로는 API 서버의 장애가 발생할 수 있으며, 이 경우 Kafka는 메시지를 잃지 않고 계속 처리할 수 있으므로 데이터 무결성을 유지합니다. 또한, Redis 캐시의 TTL이 만료된 후에는 캐시를 자동으로 갱신하므로 데이터의 최신성을 보장할 수 있습니다. 모니터링 도구를 통해 시스템 상태를 지속적으로 감시하여 장애 발생 시 신속한 대응이 가능하도록 합니다.",
    "deep_dive_qna": [
      {
        "category": "cost_optimization",
        "question": "10MB 텍스트를 RDBMS에 직접 저장하는 대신 Object Storage를 사용하는 이유는 무엇인가요?",
        "gap": "저장소 선택 기준과 비용 효율",
        "answer": "10MB 텍스트를 RDBMS에 직접 저장하는 대신 Object Storage(예: Amazon S3)를 사용하는 이유는 주로 비용 효율성과 확장성 때문입니다. RDBMS는 저장 용량과 성능에 따라 비용이 급격히 증가할 수 있지만, Object Storage는 대량의 데이터를 저렴하게 저장할 수 있으며, 자동으로 확장됩니다. 또한, Object Storage는 대량의 비정형 데이터를 효율적으로 처리하고, 데이터 접근 속도와 내구성을 보장하여, 고가용성을 요구하는 애플리케이션에 적합합니다. 트레이드오프는 RDBMS의 트랜잭션 관리와 데이터 무결성을 이용할 수 없다는 점이며, 대안으로는 NoSQL 데이터베이스를 고려할 수 있지만, 여전히 Object Storage가 비용과 확장성 면에서 우수한 선택이 될 수 있습니다."
      },
      {
        "category": "operational_excellence",
        "question": "7일 만료 데이터를 효율적으로 정리하는 Worker 설계를 구체적으로 설명해주세요.",
        "gap": "배치 작업 및 스케줄링 설계",
        "answer": "7일 만료 데이터를 효율적으로 정리하기 위해, AWS Lambda를 사용하여 서버리스 방식으로 Worker를 구현할 수 있습니다. 이 Worker는 Amazon CloudWatch Events를 통해 매일 실행되어 PostgreSQL에서 만료된 로그의 ID를 조회하고, 해당 ID를 기반으로 S3에서 로그 파일을 삭제한 후, 메타데이터 데이터베이스에서도 삭제 작업을 수행합니다. 이 접근 방식의 장점은 인프라 관리 부담을 줄이고, 필요할 때만 비용을 발생시킬 수 있다는 것입니다. 트레이드오프는 Lambda의 실행 시간 제한(최대 15분)으로 인해 대량의 데이터를 한 번에 처리할 수 없다는 점이 있으며, 이를 해결하기 위해 배치 처리 방식으로 나누어 실행할 수 있습니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "Object Storage",
      "S3",
      "RDBMS",
      "Cleanup Worker"
    ],
    "_key_flows": [
      "본문 → Object Storage",
      "메타데이터 → RDBMS",
      "만료 → Worker 처리"
    ]
  },
  {
    "sample_id": "jr_002_pastebin_good",
    "problem_id": "jr_002_pastebin",
    "problem": {
      "title": "동아리 에러 로그 공유함 (Pastebin)",
      "scenario": "개발 동아리에서 긴 에러 로그를 텍스트로 업로드하고 링크로 공유하는 서비스를 만듭니다. 텍스트 본문이 매우 커서 일반적인 DB 저장 방식은 한계가 있습니다.",
      "missions": [
        "대용량 텍스트 데이터와 메타데이터의 저장소를 분리하여 설계하세요.",
        "만료된 데이터를 효율적으로 정리하는 컴포넌트를 배치하세요."
      ],
      "constraints": [
        "일일 업로드 5,000건, 조회 50,000건",
        "텍스트 본문 최대 10MB",
        "7일 후 자동 만료 및 삭제 처리"
      ]
    },
    "quality_level": "good",
    "expected_score_range": [
      72,
      84
    ],
    "architecture_context": "1. 사용자 인터페이스 (UI)\n2. API 서버\n3. 메타데이터 저장소 (관계형 데이터베이스)\n4. 대용량 텍스트 저장소 (오브젝트 스토리지, 예: AWS S3)\n5. 데이터 정리 컴포넌트 (크론잡 또는 메시지 큐 기반)\n6. 캐시 시스템 (예: Redis)\n\n구성도:\n사용자 인터페이스 → API 서버 → 메타데이터 저장소  \nAPI 서버 ↔ 대용량 텍스트 저장소  \nAPI 서버 → 캐시 시스템  \n데이터 정리 컴포넌트 ↔ 메타데이터 저장소  \n데이터 정리 컴포넌트 ↔ 대용량 텍스트 저장소",
    "user_explanation": "이 시스템 아키텍처는 대용량 에러 로그 데이터의 업로드 및 조회를 효율적으로 처리하기 위해 설계되었습니다. 사용자 인터페이스는 클라이언트와의 상호작용을 담당하며, API 서버는 모든 요청을 처리하여 메타데이터와 대용량 텍스트 데이터 간의 흐름을 관리합니다.\n\n메타데이터 저장소는 관계형 데이터베이스를 사용하여 에러 로그의 메타데이터(예: 로그 ID, 업로드 시간, 만료 시간 등)를 저장합니다. 대용량 텍스트는 오브젝트 스토리지에 저장하여 파일 시스템의 용량 한계를 극복하고, 필요한 경우에만 데이터에 접근할 수 있도록 합니다.\n\n데이터 정리 컴포넌트는 7일 후 만료된 데이터를 자동으로 삭제하여 저장소의 용량을 효율적으로 관리합니다. 이 컴포넌트는 크론잡 또는 메시지 큐를 활용하여 주기적으로 실행되며, 메타데이터와 텍스트 저장소 모두에서 데이터를 정리합니다.\n\n마지막으로, 캐시 시스템을 도입하여 자주 조회되는 데이터를 캐싱함으로써 성능을 향상시키고 API 서버의 부하를 줄입니다. 이 설계는 일일 5,000건의 업로드와 50,000건의 조회를 원활하게 처리할 수 있도록 최적화되었습니다.",
    "deep_dive_qna": [
      {
        "category": "cost_optimization",
        "question": "10MB 텍스트를 RDBMS에 직접 저장하는 대신 Object Storage를 사용하는 이유는 무엇인가요?",
        "gap": "저장소 선택 기준과 비용 효율",
        "answer": "10MB 텍스트를 RDBMS에 직접 저장하는 대신 Object Storage를 사용하는 이유는 주로 비용 효율성과 확장성 때문입니다. Object Storage는 대량의 비정형 데이터를 저장하는 데 최적화되어 있어, 데이터 용량 증가에 따른 저장 비용이 상대적으로 낮고, 데이터 접근 및 관리가 용이합니다. 또한, Object Storage는 높은 가용성과 내구성을 제공하여, 대량의 로그 데이터를 안전하게 저장하고 필요 시 쉽게 접근할 수 있도록 합니다."
      },
      {
        "category": "operational_excellence",
        "question": "7일 만료 데이터를 효율적으로 정리하는 Worker 설계를 구체적으로 설명해주세요.",
        "gap": "배치 작업 및 스케줄링 설계",
        "answer": "7일 만료 데이터를 효율적으로 정리하는 Worker는 주기적으로 메타데이터 저장소에서 만료된 로그 항목을 조회하여 해당 데이터를 식별합니다. 식별된 데이터는 대용량 텍스트 저장소에서 삭제되고, 메타데이터 저장소에서도 관련 기록을 제거하는 방식으로 진행됩니다. 이 과정은 크론잡 또는 메시지 큐를 통해 트리거되어 자동화되며, 정리 작업이 완료되면 캐시 시스템을 업데이트하여 최신 상태를 반영합니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "Object Storage",
      "S3",
      "RDBMS",
      "Cleanup Worker"
    ],
    "_key_flows": [
      "본문 → Object Storage",
      "메타데이터 → RDBMS",
      "만료 → Worker 처리"
    ]
  },
  {
    "sample_id": "jr_002_pastebin_average",
    "problem_id": "jr_002_pastebin",
    "problem": {
      "title": "동아리 에러 로그 공유함 (Pastebin)",
      "scenario": "개발 동아리에서 긴 에러 로그를 텍스트로 업로드하고 링크로 공유하는 서비스를 만듭니다. 텍스트 본문이 매우 커서 일반적인 DB 저장 방식은 한계가 있습니다.",
      "missions": [
        "대용량 텍스트 데이터와 메타데이터의 저장소를 분리하여 설계하세요.",
        "만료된 데이터를 효율적으로 정리하는 컴포넌트를 배치하세요."
      ],
      "constraints": [
        "일일 업로드 5,000건, 조회 50,000건",
        "텍스트 본문 최대 10MB",
        "7일 후 자동 만료 및 삭제 처리"
      ]
    },
    "quality_level": "average",
    "expected_score_range": [
      55,
      71
    ],
    "architecture_context": "1. 클라이언트 애플리케이션: 사용자가 에러 로그를 업로드하고 조회할 수 있는 웹 인터페이스.\n2. 웹 서버: 클라이언트 요청을 처리하고 비즈니스 로직을 수행하는 서버.\n3. 메타데이터 저장소: 에러 로그와 관련된 메타데이터(업로드 시간, 사용자 정보 등)를 저장하는 데이터베이스.\n4. 텍스트 저장소: 대용량 에러 로그 텍스트를 저장하는 시스템. \n5. 데이터 정리 컴포넌트: 만료된 데이터를 자동으로 삭제하는 기능을 담당하는 모듈.\n\n구성도:\n클라이언트 애플리케이션 → 웹 서버 → 메타데이터 저장소\n                                   ↓\n                             텍스트 저장소\n                                   ↓\n                        데이터 정리 컴포넌트",
    "user_explanation": "이 아키텍처는 대량의 에러 로그 데이터를 효과적으로 처리하기 위해 설계되었습니다. 클라이언트 애플리케이션은 사용자가 에러 로그를 업로드하고 조회하는 인터페이스를 제공합니다. 웹 서버는 이 요청을 처리하여 비즈니스 로직을 실행하고, 적절한 컴포넌트와 통신합니다.\n\n메타데이터 저장소는 각 에러 로그에 대한 정보를 효율적으로 관리하기 위해 사용됩니다. 이는 데이터베이스를 통해 업로드 시간, 사용자 정보 등의 메타데이터를 저장하며, 조회 시 빠른 검색을 가능하게 합니다.\n\n대용량 에러 로그 텍스트는 텍스트 저장소에 저장됩니다. 이는 일반적인 데이터베이스의 저장 용량 한계를 극복하기 위해 설계된 시스템으로, 대량의 데이터를 효과적으로 관리할 수 있습니다.\n\n마지막으로, 데이터 정리 컴포넌트는 7일 후에 만료된 데이터를 자동으로 삭제하는 기능을 제공합니다. 이를 통해 저장소의 효율성을 유지하고 불필요한 데이터를 제거하여 시스템 성능을 최적화합니다. 이러한 설계는 전체 시스템의 신뢰성과 효율성을 높이는 데 기여합니다.",
    "deep_dive_qna": [
      {
        "category": "cost_optimization",
        "question": "10MB 텍스트를 RDBMS에 직접 저장하는 대신 Object Storage를 사용하는 이유는 무엇인가요?",
        "gap": "저장소 선택 기준과 비용 효율",
        "answer": "Object Storage를 사용하면 대용량 파일을 효율적으로 저장하고 관리할 수 있으며, RDBMS에 비해 저장 비용이 저렴합니다. 또한, Object Storage는 확장성이 뛰어나고, 대량의 데이터를 다룰 때 성능이 향상됩니다. 이로 인해 에러 로그와 같은 대용량 데이터를 보다 효과적으로 처리할 수 있습니다."
      },
      {
        "category": "operational_excellence",
        "question": "7일 만료 데이터를 효율적으로 정리하는 Worker 설계를 구체적으로 설명해주세요.",
        "gap": "배치 작업 및 스케줄링 설계",
        "answer": "7일 만료 데이터를 효율적으로 정리하는 Worker는 주기적으로 실행되도록 설정할 수 있습니다. 이 Worker는 메타데이터 저장소에서 만료된 로그 항목을 조회하고, 해당 항목의 식별자를 기반으로 텍스트 저장소에서 관련된 로그 데이터를 삭제하는 작업을 수행합니다. 이를 위해 배치 처리 방식으로 데이터를 한 번에 정리하여 성능을 최적화할 수 있습니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "Object Storage",
      "S3",
      "RDBMS",
      "Cleanup Worker"
    ],
    "_key_flows": [
      "본문 → Object Storage",
      "메타데이터 → RDBMS",
      "만료 → Worker 처리"
    ]
  },
  {
    "sample_id": "jr_002_pastebin_poor",
    "problem_id": "jr_002_pastebin",
    "problem": {
      "title": "동아리 에러 로그 공유함 (Pastebin)",
      "scenario": "개발 동아리에서 긴 에러 로그를 텍스트로 업로드하고 링크로 공유하는 서비스를 만듭니다. 텍스트 본문이 매우 커서 일반적인 DB 저장 방식은 한계가 있습니다.",
      "missions": [
        "대용량 텍스트 데이터와 메타데이터의 저장소를 분리하여 설계하세요.",
        "만료된 데이터를 효율적으로 정리하는 컴포넌트를 배치하세요."
      ],
      "constraints": [
        "일일 업로드 5,000건, 조회 50,000건",
        "텍스트 본문 최대 10MB",
        "7일 후 자동 만료 및 삭제 처리"
      ]
    },
    "quality_level": "poor",
    "expected_score_range": [
      40,
      54
    ],
    "architecture_context": "1. 클라이언트 애플리케이션: 사용자 친화적인 인터페이스를 제공하여 에러 로그를 업로드하고 조회할 수 있도록 함.\n2. 단일 데이터베이스: 모든 텍스트 본문과 메타데이터를 하나의 데이터베이스에 저장. (예: MySQL)\n3. 파일 시스템: 에러 로그의 큰 텍스트 파일을 서버의 로컬 파일 시스템에 저장.\n4. 크론잡: 특정 주기로 만료된 데이터를 삭제하는 스크립트를 실행.\n\n구성도:\n- 클라이언트 애플리케이션 ↔ 단일 데이터베이스 (MySQL)\n- 단일 데이터베이스 ↔ 파일 시스템\n- 크론잡 ↔ 단일 데이터베이스",
    "user_explanation": "이 설계는 개발 동아리의 요구사항을 충족시키기 위해 단순한 구조를 선택했습니다. 클라이언트 애플리케이션은 사용자가 에러 로그를 쉽게 업로드하고 조회할 수 있도록 돕습니다. 모든 데이터는 단일 데이터베이스에 저장되며, 이는 관리가 용이할 것이라고 생각했습니다. 그러나 이 방식은 대용량 텍스트 처리에 적합하지 않으며, 성능 저하를 초래할 수 있습니다.\n\n텍스트 데이터는 서버의 로컬 파일 시스템에 저장하여 데이터베이스의 부담을 줄이고자 했습니다. 그러나 이 접근 방식은 데이터 무결성 및 백업 문제를 야기할 수 있습니다. 또한, 크론잡을 사용하여 만료된 데이터를 삭제하도록 설정했지만, 이로 인해 성능이 저하될 위험이 있으며, 효율적인 정리 방식이 아닙니다.\n\n전반적으로 이 설계는 시스템 아키텍처의 핵심 컴포넌트를 간과하고 있으며, 성능 요구사항을 만족시키지 못할 가능성이 큽니다.",
    "deep_dive_qna": [
      {
        "category": "cost_optimization",
        "question": "10MB 텍스트를 RDBMS에 직접 저장하는 대신 Object Storage를 사용하는 이유는 무엇인가요?",
        "gap": "저장소 선택 기준과 비용 효율",
        "answer": "10MB 텍스트를 RDBMS에 저장하는 대신 Object Storage를 사용하면 비용이 더 많이 들기 때문입니다. RDBMS는 대용량 데이터를 효율적으로 처리하는 데 적합하지 않아서 성능이 저하될 수 있습니다. 그래서 파일 시스템에 저장하는 것이 더 나은 선택입니다. Object Storage는 데이터를 더 안전하게 저장할 수 있어서 좋다고 생각합니다."
      },
      {
        "category": "operational_excellence",
        "question": "7일 만료 데이터를 효율적으로 정리하는 Worker 설계를 구체적으로 설명해주세요.",
        "gap": "배치 작업 및 스케줄링 설계",
        "answer": "Worker를 설계할 때, 만료된 데이터를 확인하기 위해 데이터베이스에서 단순히 모든 데이터를 조회한 후 7일 이상 된 로그를 삭제하는 방식으로 진행하면 됩니다. 이 과정에서 파일 시스템에 저장된 로그 파일도 함께 삭제해야 하지만, 파일 이름과 데이터베이스의 매핑이 제대로 되어 있지 않으면 불필요한 파일이 남을 수 있습니다. 또한, 정기적으로 실행되므로 성능 저하가 발생할 수 있는 점은 고려하지 않아도 됩니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "Object Storage",
      "S3",
      "RDBMS",
      "Cleanup Worker"
    ],
    "_key_flows": [
      "본문 → Object Storage",
      "메타데이터 → RDBMS",
      "만료 → Worker 처리"
    ]
  },
  {
    "sample_id": "jr_002_pastebin_very_poor",
    "problem_id": "jr_002_pastebin",
    "problem": {
      "title": "동아리 에러 로그 공유함 (Pastebin)",
      "scenario": "개발 동아리에서 긴 에러 로그를 텍스트로 업로드하고 링크로 공유하는 서비스를 만듭니다. 텍스트 본문이 매우 커서 일반적인 DB 저장 방식은 한계가 있습니다.",
      "missions": [
        "대용량 텍스트 데이터와 메타데이터의 저장소를 분리하여 설계하세요.",
        "만료된 데이터를 효율적으로 정리하는 컴포넌트를 배치하세요."
      ],
      "constraints": [
        "일일 업로드 5,000건, 조회 50,000건",
        "텍스트 본문 최대 10MB",
        "7일 후 자동 만료 및 삭제 처리"
      ]
    },
    "quality_level": "very_poor",
    "expected_score_range": [
      0,
      39
    ],
    "architecture_context": "모든 에러 로그와 메타데이터를 관계형 데이터베이스에 저장합니다. 사용자 요청 시 데이터베이스에서 직접 데이터를 조회하여 제공합니다. 단일 서버에서 모든 기능이 실행되며, 사용자 인터페이스는 간단한 웹 페이지로 구성됩니다.",
    "user_explanation": "저는 모든 데이터를 데이터베이스에 저장하는 것이 가장 효율적이라고 생각합니다. 이렇게 하면 데이터를 쉽게 관리할 수 있고, 사용자들이 빠르게 에러 로그에 접근할 수 있습니다. 복잡한 구조가 필요 없으므로, 단순한 설계가 오히려 더 효과적이라고 믿습니다.",
    "deep_dive_qna": [
      {
        "category": "cost_optimization",
        "question": "10MB 텍스트를 RDBMS에 직접 저장하는 대신 Object Storage를 사용하는 이유는 무엇인가요?",
        "answer": "그냥 DB에 저장하면 됩니다. 큰 파일을 저장하는 데 특별한 이유는 없어요."
      },
      {
        "category": "operational_excellence",
        "question": "7일 만료 데이터를 효율적으로 정리하는 Worker 설계를 구체적으로 설명해주세요.",
        "answer": "그냥 모든 데이터가 DB에 저장되니까, 오래된 데이터는 자동으로 삭제되게 설정하면 됩니다. Worker 같은 거 만들 필요 없이 DB에 쿼리만 날리면 해결됩니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "Object Storage",
      "S3",
      "RDBMS",
      "Cleanup Worker"
    ],
    "_key_flows": [
      "본문 → Object Storage",
      "메타데이터 → RDBMS",
      "만료 → Worker 처리"
    ]
  },
  {
    "sample_id": "jr_003_notification_excellent",
    "problem_id": "jr_003_notification",
    "problem": {
      "title": "오늘의 학식 점심 알림",
      "scenario": "매일 점심 11시 30분에 전교생 1만 명에게 동시에 푸시 알림을 보냅니다. 알림 발송 순간 메인 서버가 멈추는 현상이 발생하고 있습니다.",
      "missions": [
        "트래픽 폭주(Spike)를 완충할 수 있는 비동기 메시징 시스템을 설계하세요.",
        "서버와 발송 로직의 결합도를 낮추는 구조를 그리세요."
      ],
      "constraints": [
        "오전 11:30에 10,000건의 알림 요청 집중",
        "전송에 1~2분 정도의 지연은 허용됨",
        "알림 전송 실패 시 반드시 재시도 로직이 동작해야 함"
      ]
    },
    "quality_level": "excellent",
    "expected_score_range": [
      85,
      100
    ],
    "architecture_context": "1. 사용자 요청 처리 서버 (Application Server)\n2. 비동기 메시징 시스템 (Apache Kafka)\n3. 데이터 저장소 (Redis)\n4. 알림 처리 서버 (Notification Service)\n5. 재시도 로직 (Retry Mechanism)\n6. 모니터링 및 로깅 시스템 (Prometheus, Grafana)\n\n구성도:\n- 사용자 요청 처리 서버는 10,000건의 알림 요청을 수신하여 Kafka에 메시지를 발행합니다.\n- Kafka는 메시지를 큐에 저장하고 알림 처리 서버에 비동기적으로 전달합니다.\n- 알림 처리 서버는 Redis에서 메시지를 가져와 알림을 전송합니다.\n- 알림 전송 실패 시, 재시도 로직이 작동하여 최대 3회까지 재전송을 시도합니다.\n- 모든 과정은 모니터링 시스템을 통해 실시간으로 감시됩니다.",
    "user_explanation": "이 시스템은 고가용성을 목표로 하며, 비동기 메시징 시스템인 Apache Kafka를 통해 사용자 요청과 알림 전송 로직의 결합도를 낮추었습니다. Kafka는 높은 TPS(초당 트랜잭션 수)를 지원하며, 대량의 메시지를 처리할 수 있는 안정성을 제공합니다. Redis는 메시지 캐시 및 상태 저장소로 사용되어 빠른 데이터 접근성을 보장합니다.\n\n사용자 요청 처리 서버는 10,000건의 알림 요청을 수신하고, 이를 Kafka에 발행하여 트래픽 폭주를 완충합니다. 알림 처리 서버는 Kafka에서 메시지를 읽어들여 Redis로부터 필요한 데이터를 가져와 알림을 전송합니다. 전송 실패 시에는 재시도 로직이 활성화되어 최대 3회의 재전송을 시도합니다. 이로 인해 알림 전송의 신뢰성을 높이고, 사용자의 경험을 향상시킵니다.\n\n모니터링 및 로깅 시스템은 Prometheus와 Grafana를 사용하여 시스템 상태 및 성능을 실시간으로 감시합니다. 이 시스템은 장애 발생 시 신속한 대처를 가능하게 하여 전체 시스템의 신뢰성을 높이는 역할을 합니다. 장애 시나리오에서는 Kafka의 메시지 큐가 남아있기 때문에, 알림 처리 서버가 재시작되더라도 이전 요청을 처리할 수 있습니다. Redis의 TTL(Time To Live)을 설정하여 일정 시간이 지나면 메시지를 자동 삭제하도록 하여 메모리 관리를 효율적으로 수행합니다.",
    "deep_dive_qna": [
      {
        "category": "reliability",
        "question": "알림 발송에 실패했을 때 재시도 로직을 어떻게 구현해야 하나요? 중복 발송을 막으려면?",
        "gap": "멱등성과 재시도 전략",
        "answer": "알림 발송에 실패했을 때 재시도 로직은 Kafka의 '오프셋 커밋'을 활용하여 구현할 수 있습니다. 실패한 메시지는 Redis에 저장하여 재시도 횟수를 카운트하고, 최대 재시도 횟수(예: 5회)를 초과하면 해당 메시지를 Dead Letter Queue(DLQ)로 이동시킵니다. 중복 발송을 방지하기 위해 각 메시지에 고유한 ID를 부여하고, Redis에 해당 ID를 키로 하여 발송 여부를 기록함으로써 이미 발송된 메시지를 재처리하지 않도록 합니다. 이 방식은 구현이 간단하고, 메시지의 중복 처리를 효과적으로 관리할 수 있지만, Redis의 저장 공간과 처리 성능을 고려해야 하는 트레이드오프가 있습니다."
      },
      {
        "category": "performance_optimization",
        "question": "Message Queue를 사용하여 트래픽 스파이크를 어떻게 완충하나요?",
        "gap": "비동기 처리와 백프레셔",
        "answer": "Message Queue인 Apache Kafka를 사용하여 트래픽 스파이크를 완충하는 방법은 다음과 같습니다. Kafka는 높은 처리량과 수평 확장을 지원하여, 여러 개의 파티션을 통해 동시 다발적인 메시지를 효과적으로 처리할 수 있습니다. 예를 들어, 각 파티션에 대해 10,000건의 메시지를 처리할 수 있도록 설정하고, 알림 처리 서버를 수평으로 확장하여 동시 처리 능력을 높일 수 있습니다. 트레이드오프로는 메시지 지연이 발생할 수 있으며, 이를 해결하기 위해 Redis를 캐시로 사용하여 최근 요청을 빠르게 처리할 수 있습니다. 대안으로 RabbitMQ와 같은 다른 메시징 시스템도 고려할 수 있지만, Kafka는 대량의 데이터를 처리하는 데 있어 더 높은 성능을 제공합니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "Message Queue",
      "Kafka",
      "RabbitMQ",
      "Notification Worker"
    ],
    "_key_flows": [
      "서버 → 큐 적재",
      "큐 → Worker 소비",
      "실패 → 재시도"
    ]
  },
  {
    "sample_id": "jr_003_notification_good",
    "problem_id": "jr_003_notification",
    "problem": {
      "title": "오늘의 학식 점심 알림",
      "scenario": "매일 점심 11시 30분에 전교생 1만 명에게 동시에 푸시 알림을 보냅니다. 알림 발송 순간 메인 서버가 멈추는 현상이 발생하고 있습니다.",
      "missions": [
        "트래픽 폭주(Spike)를 완충할 수 있는 비동기 메시징 시스템을 설계하세요.",
        "서버와 발송 로직의 결합도를 낮추는 구조를 그리세요."
      ],
      "constraints": [
        "오전 11:30에 10,000건의 알림 요청 집중",
        "전송에 1~2분 정도의 지연은 허용됨",
        "알림 전송 실패 시 반드시 재시도 로직이 동작해야 함"
      ]
    },
    "quality_level": "good",
    "expected_score_range": [
      72,
      84
    ],
    "architecture_context": "1. 메인 서버\n2. 비동기 메시징 시스템 (예: RabbitMQ)\n3. 알림 처리 서비스\n4. 데이터베이스 (예: MySQL)\n\n구성도:\n메인 서버 -> 비동기 메시징 시스템 (RabbitMQ) -> 알림 처리 서비스 -> 데이터베이스",
    "user_explanation": "이번 설계에서는 10,000건의 알림 요청을 효과적으로 처리하기 위해 비동기 메시징 시스템을 도입했습니다. 메인 서버는 알림 요청을 수신하면, 이를 비동기 메시징 시스템인 RabbitMQ에 전송하여 큐에 쌓습니다. 이는 메인 서버와 알림 처리 서비스 간의 결합도를 낮추어 서버가 멈추는 현상을 완화하는 데 기여합니다.\n\n알림 처리 서비스는 RabbitMQ에서 메시지를 소비하여 실제로 푸시 알림을 전송하는 역할을 수행합니다. 이 서비스는 요청을 비동기적으로 처리하므로 대량의 요청이 발생하더라도 시스템의 부담을 줄일 수 있습니다. 또한, 데이터베이스는 알림 전송 상태를 기록하여 재시도 로직이 필요할 경우 이를 기반으로 다시 시도할 수 있도록 합니다. \n\n전송 지연이 1-2분이 허용되기 때문에, 알림 처리 서비스는 일정량의 메시지를 한꺼번에 처리하여 최적의 성능을 유지할 수 있습니다. 실패한 알림 전송의 경우, 알림 처리 서비스는 메시지를 다시 큐에 넣어 재시도를 진행하도록 설계합니다. 이러한 방식으로 시스템의 신뢰성을 높이며, 사용자에게 안정적인 서비스를 제공할 수 있습니다.",
    "deep_dive_qna": [
      {
        "category": "reliability",
        "question": "알림 발송에 실패했을 때 재시도 로직을 어떻게 구현해야 하나요? 중복 발송을 막으려면?",
        "gap": "멱등성과 재시도 전략",
        "answer": "알림 발송에 실패했을 경우, 비동기 메시징 시스템의 재시도 메커니즘을 활용하여 일정 횟수만큼 재전송을 시도할 수 있습니다. 이때 중복 발송을 방지하기 위해 각 알림에 고유한 ID를 부여하고, 데이터베이스에 발송 이력을 기록하여 이미 처리된 알림은 재처리하지 않도록 합니다. 추가적으로, 일정 시간 간격을 두고 재시도를 하여 시스템에 부하를 주지 않도록 조절할 수 있습니다."
      },
      {
        "category": "performance_optimization",
        "question": "Message Queue를 사용하여 트래픽 스파이크를 어떻게 완충하나요?",
        "gap": "비동기 처리와 백프레셔",
        "answer": "Message Queue를 사용하여 트래픽 스파이크를 완충하는 방법은 비동기 처리를 통해 요청을 큐에 저장하고, 이를 순차적으로 처리하는 것입니다. 이로 인해 알림 처리 서비스는 급격한 요청 증가에도 안정적으로 작동할 수 있으며, 시스템의 부하를 분산시켜 성능 저하를 방지합니다. 또한, 큐의 크기를 조정하거나 소비자 인스턴스를 수평 확장하여 처리 능력을 유연하게 조절할 수 있습니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "Message Queue",
      "Kafka",
      "RabbitMQ",
      "Notification Worker"
    ],
    "_key_flows": [
      "서버 → 큐 적재",
      "큐 → Worker 소비",
      "실패 → 재시도"
    ]
  },
  {
    "sample_id": "jr_003_notification_average",
    "problem_id": "jr_003_notification",
    "problem": {
      "title": "오늘의 학식 점심 알림",
      "scenario": "매일 점심 11시 30분에 전교생 1만 명에게 동시에 푸시 알림을 보냅니다. 알림 발송 순간 메인 서버가 멈추는 현상이 발생하고 있습니다.",
      "missions": [
        "트래픽 폭주(Spike)를 완충할 수 있는 비동기 메시징 시스템을 설계하세요.",
        "서버와 발송 로직의 결합도를 낮추는 구조를 그리세요."
      ],
      "constraints": [
        "오전 11:30에 10,000건의 알림 요청 집중",
        "전송에 1~2분 정도의 지연은 허용됨",
        "알림 전송 실패 시 반드시 재시도 로직이 동작해야 함"
      ]
    },
    "quality_level": "average",
    "expected_score_range": [
      55,
      71
    ],
    "architecture_context": "1. 클라이언트 애플리케이션: 사용자에게 알림을 수신하는 모바일 또는 웹 애플리케이션.\n2. 메시지 큐: 알림 요청을 비동기적으로 처리하기 위한 메시징 시스템.\n3. 알림 발송 서버: 메시지 큐로부터 알림 요청을 받아 실제로 푸시 알림을 전송하는 서버.\n4. 데이터베이스: 사용자 정보 및 알림 전송 상태를 기록하는 데이터 저장소.\n5. 재시도 로직: 전송 실패 시 알림을 다시 시도하는 기능을 담당하는 모듈.\n\n구성도:\n클라이언트 애플리케이션 → 메시지 큐 → 알림 발송 서버 → 데이터베이스  \n(알림 발송 서버는 재시도 로직과 연동됨)",
    "user_explanation": "이 설계는 시스템의 신뢰성을 높이고 서버의 부하를 줄이기 위해 비동기 메시징 시스템을 활용하고 있습니다. 클라이언트 애플리케이션은 사용자에게 알림을 전송하기 위해 알림 요청을 생성하며, 이 요청은 메시지 큐를 통해 전달됩니다. 메시지 큐는 요청을 비동기적으로 처리하여 갑작스러운 트래픽 폭주로 인한 서버의 부하를 완화합니다.\n\n알림 발송 서버는 메시지 큐로부터 요청을 수신하고, 이를 처리하여 실제로 푸시 알림을 전송합니다. 이 과정에서 데이터베이스는 사용자 정보를 저장하고, 전송 상태를 기록하여 알림의 성공적인 전송을 추적합니다. 또한, 전송 실패 시에는 재시도 로직이 작동하여 알림을 다시 시도함으로써 신뢰성을 보장합니다.\n\n이러한 구조는 서버와 발송 로직의 결합도를 낮추어 시스템의 유지 보수성과 확장성을 높입니다. 사용자는 알림 전송에 1~2분의 지연이 허용되므로, 시스템은 유연하게 처리할 수 있습니다.",
    "deep_dive_qna": [
      {
        "category": "reliability",
        "question": "알림 발송에 실패했을 때 재시도 로직을 어떻게 구현해야 하나요? 중복 발송을 막으려면?",
        "gap": "멱등성과 재시도 전략",
        "answer": "재시도 로직은 알림 발송 서버에서 실패한 알림 요청을 감지하여 일정한 간격으로 재전송을 시도하는 방식으로 구현할 수 있습니다. 중복 발송을 막기 위해 각 알림 요청에 고유한 식별자를 부여하고, 데이터베이스에서 해당 식별자의 전송 상태를 기록하여 이미 발송된 알림에 대해서는 재전송하지 않도록 하는 방법이 효과적입니다."
      },
      {
        "category": "performance_optimization",
        "question": "Message Queue를 사용하여 트래픽 스파이크를 어떻게 완충하나요?",
        "gap": "비동기 처리와 백프레셔",
        "answer": "메시지 큐를 사용하면 알림 요청을 비동기적으로 처리할 수 있어 트래픽 스파이크에 효과적으로 대응할 수 있습니다. 클라이언트 애플리케이션에서 요청이 발생하면 메시지 큐에 쌓여 일시적으로 처리량을 조절할 수 있어, 알림 발송 서버의 부하를 줄이고 안정성을 높입니다. 이를 통해 시스템이 과부하에 걸리는 상황을 피할 수 있습니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "Message Queue",
      "Kafka",
      "RabbitMQ",
      "Notification Worker"
    ],
    "_key_flows": [
      "서버 → 큐 적재",
      "큐 → Worker 소비",
      "실패 → 재시도"
    ]
  },
  {
    "sample_id": "jr_003_notification_poor",
    "problem_id": "jr_003_notification",
    "problem": {
      "title": "오늘의 학식 점심 알림",
      "scenario": "매일 점심 11시 30분에 전교생 1만 명에게 동시에 푸시 알림을 보냅니다. 알림 발송 순간 메인 서버가 멈추는 현상이 발생하고 있습니다.",
      "missions": [
        "트래픽 폭주(Spike)를 완충할 수 있는 비동기 메시징 시스템을 설계하세요.",
        "서버와 발송 로직의 결합도를 낮추는 구조를 그리세요."
      ],
      "constraints": [
        "오전 11:30에 10,000건의 알림 요청 집중",
        "전송에 1~2분 정도의 지연은 허용됨",
        "알림 전송 실패 시 반드시 재시도 로직이 동작해야 함"
      ]
    },
    "quality_level": "poor",
    "expected_score_range": [
      40,
      54
    ],
    "architecture_context": "- 컴포넌트 목록:\n  1. 메인 서버\n  2. 데이터베이스\n  3. 푸시 알림 서비스\n  4. 클라이언트 디바이스\n\n구성도:\n메인 서버 --> 데이터베이스\n메인 서버 --> 푸시 알림 서비스\n푸시 알림 서비스 --> 클라이언트 디바이스",
    "user_explanation": "이번 설계에서는 주로 메인 서버와 푸시 알림 서비스에 의존하는 구조를 가지고 있습니다. 메인 서버가 모든 요청을 처리하고, 데이터베이스와 직접 연결되어 있어 알림 요청을 저장합니다. 푸시 알림 서비스는 메인 서버와 연결되어 있어, 메인 서버가 요청을 보낸 후 클라이언트 디바이스로 알림을 전송합니다. \n\n이 설계는 성능 요구 사항을 고려하지 않아, 10,000건의 요청이 동시에 들어올 경우 메인 서버가 과부하에 걸려 멈출 수 있습니다. 또한, 푸시 알림 서비스에서 실패한 전송에 대한 재시도 로직이 없기 때문에 알림 전송 실패 시 복구할 방법이 없습니다. 서버와 발송 로직이 강하게 결합되어 있어, 서버에 문제가 생기면 푸시 알림 서비스도 영향을 받습니다. 전체적으로 비효율적이고 신뢰성이 낮은 구조입니다.",
    "deep_dive_qna": [
      {
        "category": "reliability",
        "question": "알림 발송에 실패했을 때 재시도 로직을 어떻게 구현해야 하나요? 중복 발송을 막으려면?",
        "gap": "멱등성과 재시도 전략",
        "answer": "알림 발송에 실패했을 때는 단순히 일정 시간 후에 다시 시도하면 됩니다. 중복 발송을 막기 위해서는 각 알림에 고유한 ID를 부여하고, 이미 발송된 ID를 기록해두면 좋을 것 같습니다. 하지만 이 방법은 완벽하지 않아서 가끔 중복이 발생할 수도 있습니다. 그러니 실패한 알림은 다시 보내면 되고, 그걸로 충분한 것 같습니다."
      },
      {
        "category": "performance_optimization",
        "question": "Message Queue를 사용하여 트래픽 스파이크를 어떻게 완충하나요?",
        "gap": "비동기 처리와 백프레셔",
        "answer": "Message Queue를 사용하면 메인 서버에서 푸시 알림 서비스로의 직접적인 연결을 줄여서 트래픽을 감소시킬 수 있습니다. 이렇게 하면 클라이언트 디바이스로의 알림 전송이 더 원활해지고, 서버의 부하가 줄어듭니다. 하지만, 큐에 쌓인 메시지가 처리되기까지 시간이 걸릴 수 있어 오히려 지연이 발생할 수 있습니다. 결과적으로, 성능 최적화 효과는 제한적일 수 있습니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "Message Queue",
      "Kafka",
      "RabbitMQ",
      "Notification Worker"
    ],
    "_key_flows": [
      "서버 → 큐 적재",
      "큐 → Worker 소비",
      "실패 → 재시도"
    ]
  },
  {
    "sample_id": "jr_003_notification_very_poor",
    "problem_id": "jr_003_notification",
    "problem": {
      "title": "오늘의 학식 점심 알림",
      "scenario": "매일 점심 11시 30분에 전교생 1만 명에게 동시에 푸시 알림을 보냅니다. 알림 발송 순간 메인 서버가 멈추는 현상이 발생하고 있습니다.",
      "missions": [
        "트래픽 폭주(Spike)를 완충할 수 있는 비동기 메시징 시스템을 설계하세요.",
        "서버와 발송 로직의 결합도를 낮추는 구조를 그리세요."
      ],
      "constraints": [
        "오전 11:30에 10,000건의 알림 요청 집중",
        "전송에 1~2분 정도의 지연은 허용됨",
        "알림 전송 실패 시 반드시 재시도 로직이 동작해야 함"
      ]
    },
    "quality_level": "very_poor",
    "expected_score_range": [
      0,
      39
    ],
    "architecture_context": "메인 서버 -> 푸시 알림 기능 -> 데이터베이스",
    "user_explanation": "메인 서버에서 직접 푸시 알림 기능을 처리하도록 하였습니다. 데이터베이스는 알림 요청을 저장하지만, 특별한 비동기 처리나 재시도 로직은 없습니다. 이렇게 설계한 이유는 단순함을 추구했기 때문입니다. 모든 요청을 한꺼번에 처리하도록 하여 서버에 부담을 주는 구조입니다.",
    "deep_dive_qna": [
      {
        "category": "reliability",
        "question": "알림 발송에 실패했을 때 재시도 로직을 어떻게 구현해야 하나요? 중복 발송을 막으려면?",
        "gap": "멱등성과 재시도 전략",
        "answer": "알림 발송이 실패하면 그냥 무시하면 되고, 재시도할 필요는 없습니다. 중복 발송은 서버에서 알림을 한 번만 보내면 자동으로 막힙니다. 데이터베이스에 실패한 기록을 남기지 않으면 더 안전합니다."
      },
      {
        "category": "performance_optimization",
        "question": "Message Queue를 사용하여 트래픽 스파이크를 어떻게 완충하나요?",
        "gap": "비동기 처리와 백프레셔",
        "answer": "메시지 큐를 사용하면 데이터베이스가 느려질 수 있습니다. 대신에 서버를 더 강력하게 만들어서 트래픽을 처리하면 됩니다. 그렇게 하면 알림을 더 빠르게 보낼 수 있습니다."
      }
    ],
    "_required_components": [
      "Web Server",
      "Message Queue",
      "Kafka",
      "RabbitMQ",
      "Notification Worker"
    ],
    "_key_flows": [
      "서버 → 큐 적재",
      "큐 → Worker 소비",
      "실패 → 재시도"
    ]
  },
  {
    "sample_id": "jr_004_image_feed_excellent",
    "problem_id": "jr_004_image_feed",
    "problem": {
      "title": "반려 식물 성장 일기 (이미지 피드)",
      "scenario": "사용자들이 고화질 식물 사진을 업로드하고 피드를 통해 공유합니다. 전 세계 어디서든 사진이 빠르게 로딩되어야 합니다.",
      "missions": [
        "정적 콘텐츠 전송 성능을 극대화하고 서버 부하를 줄이는 캐싱 구조를 설계하세요.",
        "이미지 조회 시 데이터가 흐르는 경로를 최적화하세요."
      ],
      "constraints": [
        "평균 5MB 내외의 고화질 이미지",
        "이미지 로딩 지연 시간 500ms 이내",
        "전 세계 각지에서 동시 접속",
        "원본 서버의 대역폭 사용료 절감 필요"
      ]
    },
    "quality_level": "excellent",
    "expected_score_range": [
      85,
      100
    ],
    "architecture_context": "1. 사용자 디바이스 (모바일/웹)\n2. CDN (Content Delivery Network) - Cloudflare\n3. 이미지 저장소 - AWS S3\n4. 캐시 시스템 - Redis\n5. 메시지 큐 - Apache Kafka\n6. 웹 서버 - NGINX\n7. 데이터베이스 - Amazon RDS (MySQL)\n8. 모니터링 시스템 - Prometheus + Grafana\n\n구성도:\n사용자 디바이스 -> 웹 서버 (NGINX) -> 캐시 시스템 (Redis) -> 이미지 저장소 (AWS S3) <-> 데이터베이스 (Amazon RDS)\n                      -> CDN (Cloudflare) -> 사용자 디바이스",
    "user_explanation": "이 아키텍처는 전 세계 사용자가 고화질 식물 사진을 빠르게 업로드하고 공유할 수 있도록 설계되었습니다. 각 컴포넌트는 성능, 신뢰성, 비용 효율성을 기반으로 선택되었습니다.\n\n1. 사용자 디바이스: 모바일 및 웹 플랫폼을 통해 사진을 업로드하고 피드를 확인합니다. 다양한 디바이스에서 접근 가능하도록 설계되었습니다.\n\n2. CDN (Cloudflare): 이미지 전송 성능을 극대화하기 위해 사용됩니다. 전 세계의 Edge 서버를 활용하여 사용자와 가까운 곳에서 이미지를 제공, 로딩 시간을 최소화합니다. CDN을 통해 이미지가 캐시되어 대역폭 사용료를 절감할 수 있습니다.\n\n3. 이미지 저장소 (AWS S3): 고화질 이미지를 안전하게 저장합니다. S3는 높은 내구성과 가용성을 제공하며, 자동 확장이 가능하므로 대량의 트래픽을 처리할 수 있습니다.\n\n4. 캐시 시스템 (Redis): 자주 요청되는 이미지 메타데이터와 이미지를 캐시하여 데이터베이스와 S3에 대한 요청을 줄입니다. TTL(Time to Live)을 1시간으로 설정하여 최신 이미지를 유지하면서도 캐시 효율성을 극대화합니다.\n\n5. 메시지 큐 (Apache Kafka): 이미지 업로드와 관련된 이벤트를 비동기적으로 처리합니다. 시스템의 확장성을 높이고, 이미지 처리 작업을 분리하여 전반적인 성능을 향상시킵니다.\n\n6. 웹 서버 (NGINX): 정적 파일을 서빙하고, SSL 종료 및 로드 밸런싱을 처리합니다. 높은 동시 접속을 지원하며, 캐싱 설정을 통해 성능을 최적화합니다.\n\n7. 데이터베이스 (Amazon RDS): 사용자 정보와 이미지 메타데이터를 저장합니다. MySQL을 사용하여 ACID 트랜잭션을 보장하며, 장애 발생 시 자동 복구 기능을 제공합니다.\n\n8. 모니터링 시스템 (Prometheus + Grafana): 시스템의 성능을 실시간으로 모니터링하고, 트래픽 및 오류를 추적하여 문제를 조기에 발견하고 대응할 수 있습니다.\n\n장애 시나리오로는 S3의 이미지 접근이 실패하는 경우가 있습니다. 이 경우 Redis의 캐시된 이미지를 먼저 제공하고, 동시에 S3의 상태를 확인하여 자동으로 복구하도록 설정합니다. Kafka를 통해 장애 알림을 시스템 운영팀에 전달하여 신속한 대응이 가능하도록 합니다. 이러한 구조를 통해 성능을 최적화하고 신뢰성을 높이며, 비용 효율성을 유지할 수 있습니다.",
    "deep_dive_qna": [
      {
        "category": "performance_optimization",
        "question": "CDN의 캐시 히트율을 높이려면 어떤 캐시 정책을 사용해야 하나요?",
        "gap": "CDN TTL 설정과 캐시 무효화 전략",
        "answer": "CDN의 캐시 히트율을 높이기 위해서는 'Cache-Control' 헤더를 활용하여 적절한 캐시 정책을 설정하는 것이 중요합니다. 예를 들어, 이미지와 같은 정적 자원에 대해 'max-age'를 1주일(604800초)로 설정하여 장기간 캐싱할 수 있도록 하고, 'immutable' 속성을 추가하여 변경되지 않는 자원임을 명시할 수 있습니다. 또한, 'stale-while-revalidate'와 'stale-if-error'를 통해 만료된 캐시도 일정 시간 동안 사용할 수 있도록 설정하면 사용자 경험이 개선됩니다. 하지만 이러한 설정은 업데이트가 잦은 자원에 불리할 수 있으므로, 자원의 특성에 따라 캐시 정책을 유연하게 조정하는 트레이드오프가 필요합니다."
      },
      {
        "category": "cost_optimization",
        "question": "원본 서버 대역폭 비용을 줄이는 구체적인 방법을 설명해주세요.",
        "gap": "CDN을 통한 오리진 서버 트래픽 절감",
        "answer": "원본 서버 대역폭 비용을 줄이기 위해 CDN을 활용하여 정적 자산(이미지, CSS, JS 파일 등)을 사용자에게 가까운 엣지 서버에서 제공하도록 구성합니다. Cloudflare와 같은 CDN은 전 세계에 분산된 서버를 통해 트래픽을 분산시키고, 대역폭 사용량을 줄여줍니다. 또한, 이미지 압축 및 최적화를 통해 파일 크기를 줄이는 것이 중요하며, 이를 위해 AWS S3에 저장된 이미지를 자동으로 최적화하는 Lambda 함수를 설정할 수 있습니다. 트레이드오프로는 CDN 사용 시 추가 비용이 발생할 수 있으며, 이미지 품질이 떨어질 수 있으므로 적절한 품질 설정이 필요합니다."
      }
    ],
    "_required_components": [
      "Object Storage",
      "CDN",
      "Web Server",
      "Database"
    ],
    "_key_flows": [
      "클라이언트 → CDN",
      "CDN 미스 → Object Storage",
      "지역 엣지 서버 활용"
    ]
  },
  {
    "sample_id": "jr_004_image_feed_good",
    "problem_id": "jr_004_image_feed",
    "problem": {
      "title": "반려 식물 성장 일기 (이미지 피드)",
      "scenario": "사용자들이 고화질 식물 사진을 업로드하고 피드를 통해 공유합니다. 전 세계 어디서든 사진이 빠르게 로딩되어야 합니다.",
      "missions": [
        "정적 콘텐츠 전송 성능을 극대화하고 서버 부하를 줄이는 캐싱 구조를 설계하세요.",
        "이미지 조회 시 데이터가 흐르는 경로를 최적화하세요."
      ],
      "constraints": [
        "평균 5MB 내외의 고화질 이미지",
        "이미지 로딩 지연 시간 500ms 이내",
        "전 세계 각지에서 동시 접속",
        "원본 서버의 대역폭 사용료 절감 필요"
      ]
    },
    "quality_level": "good",
    "expected_score_range": [
      72,
      84
    ],
    "architecture_context": "1. 사용자 인터페이스(UI): 웹/모바일 애플리케이션\n2. CDN(콘텐츠 전송 네트워크): Akamai 또는 Cloudflare\n3. 이미지 저장소: Amazon S3 또는 Google Cloud Storage\n4. 서버: Node.js 또는 Python Flask\n5. 데이터베이스: MongoDB 또는 PostgreSQL\n\n구성도:\n사용자 UI -> CDN -> 이미지 저장소 -> 서버 -> 데이터베이스",
    "user_explanation": "이 아키텍처는 반려 식물 성장 일기 애플리케이션의 이미지 피드를 효율적으로 처리하기 위해 설계되었습니다. 사용자 인터페이스(UI)는 사용자들이 고화질 식물 사진을 업로드하고 피드를 통해 공유할 수 있는 플랫폼입니다. \n\nCDN은 전 세계적으로 분산된 서버를 통해 사용자에게 빠르게 콘텐츠를 제공하는 역할을 합니다. 이를 통해 이미지 로딩 시간을 500ms 이내로 유지하며, 원본 서버의 대역폭 사용료를 줄일 수 있습니다. \n\n이미지 저장소는 Amazon S3 또는 Google Cloud Storage와 같은 클라우드 스토리지 서비스를 사용하여 고화질 이미지를 안전하게 저장하고, 필요할 때마다 CDN을 통해 빠르게 전송합니다. \n\n서버는 Node.js 또는 Python Flask를 사용하여 이미지 업로드, 메타데이터 저장, 사용자 요청 처리 등의 기능을 수행합니다. 마지막으로, 데이터베이스는 MongoDB 또는 PostgreSQL과 같은 비관계형 또는 관계형 데이터베이스를 사용하여 사용자 정보와 이미지 메타데이터를 저장합니다. \n\n이러한 구성 요소들은 함께 작동하여 사용자가 원하는 이미지를 신속하게 제공하고, 전체 시스템의 성능을 극대화합니다.",
    "deep_dive_qna": [
      {
        "category": "performance_optimization",
        "question": "CDN의 캐시 히트율을 높이려면 어떤 캐시 정책을 사용해야 하나요?",
        "gap": "CDN TTL 설정과 캐시 무효화 전략",
        "answer": "CDN의 캐시 히트율을 높이기 위해서는 적절한 캐시 만료 정책을 설정하는 것이 중요합니다. 예를 들어, 이미지 파일과 같은 정적 자원은 상대적으로 긴 TTL(Time To Live)을 설정하여 자주 변경되지 않도록 하고, 자주 업데이트되는 콘텐츠에 대해서는 짧은 TTL을 설정하여 신선도를 유지할 수 있습니다. 또한, Cache-Control 헤더를 활용해 브라우저 캐시와 CDN 캐시 간의 협업을 최적화하는 것이 필요합니다."
      },
      {
        "category": "cost_optimization",
        "question": "원본 서버 대역폭 비용을 줄이는 구체적인 방법을 설명해주세요.",
        "gap": "CDN을 통한 오리진 서버 트래픽 절감",
        "answer": "원본 서버 대역폭 비용을 줄이기 위해 CDN을 활용하여 정적 콘텐츠를 캐싱하고 사용자에게 가까운 서버에서 제공함으로써 원본 서버에 대한 요청을 최소화할 수 있습니다. 또한 이미지 최적화 기술을 사용하여 파일 크기를 줄이고, 필요에 따라 다양한 해상도의 이미지를 제공하여 사용자에게 적합한 크기의 콘텐츠를 전송함으로써 대역폭 사용량을 감소시킬 수 있습니다."
      }
    ],
    "_required_components": [
      "Object Storage",
      "CDN",
      "Web Server",
      "Database"
    ],
    "_key_flows": [
      "클라이언트 → CDN",
      "CDN 미스 → Object Storage",
      "지역 엣지 서버 활용"
    ]
  },
  {
    "sample_id": "jr_004_image_feed_average",
    "problem_id": "jr_004_image_feed",
    "problem": {
      "title": "반려 식물 성장 일기 (이미지 피드)",
      "scenario": "사용자들이 고화질 식물 사진을 업로드하고 피드를 통해 공유합니다. 전 세계 어디서든 사진이 빠르게 로딩되어야 합니다.",
      "missions": [
        "정적 콘텐츠 전송 성능을 극대화하고 서버 부하를 줄이는 캐싱 구조를 설계하세요.",
        "이미지 조회 시 데이터가 흐르는 경로를 최적화하세요."
      ],
      "constraints": [
        "평균 5MB 내외의 고화질 이미지",
        "이미지 로딩 지연 시간 500ms 이내",
        "전 세계 각지에서 동시 접속",
        "원본 서버의 대역폭 사용료 절감 필요"
      ]
    },
    "quality_level": "average",
    "expected_score_range": [
      55,
      71
    ],
    "architecture_context": "1. 클라이언트 애플리케이션\n2. CDN (콘텐츠 전송 네트워크)\n3. 웹 서버\n4. 이미지 저장소\n5. 데이터베이스\n\n구성도:\n클라이언트 애플리케이션 → CDN → 웹 서버 → 이미지 저장소\n                             ↓\n                         데이터베이스",
    "user_explanation": "이 아키텍처는 반려 식물 성장 일기를 위한 효율적인 이미지 전송과 관리를 목표로 합니다. 클라이언트 애플리케이션은 사용자들이 고화질 식물 사진을 업로드하고 조회하는 인터페이스를 제공합니다. 사용자가 사진을 요청할 때, CDN이 중간에서 역할을 하여 전 세계적으로 분산된 서버에서 콘텐츠를 신속하게 제공하게 됩니다. \n\n웹 서버는 수신된 요청을 처리하고, 필요에 따라 이미지 저장소와 데이터베이스에 접근하여 데이터를 관리합니다. 이미지 저장소는 높은 용량의 이미지를 안전하게 저장하고, 빠른 접근을 위해 최적화된 구조를 갖추고 있습니다. 데이터베이스는 사용자 정보와 이미지 메타데이터를 기록하여 관리합니다.\n\n이 구조는 정적 콘텐츠의 전송 성능을 극대화하고, 서버의 부하를 줄이며, 원본 서버의 대역폭 사용료를 절감하는 데 기여할 것입니다. CDN을 사용함으로써 이미지 로딩 시간을 500ms 이내로 유지하고, 전 세계 사용자들이 빠르게 사진을 조회할 수 있도록 합니다.",
    "deep_dive_qna": [
      {
        "category": "performance_optimization",
        "question": "CDN의 캐시 히트율을 높이려면 어떤 캐시 정책을 사용해야 하나요?",
        "gap": "CDN TTL 설정과 캐시 무효화 전략",
        "answer": "CDN의 캐시 히트율을 높이기 위해서는 자주 요청되는 콘텐츠를 우선적으로 캐싱하는 정책을 사용할 수 있습니다. 예를 들어, 인기 있는 이미지나 자주 사용되는 데이터에 대해 TTL(Time to Live)을 설정하여 일정 기간 동안 캐시를 유지하는 것이 효과적입니다. 또한, 콘텐츠의 변경 빈도에 따라 캐시 무효화 전략을 조정하여 업데이트된 정보를 신속하게 반영할 수 있도록 해야 합니다."
      },
      {
        "category": "cost_optimization",
        "question": "원본 서버 대역폭 비용을 줄이는 구체적인 방법을 설명해주세요.",
        "gap": "CDN을 통한 오리진 서버 트래픽 절감",
        "answer": "원본 서버 대역폭 비용을 줄이기 위해 CDN을 활용하여 정적 자산(이미지 등)을 캐싱하면 원본 서버로의 요청을 줄일 수 있습니다. 또한, 이미지 최적화 기술을 적용하여 파일 크기를 줄이고, 필요 없는 대역폭 사용을 최소화하는 것도 효과적입니다. 마지막으로, 사용자가 자주 요청하는 콘텐츠를 미리 CDN에 배포하여 원본 서버에 대한 요청을 더욱 줄일 수 있습니다."
      }
    ],
    "_required_components": [
      "Object Storage",
      "CDN",
      "Web Server",
      "Database"
    ],
    "_key_flows": [
      "클라이언트 → CDN",
      "CDN 미스 → Object Storage",
      "지역 엣지 서버 활용"
    ]
  },
  {
    "sample_id": "jr_004_image_feed_poor",
    "problem_id": "jr_004_image_feed",
    "problem": {
      "title": "반려 식물 성장 일기 (이미지 피드)",
      "scenario": "사용자들이 고화질 식물 사진을 업로드하고 피드를 통해 공유합니다. 전 세계 어디서든 사진이 빠르게 로딩되어야 합니다.",
      "missions": [
        "정적 콘텐츠 전송 성능을 극대화하고 서버 부하를 줄이는 캐싱 구조를 설계하세요.",
        "이미지 조회 시 데이터가 흐르는 경로를 최적화하세요."
      ],
      "constraints": [
        "평균 5MB 내외의 고화질 이미지",
        "이미지 로딩 지연 시간 500ms 이내",
        "전 세계 각지에서 동시 접속",
        "원본 서버의 대역폭 사용료 절감 필요"
      ]
    },
    "quality_level": "poor",
    "expected_score_range": [
      40,
      54
    ],
    "architecture_context": "1. 중앙 서버: 모든 이미지 데이터와 사용자 요청을 처리하는 서버.\n2. 사용자 클라이언트: 사용자들이 이미지를 업로드하고 피드를 확인하는 웹 애플리케이션.\n3. 데이터베이스: 모든 이미지 메타데이터를 저장하는 단순한 관계형 데이터베이스.\n4. CDN (콘텐츠 전송 네트워크): 사용하지 않음.\n5. 캐싱: 이미지 캐싱을 위한 메모리 캐시 시스템을 구현하지 않음.\n6. 로드 밸런서: 사용하지 않음.\n\n구성도:\n사용자 클라이언트 → 중앙 서버 → 데이터베이스",
    "user_explanation": "이 설계는 중앙 서버를 통해 모든 요청을 처리하도록 구성되어 있습니다. 사용자 클라이언트는 중앙 서버에 직접 모든 이미지를 업로드하고, 이미지를 요청할 때도 중앙 서버에서 직접 데이터를 가져오도록 하였습니다. 데이터베이스는 이미지 메타데이터를 저장하는 용도로 사용되며, 이미지 파일 자체는 서버에 저장됩니다.\n\n캐싱은 고려하지 않았으며, CDN을 사용할 필요성도 느끼지 못했습니다. 따라서 모든 사용자가 전 세계 어디서든 직접 중앙 서버에 접근해야 하며, 이는 대역폭 문제를 초래할 수 있습니다. 이미지 로딩 지연 시간도 500ms 이내로 유지되기 어렵고, 성능 저하가 발생할 가능성이 큽니다. 로드 밸런서가 없기 때문에 동시 접속 시 서버 부하가 심해질 수 있습니다. 전체적으로 이 설계는 성능 요구 사항을 무시하고 있으며, 효율적인 데이터 흐름을 고려하지 않은 매우 부족한 아키텍처입니다.",
    "deep_dive_qna": [
      {
        "category": "performance_optimization",
        "question": "CDN의 캐시 히트율을 높이려면 어떤 캐시 정책을 사용해야 하나요?",
        "gap": "CDN TTL 설정과 캐시 무효화 전략",
        "answer": "CDN의 캐시 히트율을 높이기 위해서는 LRU(Least Recently Used) 같은 캐시 정책을 사용하는 것이 좋습니다. 하지만 현재 아키텍처에서는 CDN을 사용하지 않기 때문에 캐시 정책을 적용할 필요가 없습니다. 대신 중앙 서버에서 직접 이미지를 관리하는 것이 더 효율적일 수 있습니다. 캐시 정책은 일반적으로 데이터베이스의 쿼리 최적화와 관련이 있습니다."
      },
      {
        "category": "cost_optimization",
        "question": "원본 서버 대역폭 비용을 줄이는 구체적인 방법을 설명해주세요.",
        "gap": "CDN을 통한 오리진 서버 트래픽 절감",
        "answer": "원본 서버 대역폭 비용을 줄이는 방법으로는 이미지 압축을 고려할 수 있습니다. 이미지를 업로드할 때 해상도를 낮추거나 JPEG 형식으로 변환하는 것이 좋습니다. 또한, 사용자들이 이미지를 업로드할 때 자동으로 리사이즈를 적용하면 대역폭을 절약할 수 있습니다. 하지만 이런 방식은 이미지 품질을 저하시킬 수 있으므로 주의가 필요합니다."
      }
    ],
    "_required_components": [
      "Object Storage",
      "CDN",
      "Web Server",
      "Database"
    ],
    "_key_flows": [
      "클라이언트 → CDN",
      "CDN 미스 → Object Storage",
      "지역 엣지 서버 활용"
    ]
  },
  {
    "sample_id": "jr_004_image_feed_very_poor",
    "problem_id": "jr_004_image_feed",
    "problem": {
      "title": "반려 식물 성장 일기 (이미지 피드)",
      "scenario": "사용자들이 고화질 식물 사진을 업로드하고 피드를 통해 공유합니다. 전 세계 어디서든 사진이 빠르게 로딩되어야 합니다.",
      "missions": [
        "정적 콘텐츠 전송 성능을 극대화하고 서버 부하를 줄이는 캐싱 구조를 설계하세요.",
        "이미지 조회 시 데이터가 흐르는 경로를 최적화하세요."
      ],
      "constraints": [
        "평균 5MB 내외의 고화질 이미지",
        "이미지 로딩 지연 시간 500ms 이내",
        "전 세계 각지에서 동시 접속",
        "원본 서버의 대역폭 사용료 절감 필요"
      ]
    },
    "quality_level": "very_poor",
    "expected_score_range": [
      0,
      39
    ],
    "architecture_context": "- 원본 서버: 모든 이미지 파일을 저장하는 서버  \n- 클라이언트: 사용자가 사진을 업로드하는 모바일 앱  \n- CDN: 콘텐츠를 전 세계에 배포하는 시스템 없음  \n- 데이터베이스: 이미지 메타데이터를 저장하는 데이터베이스",
    "user_explanation": "이 설계는 원본 서버에 모든 이미지 파일을 저장하고, 클라이언트는 직접 서버에 접근하여 이미지를 업로드하고 다운로드하게 됩니다. CDN을 사용하지 않아서 전 세계 사용자들이 빠르게 이미지에 접근할 수 있는 방법이 없습니다. 데이터베이스는 이미지를 찾는 데에 사용되지만, 성능 최적화나 캐싱 구조는 전혀 고려되지 않았습니다. 이렇게 설계하면 서버 부하가 심해지고, 로딩 시간이 500ms를 초과할 가능성이 높습니다.",
    "deep_dive_qna": [
      {
        "category": "performance_optimization",
        "question": "CDN의 캐시 히트율을 높이려면 어떤 캐시 정책을 사용해야 하나요?",
        "gap": "CDN TTL 설정과 캐시 무효화 전략",
        "answer": "CDN의 캐시 히트율을 높이기 위해서는 모든 이미지를 무조건 캐시에 저장하면 됩니다. 이렇게 하면 사용자들이 언제든지 이미지를 빠르게 받을 수 있습니다. 캐시 정책은 중요하지 않으니 신경 쓸 필요가 없습니다."
      },
      {
        "category": "cost_optimization",
        "question": "원본 서버 대역폭 비용을 줄이는 구체적인 방법을 설명해주세요.",
        "gap": "CDN을 통한 오리진 서버 트래픽 절감",
        "answer": "원본 서버의 대역폭 비용을 줄이려면 이미지를 더 작게 만들거나 저화질로 변환하면 됩니다. 또한, 사용자가 사진을 업로드할 때 압축하지 않는 것이 중요합니다. 다른 방법으로는 이미지를 아예 저장하지 않고 그냥 삭제하는 것도 고려할 수 있습니다."
      }
    ],
    "_required_components": [
      "Object Storage",
      "CDN",
      "Web Server",
      "Database"
    ],
    "_key_flows": [
      "클라이언트 → CDN",
      "CDN 미스 → Object Storage",
      "지역 엣지 서버 활용"
    ]
  }
]