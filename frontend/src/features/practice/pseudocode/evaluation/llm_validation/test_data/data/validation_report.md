# 의사코드 트랙 LLM 신뢰성 검증 보고서

- **평가 모델**: gpt-4o
- **검증 규모**: 30개 샘플 × 5회 반복 = **150회 평가**
- **샘플 구성**: 6개 Quest × 5개 품질 레벨 (excellent / good / average / poor / very_poor)
- **최종 결과**: ✅ **전체 통과**

---

## 검증 항목 요약

| 항목 | 결과 | 목표 | 판정 |
|---|---|---|---|
| 일관성 (avg σ) | 2.12 | ≤ 5 | ✅ 통과 |
| 일관성 (max σ) | 4.56 | ≤ 10 | ✅ 통과 |
| 구분력 (점수 격차) | 61.1pt | ≥ 30 | ✅ 통과 |
| 순위 정확도 (Kendall τ) | 0.867 | ≥ 0.75 | ✅ 통과 |
| 수렴 타당도 (Pearson r) | 0.751 | ≥ 0.65 | ✅ 통과 |

---

## 1. 일관성 (Consistency)

동일 샘플을 5회 반복 평가했을 때 점수의 표준편차.

- **평균 σ = 2.12** (목표 ≤ 5) ✅
- **최대 σ = 4.56** (목표 ≤ 10) ✅

| Quest | 품질 | 평균 | σ | 점수 목록 |
|---|---|---|---|---|
| Quest 1 | excellent | 83.0 | 3.74 | 82, 88, 85, 78, 82 |
| Quest 1 | good | 79.2 | 1.79 | 80, 80, 80, 80, 76 |
| Quest 1 | average | 78.6 | 1.95 | 77, 82, 78, 78, 78 |
| Quest 1 | poor | 48.4 | 1.34 | 49, 49, 46, 49, 49 |
| Quest 1 | very_poor | 34.6 | 2.61 | 39, 34, 34, 34, 32 |
| Quest 2 | excellent | 92.0 | 0.00 | 92, 92, 92, 92, 92 |
| Quest 2 | good | 80.0 | 0.00 | 80, 80, 80, 80, 80 |
| Quest 2 | average | 73.6 | 4.45 | 71, 77, 77, 67, 76 |
| Quest 2 | poor | 22.0 | 4.24 | 22, 26, 26, 16, 20 |
| Quest 2 | very_poor | 20.2 | 1.64 | 19, 22, 19, 19, 22 |
| Quest 3 | excellent | 85.6 | 0.89 | 86, 86, 84, 86, 86 |
| Quest 3 | good | 90.8 | 2.68 | 92, 92, 86, 92, 92 |
| Quest 3 | average | 91.2 | 1.79 | 88, 92, 92, 92, 92 |
| Quest 3 | poor | 32.4 | 1.67 | 34, 32, 34, 30, 32 |
| Quest 3 | very_poor | 22.0 | 2.74 | 25, 20, 20, 25, 20 |
| Quest 4 | excellent | 73.6 | 2.61 | 78, 72, 72, 74, 72 |
| Quest 4 | good | 73.2 | 3.63 | 78, 74, 74, 68, 72 |
| Quest 4 | average | 60.6 | 4.56 | 58, 57, 62, 58, 68 |
| Quest 4 | poor | 33.8 | 1.64 | 32, 35, 35, 32, 35 |
| Quest 4 | very_poor | 20.4 | 0.89 | 20, 22, 20, 20, 20 |
| Quest 5 | excellent | 86.0 | 0.00 | 86, 86, 86, 86, 86 |
| Quest 5 | good | 62.2 | 2.49 | 59, 62, 66, 62, 62 |
| Quest 5 | average | 57.8 | 1.79 | 58, 58, 60, 55, 58 |
| Quest 5 | poor | 20.0 | 2.83 | 16, 20, 24, 20, 20 |
| Quest 5 | very_poor | 21.0 | 2.24 | 25, 20, 20, 20, 20 |
| Quest 6 | excellent | 80.8 | 2.49 | 81, 81, 84, 81, 77 |
| Quest 6 | good | 78.6 | 2.07 | 79, 79, 75, 80, 80 |
| Quest 6 | average | 72.8 | 3.90 | 71, 67, 74, 75, 77 |
| Quest 6 | poor | 31.4 | 0.89 | 31, 31, 31, 31, 33 |
| Quest 6 | very_poor | 16.0 | 0.00 | 16, 16, 16, 16, 16 |

---

## 2. 구분력 (Discrimination)

excellent와 very_poor 품질 간 평균 점수 차이.

- **excellent 평균**: 83.5점
- **very_poor 평균**: 22.4점
- **격차**: **61.1pt** (목표 ≥ 30pt) ✅

| 품질 | 평균 점수 | σ |
|---|---|---|
| excellent | 83.5 | 5.6 |
| good | 77.3 | 8.6 |
| average | 72.4 | 11.1 |
| poor | 31.3 | 9.3 |
| very_poor | 22.4 | 5.8 |

---

## 3. 순위 정확도 (Ranking Accuracy) — Kendall's τ

Quest별로 5개 품질 레벨의 평균 점수가 올바른 순서(excellent > good > average > poor > very_poor)인지 확인.

- **평균 τ = 0.867** (목표 ≥ 0.75) ✅
- 완전 정순위: 4/6 Quest

| Quest | 제목 | τ | 실제 순위 | 판정 |
|---|---|---|---|---|
| Quest 1 | 데이터 전처리 누수 방어 시스템 | 1.000 | exce > good > aver > poor > very | ✅ |
| Quest 2 | 과적합 방어 정규화 시스템 | 1.000 | exce > good > aver > poor > very | ✅ |
| Quest 3 | 불균형 데이터 처리 시스템 | 0.400 | **aver > good > exce** > poor > very | ❌ |
| Quest 4 | 피처 엔지니어링 최적화 | 1.000 | exce > good > aver > poor > very | ✅ |
| Quest 5 | 하이퍼파라미터 튜닝 전략 | 0.800 | exce > good > aver > **very > poor** | ✅ |
| Quest 6 | 모델 해석성과 설명가능성 | 1.000 | exce > good > aver > poor > very | ✅ |

> **Quest 3 역전 현상**: 불균형 데이터 처리 문제에서 average(91.2점)가 excellent(85.6점)보다 높게 평가됨.
> SMOTE, AUC-ROC 등 핵심 키워드가 average 샘플에도 포함되어 LLM이 품질 차이를 충분히 구분하지 못한 것으로 보임.
> Quest 5는 very_poor(21.0점)와 poor(20.0점) 점수가 근소하게 역전되었으나 실질적 차이가 거의 없음.

---

## 4. 수렴 타당도 (Convergent Validity) — Pearson r

LLM 평가 점수와 룰 기반(키워드 매칭) 점수 간의 상관관계.

- **Pearson r = 0.751** (목표 ≥ 0.65) ✅
- p-value = 0.000002 (통계적으로 유의)
- 분석 샘플 수: 30

| Quest | r 값 |
|---|---|
| Quest 1 | 0.898 |
| Quest 2 | 0.746 |
| Quest 3 | 0.948 |
| Quest 4 | 0.988 |
| Quest 5 | 0.902 |
| Quest 6 | 0.824 |

---

## 종합 결론

의사코드 트랙의 LLM 평가 시스템(gpt-4o)은 4가지 신뢰성 검증 지표를 **모두 통과**하였습니다.

- 반복 평가 시 점수 변동이 작고 (σ=2.12)
- 품질 레벨 간 점수 차이가 충분히 크며 (61.1pt)
- 품질 순위를 대체로 올바르게 인식하고 (τ=0.867)
- 객관적 기준(룰 기반)과도 잘 일치합니다 (r=0.751)

단, Quest 3 (불균형 데이터 처리)에서 average 샘플이 excellent보다 높은 점수를 받는 이상 현상이 관찰되었습니다. 해당 Quest의 테스트 샘플 품질을 재검토하거나 평가 프롬프트에서 핵심 개념 구분 기준을 보강하는 것을 고려해볼 수 있습니다.
