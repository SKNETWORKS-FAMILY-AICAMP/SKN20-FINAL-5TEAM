# 🦆 PSEUDOCODE Practice Unit (Coduck Wars) 팀 가이드

이 문서는 프로젝트의 핵심인 **의사코드(Pseudocode) 학습 및 평가 시스템**을 팀원들이 이해하고 유지보수하기 위해 작성되었습니다. BUGHUNT의 엄격한 평가 철학을 계승하여 고도화되었습니다.

---

### 1. 시스템 핵심 철학: "공학적 무결성 검증"
단순히 코드를 짜는 법을 배우는 것이 아니라, 데이터 과학 파이프라인에서 발생할 수 있는 **치명적인 설계 오류(예: 데이터 누수)**를 방지하는 사고력을 기르는 데 중점을 둡니다.

### 2. 고도화된 AI 평가 엔진 (Evaluation Logic)
현재 시스템은 **GPT-4o-mini**를 기반으로 하며, 다음과 같은 엄격한 채점 규정을 따릅니다.

#### 📊 5대 평가 지표 (AI 점수 85점 만점 기준)
1.  **Consistency (35점)**: [핵심] 데이터 격리 원칙(Isolation) 준수 여부.
2.  **Design (30점)**: 전체 파이프라인([로드-분리-학습-변환-평가]) 흐름의 공학적 타당성.
3.  **Implementation (10점)**: 표현의 구체성 및 코드 변환 가능성.
4.  **Abstraction (5점)**: 전문 용어(Anchor, Drift 등) 활용 능력.
5.  **Edge Case (5점)**: 예외 상황 고려.

#### 🚫 데이터 누수(Leakage) 차단 룰 (Ceiling Logic)
-   **누수 판정**: `train_test_split` 전에 `fit`을 수행하는 설계를 감지하면 AI는 `self_audit: has_leakage`를 생성합니다.
-   **점수 상한선(Score Ceiling)**: 누수가 판정되면 다른 지표가 완벽하더라도 **전체 점수는 40점을 넘을 수 없습니다.** 이는 일관성 있는 평가를 위한 강력한 제약 사항입니다.

#### 🪞 로직 거울 반사 (Mirroring)
-   AI는 사용자의 의사코드를 '정답'으로 고쳐주지 않습니다.
-   사용자가 틀린 로직을 썼다면, 이를 **틀린 Python 코드로 그대로 변환**하여 피드백(`converted_python`)으로 제공함으로써 학습자가 스스로 실수를 깨닫게 합니다.

---

### 3. 주요 파일구조 및 역할
-   **`CoduckWars.vue`**: 프론트엔드 메인 UI 및 스테이지 흐름(인터뷰 -> 설계 -> 구현 -> 평가) 관리.
-   **`composables/useCoduckWars.js`**: 게임 상태 관리 및 `pseudocodeApi`를 통한 AI 평가 호출.
-   **`data/stages.js`**: 퀘스트 시나리오, 인터뷰 질문, 제공 스니펫 데이터 정의.
-   **`backend/core/views/pseudocode_evaluation.py`**: **[핵심 로직]** 수석 아키텍트 관점의 AI 채점 프롬프트 및 규정 관리.

---

### 4. 관리 및 유지보수 가이드
-   **스테이지 추가 시**: `data/stages.js`에 시나리오를 추가한 후, 반드시 백엔드의 `MISSION_BLUEPRINTS`에도 해당 미션의 제약 조건을 업데이트해야 정밀한 채점이 가능합니다.
-   **평가 기준 조정**: 채점이 너무 짜거나 후하다고 느껴지면 백엔드의 `SYSTEM_PROMPT` 내 배점 수치(pts)를 조정하십시오.
-   **벤치마크 확인**: 최신 모델별 성능 분석 결과는 `backend/evaluation/pseudocode_comparison/results/` 폴더의 보고서들을 참고하십시오.

---
**수정 일자**: 2026.02.15
**수정 내용**: BUGHUNT 스타일의 고도화된 평가 로직 및 일관성 확보 성과 반영
