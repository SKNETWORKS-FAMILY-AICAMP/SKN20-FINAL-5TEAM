import json
import logging
from django.conf import settings
from django.db.models import F
from core.models import UserSolvedProblem, PracticeDetail
import openai

logger = logging.getLogger(__name__)

class VulnerabilityAnalysisService:
    def __init__(self):
        self.client = None
        if settings.OPENAI_API_KEY:
            self.client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)

    def fetch_user_history(self, user_id):
        """
        Retrieves user's solved problems history from different practice areas.
        """
        history = {
            'pseudocode': [],
            'bughunt': [],
            'architecture': []
        }

        # Fetch relevant solved problems
        solved_problems = UserSolvedProblem.objects.filter(
            user_id=user_id
        ).select_related('practice_detail').order_by('solved_date')

        for problem in solved_problems:
            detail_id = problem.practice_detail.id
            data = problem.submitted_data or {}
            score = problem.score
            
            # 1. Pseudocode (Unit 01)
            # Assumption: Pseudocode practice details start with 'unit01'
            if detail_id.startswith('unit01') or 'pseudocode' in str(data):
                history['pseudocode'].append({
                    'id': detail_id,
                    'score': score,
                    'pseudocode': data.get('pseudocode', ''),
                    'evaluation': data.get('evaluation', {}),
                    'is_good': score >= 80
                })

            # 2. BugHunt (Unit 02 or track_type='bughunt')
            elif data.get('track_type') == 'bughunt' or detail_id.startswith('unit02'):
                history['bughunt'].append({
                    'id': detail_id,
                    'mission_id': data.get('mission_id', ''),
                    'score': score,
                    'retry_count': data.get('retry_count', 0),
                    'hint_used': data.get('hint_used', 0),
                    'total_debug_time': data.get('behavior_log', {}).get('total_debug_time_seconds', 0),
                    'step_codes': data.get('step_codes', {})
                })

            # 3. System Architecture (Unit 03 or detail_type='ARCHITECTURE')
            # Assumption: Architecture practice details start with 'unit03'
            elif detail_id.startswith('unit03') or 'architecture' in str(data) or 'mermaid_code' in data:
                 history['architecture'].append({
                    'id': detail_id,
                    'score': score,
                    'user_explanation': data.get('user_explanation', ''),
                    'weaknesses': data.get('evaluation_result', {}).get('weaknesses', []),
                    'suggestions': data.get('evaluation_result', {}).get('suggestions', []),
                    'deep_dive': data.get('deep_dive_answers', [])  # [Added] Rich context from Deep Dive Q&A
                })

        return history

    def format_history_for_llm(self, history):
        """
        Formats the filtered history into a concise text prompt for the LLM.
        """
        prompt_parts = []

        # Pseudocode Analysis
        pseudo_summary = "### [Pseudocode & Logic]\n"
        if history['pseudocode']:
            low_scores = [p for p in history['pseudocode'] if p['score'] < 60]
            pseudo_summary += f"- Total Attempts: {len(history['pseudocode'])}\n"
            pseudo_summary += f"- Low Score Attempts: {len(low_scores)}\n"
            if low_scores:
                pseudo_summary += "- Common Issues in Low Scores: " + ", ".join([str(p.get('evaluation', {}).get('summary', ''))[:50] for p in low_scores[:3]]) + "\n"
        else:
            pseudo_summary += "- No records found.\n"
        prompt_parts.append(pseudo_summary)

        # BugHunt Analysis
        bug_summary = "### [Debugging & Troubleshooting]\n"
        if history['bughunt']:
            total_retries = sum(p['retry_count'] for p in history['bughunt'])
            total_hints = sum(p['hint_used'] for p in history['bughunt'])
            bug_summary += f"- Total Missions: {len(history['bughunt'])}\n"
            bug_summary += f"- Total Retries: {total_retries}\n"
            bug_summary += f"- Total Hints Used: {total_hints}\n"
            # Detect pattern: Reliance on hints?
            if total_hints > len(history['bughunt']): 
                bug_summary += "- Pattern: Frequent reliance on hints.\n"
        else:
            bug_summary += "- No records found.\n"
        prompt_parts.append(bug_summary)

        # Architecture Analysis
        arch_summary = "### [System Architecture Design]\n"
        if history['architecture']:
            weaknesses = []
            for p in history['architecture']:
                weaknesses.extend(p.get('weaknesses', []))
            
            # Dedup and summarize weaknesses
            unique_weaknesses = list(set(weaknesses))[:5]
            arch_summary += f"- Total Designs: {len(history['architecture'])}\n"
            if unique_weaknesses:
                arch_summary += "- Identified Weaknesses:\n  - " + "\n  - ".join(unique_weaknesses) + "\n"
            
            # Add Deep Dive Context (User's specific answers)
            deep_dive_issues = []
            for p in history['architecture']:
                answers = p.get('deep_dive', [])
                if isinstance(answers, list):
                    for ans in answers:
                        # If answer is very short or contains "uncertainty" keywords
                        user_ans = str(ans.get('userAnswer', ''))
                        if len(user_ans) < 20 or any(x in user_ans for x in ['몰라', '모르', '글쎄', 'maybe']):
                             deep_dive_issues.append(f"Q: {ans.get('question')} -> A: {user_ans}")

            if deep_dive_issues:
                arch_summary += "\n- Suspicious Deep Dive Answers (Potential Knowledge Gaps):\n  - " + "\n  - ".join(deep_dive_issues[:3]) + "\n"
        else:
            arch_summary += "- No records found.\n"
        prompt_parts.append(arch_summary)

        return "\n".join(prompt_parts)

    def analyze_vulnerabilities(self, user_id):
        """
        Generates a vulnerability report using LLM.
        """
        if not self.client:
            return {"error": "LLM client not initialized"}

        history = self.fetch_user_history(user_id)
        context = self.format_history_for_llm(history)

        system_prompt = """
        You are a Senior Technical Analyst specialized in Developer Competency Assessment.
        Your goal is to analyze a developer's practice history and identify their "Technical Vulnerabilities".
        
        Vulnerabilities can be:
        1. **Conceptual Gaps**: e.g., "Weak understanding of time complexity", "Ignores database scalability".
        2. **Bad Habits**: e.g., "Relies too heavily on hints", "Writes code without error handling", "Brute-forces debugging".
        3. **Specific Weaknesses**: e.g., "Consistently fails at off-by-one errors", "Struggles with asynchronous logic".

        **CRITICAL INSTRUCTION**: The output MUST be in **Korean** (Hangul).

        Output must be a JSON object with the following structure:
        {
            "summary": "A concise 2-sentence summary of the user's overall technical profile in Korean.",
            "overall_risk_score": 0-100 (Higher means more vulnerable/junior),
            "top_3_vulnerabilities": [
                {
                    "title": "Short title in Korean (e.g., '예외 처리 미흡')",
                    "description": "Explanation of why this is a vulnerability based on the data in Korean.",
                    "severity": "High" | "Medium" | "Low"
                }
            ],
            "recommended_focus_area": "One specific topic to study next in Korean (e.g., '파이썬 예외 처리 패턴')"
        }
        
        Keep the tone professional, constructive, but firm and analytical.
        """

        user_message = f"""
        Analyze the following user practice history data:

        {context}
        
        Based on this data, identify the developer's vulnerabilities.
        """

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                response_format={"type": "json_object"},
                temperature=0.4
            )
            
            content = response.choices[0].message.content
            return json.loads(content)

        except Exception as e:
            logger.error(f"Vulnerability Analysis Failed: {e}")
            return {
                "error": "Failed to analyze vulnerabilities", 
                "details": str(e)
            }
