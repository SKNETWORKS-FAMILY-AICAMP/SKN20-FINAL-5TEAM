# job_planner_view.py
"""
Job Planner Agent - Django REST API
ì›ë³¸ v3.1 ê¸°ë°˜ - URL í¬ë¡¤ë§ ë° ì´ë¯¸ì§€ OCR ì§€ì›
"""
import os
import json
import base64
import traceback
from django.conf import settings

from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import AllowAny
from django.views.decorators.csrf import csrf_exempt
from django.utils.decorators import method_decorator

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import requests
    from bs4 import BeautifulSoup
    import openai
    CRAWLER_AVAILABLE = True
except ImportError:
    CRAWLER_AVAILABLE = False

def _embed_texts(texts: list):
    """OpenAI APIë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”© í›„ L2 ì •ê·œí™”ëœ numpy ë°°ì—´ ë°˜í™˜ (shape: n x dim)"""
    import numpy as np
    import openai as _openai
    client = _openai.OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
    response = client.embeddings.create(model="text-embedding-3-small", input=texts)
    vectors = [item.embedding for item in sorted(response.data, key=lambda x: x.index)]
    arr = np.array(vectors, dtype=np.float32)
    norms = np.linalg.norm(arr, axis=1, keepdims=True)
    return arr / np.maximum(norms, 1e-8)


@method_decorator(csrf_exempt, name='dispatch')
class JobPlannerParseView(APIView):
    """
    ì±„ìš©ê³µê³  íŒŒì‹± API
    - URL í¬ë¡¤ë§
    - ì´ë¯¸ì§€ OCR (OpenAI Vision)
    - í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥
    """
    authentication_classes = []
    permission_classes = [AllowAny]

    def post(self, request):
        input_type = request.data.get('type')  # 'url', 'image', 'text'

        try:
            if input_type == 'url':
                return self._parse_from_url(request)
            elif input_type == 'image':
                return self._parse_from_image(request)
            elif input_type == 'text':
                return self._parse_from_text(request)
            else:
                return Response({
                    "error": "Invalid input type. Use 'url', 'image', or 'text'."
                }, status=status.HTTP_400_BAD_REQUEST)
        except Exception as e:
            print(f"âŒ Parse ì—ëŸ¬: {e}")
            print(traceback.format_exc())
            return Response({
                "error": f"íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _parse_from_url(self, request):
        """
        URL í¬ë¡¤ë§ìœ¼ë¡œ ì±„ìš©ê³µê³  íŒŒì‹± (Collector ì‹œìŠ¤í…œ ì‚¬ìš©)

        Collector ë ˆì´ì–´ë¥¼ í†µí•´ ì±„ìš©ê³µê³  í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì§‘í•œ í›„,
        LLMìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.

        Collector ì‹œìŠ¤í…œ ë‹¨ê³„ë³„ ì„¤ëª…:
        - Phase 1: StaticCollector (requests + BeautifulSoup)
          â†’ ì •ì  HTML í˜ì´ì§€ í¬ë¡¤ë§ (ì„œë²„ì—ì„œ ì™„ì„±ëœ HTMLì„ ë°˜í™˜í•˜ëŠ” ì‚¬ì´íŠ¸)
        - Phase 2+: BrowserCollector, ApiCollector ì¶”ê°€ ì˜ˆì •
          â†’ BrowserCollector: JavaScriptë¡œ ë Œë”ë§ë˜ëŠ” SPA ì‚¬ì´íŠ¸ í¬ë¡¤ë§ (Selenium/Playwright)
          â†’ ApiCollector: ì±„ìš© ì‚¬ì´íŠ¸ ê³µì‹ APIë¥¼ í†µí•œ ë°ì´í„° ìˆ˜ì§‘

        Args:
            request: URLì´ í¬í•¨ëœ HTTP ìš”ì²­ ê°ì²´

        Returns:
            Response: íŒŒì‹±ëœ ì±„ìš©ê³µê³  ì •ë³´ (JSON)
        """
        if not CRAWLER_AVAILABLE:
            return Response({
                "error": "í¬ë¡¤ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        url = request.data.get('url')
        if not url:
            return Response({
                "error": "URLì´ í•„ìš”í•©ë‹ˆë‹¤."
            }, status=status.HTTP_400_BAD_REQUEST)

        try:
            # === Collector ì‹œìŠ¤í…œìœ¼ë¡œ í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ===
            from .collectors import CollectorRouter

            router = CollectorRouter()
            text = router.collect_with_fallback(url)

            # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ê²½ê³ 
            if len(text) < 100:
                print(f"âš ï¸  ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì§§ìŠµë‹ˆë‹¤ ({len(text)}ì). SPA ì‚¬ì´íŠ¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            # LLMìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì±„ìš©ê³µê³  ì •ë³´ ì¶”ì¶œ
            parsed_data = self._extract_job_info_with_llm(text, source='url')

            # íŒŒì‹± ê²°ê³¼ SavedJobPostingì— ì €ì¥
            saved_id = self._save_job_posting(request, parsed_data, source='url', source_url=url)
            if saved_id:
                parsed_data['saved_posting_id'] = saved_id

            return Response(parsed_data, status=status.HTTP_200_OK)

        except Exception as e:
            return Response({
                "error": f"URL íŒŒì‹± ì‹¤íŒ¨: {str(e)}"
            }, status=status.HTTP_400_BAD_REQUEST)

    def _parse_from_image(self, request):
        """ì´ë¯¸ì§€ OCRë¡œ ì±„ìš©ê³µê³  íŒŒì‹± (OpenAI Vision)"""
        image_data = request.data.get('image')  # base64 encoded
        if not image_data:
            return Response({
                "error": "ì´ë¯¸ì§€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }, status=status.HTTP_400_BAD_REQUEST)

        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return Response({
                "error": "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        try:
            client = openai.OpenAI(api_key=api_key)

            # Vision API í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": """ë‹¹ì‹ ì€ IT ì±„ìš©ê³µê³  ì´ë¯¸ì§€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì´ë¯¸ì§€ì—ì„œ ì±„ìš©ê³µê³  ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

ğŸ¯ **í•µì‹¬ ë¯¸ì…˜**: required_skillsì™€ preferred_skills ë°°ì—´ì„ ìµœëŒ€í•œ ë§ì´ ì¶”ì¶œí•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¤‘ìš”í•©ë‹ˆë‹¤!

## ì¶”ì¶œ ì •ë³´:
1. íšŒì‚¬ëª…ê³¼ í¬ì§€ì…˜
2. ì£¼ìš” ì—…ë¬´ (ë‹´ë‹¹í•  ì—…ë¬´, í•˜ê²Œ ë  ì¼)
3. í•„ìˆ˜ ìš”ê±´ (ìê²© ìš”ê±´, í•„ìˆ˜ ì¡°ê±´) - **ì›ë¬¸ ê·¸ëŒ€ë¡œ**
4. ìš°ëŒ€ ì¡°ê±´ (ìš°ëŒ€ ì‚¬í•­, í”ŒëŸ¬ìŠ¤ ìš”ì†Œ) - **ì›ë¬¸ ê·¸ëŒ€ë¡œ**
5. **ê¸°ìˆ  ìŠ¤íƒ (ê°€ì¥ ì¤‘ìš”!)** - í”„ë¡œê·¸ë˜ë° ì–¸ì–´, í”„ë ˆì„ì›Œí¬, ë„êµ¬, DB, í´ë¼ìš°ë“œ ë“± ëª¨ë‘ ì¶”ì¶œ

## ê¸°ìˆ  ìŠ¤íƒ ì¶”ì¶œ ê°€ì´ë“œ:
ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ì—ì„œ ë‹¤ìŒ **ëª¨ë“ ** ê¸°ìˆ ì„ ì°¾ì•„ ë°°ì—´ë¡œ ì¶”ì¶œí•˜ì„¸ìš”:

### ì–¸ì–´
- Python, Java, JavaScript, TypeScript, C++, C#, Go, Kotlin, Swift, Ruby, PHP, Rust, Scala ë“±
- í•œê¸€: íŒŒì´ì¬, ìë°”, ìë°”ìŠ¤í¬ë¦½íŠ¸, íƒ€ì…ìŠ¤í¬ë¦½íŠ¸ â†’ ì˜ë¬¸ìœ¼ë¡œ ë³€í™˜

### í”„ë ˆì„ì›Œí¬/ë¼ì´ë¸ŒëŸ¬ë¦¬
- Django, Flask, FastAPI, Spring, SpringBoot, React, Vue, Angular, Next.js, Node.js, Express ë“±
- í•œê¸€: ì¥ê³ , í”Œë¼ìŠ¤í¬, ìŠ¤í”„ë§, ë¦¬ì•¡íŠ¸, ë·° â†’ ì˜ë¬¸ìœ¼ë¡œ ë³€í™˜

### ë°ì´í„°ë² ì´ìŠ¤
- MySQL, PostgreSQL, MongoDB, Redis, Oracle, MariaDB, Elasticsearch ë“±

### í´ë¼ìš°ë“œ/ì¸í”„ë¼
- AWS, Azure, GCP, Docker, Kubernetes, Jenkins, Linux, Nginx ë“±

### AI/ML/ë°ì´í„°
- TensorFlow, PyTorch, Pandas, NumPy, Spark, Kafka ë“±

### ë„êµ¬
- Git, GitHub, GitLab, Jira, Figma, Postman ë“±

## ì¶”ì¶œ ê·œì¹™:
1. **ë¬¸ì¥ì—ì„œë„ ê¸°ìˆ  ì¶”ì¶œ**: "Pythonê³¼ Djangoë¥¼ í™œìš©í•œ ë°±ì—”ë“œ ê°œë°œ" â†’ ["Python", "Django"]
2. **ë¦¬ìŠ¤íŠ¸ í˜•íƒœë„ ì¶”ì¶œ**: "â€¢ Python\nâ€¢ Django\nâ€¢ PostgreSQL" â†’ ["Python", "Django", "PostgreSQL"]
3. **ì‰¼í‘œ êµ¬ë¶„ë„ ì¶”ì¶œ**: "Python, Django, React ê²½í—˜ì" â†’ ["Python", "Django", "React"]
4. **í•œê¸€ì„ ì˜ë¬¸ìœ¼ë¡œ**: "íŒŒì´ì¬" â†’ "Python", "ì¥ê³ " â†’ "Django"
5. **ë²„ì „ ì œê±°**: "Python 3.x" â†’ "Python", "Django 4.0" â†’ "Django"
6. **ê¸°ìˆ ì´ ì•„ë‹Œ ê²ƒ ì œì™¸**: "íŒ€ì›Œí¬", "ì„±ì‹¤ì„±", "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜", "ì±…ì„ê°" ë“±ì€ ì œì™¸
7. **ìµœì†Œ 3ê°œ ì´ìƒ** ì¶”ì¶œ (ìˆë‹¤ë©´ ìµœëŒ€í•œ ë§ì´)

## JSON í˜•ì‹:
{
  "company_name": "íšŒì‚¬ëª…",
  "position": "í¬ì§€ì…˜ëª…",
  "job_responsibilities": "ì£¼ìš” ì—…ë¬´ ë‚´ìš© (ì›ë¬¸ ê·¸ëŒ€ë¡œ, ì¤„ë°”ê¿ˆ í¬í•¨)",
  "required_qualifications": "í•„ìˆ˜ ìê²© ìš”ê±´ (ì›ë¬¸ ê·¸ëŒ€ë¡œ, ì¤„ë°”ê¿ˆ í¬í•¨)",
  "preferred_qualifications": "ìš°ëŒ€ ì‚¬í•­ (ì›ë¬¸ ê·¸ëŒ€ë¡œ, ì¤„ë°”ê¿ˆ í¬í•¨)",
  "required_skills": ["Python", "Django", "PostgreSQL", "..."],
  "preferred_skills": ["Docker", "AWS", "..."],
  "experience_range": "ì‹ ì…/ê²½ë ¥ (ì˜ˆ: ì‹ ì…, 2-4ë…„, 5ë…„ ì´ìƒ)",
  "deadline": "YYYY-MM-DD ë˜ëŠ” null"
}

## ì˜ˆì‹œ:
ì…ë ¥ í…ìŠ¤íŠ¸: "Python, Djangoë¥¼ í™œìš©í•œ ë°±ì—”ë“œ ê°œë°œ ê²½í—˜ 3ë…„ ì´ìƒ. PostgreSQL ë˜ëŠ” MySQL ì‚¬ìš© ê²½í—˜. Docker ë° AWS ê²½í—˜ì ìš°ëŒ€"
ì¶œë ¥:
{
  "required_skills": ["Python", "Django", "PostgreSQL", "MySQL"],
  "preferred_skills": ["Docker", "AWS"]
}

âš ï¸ **ì¤‘ìš”**: required_skillsì™€ preferred_skills ë°°ì—´ì„ ì ˆëŒ€ ë¹„ì›Œë‘ì§€ ë§ˆì„¸ìš”! ì´ë¯¸ì§€ì—ì„œ ê¸°ìˆ  ìŠ¤íƒì„ ìµœëŒ€í•œ ì°¾ì•„ë‚´ì„¸ìš”!"""
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": image_data  # data:image/jpeg;base64,... í˜•ì‹
                                }
                            }
                        ]
                    }
                ],
                max_tokens=3000,  # 2000 â†’ 3000 (ë” ë§ì€ ì •ë³´ ì¶”ì¶œ)
                temperature=0.2   # 0.3 â†’ 0.2 (ë” ì •í™•í•œ ì¶”ì¶œ)
            )

            content = response.choices[0].message.content

            # JSON ì¶”ì¶œ
            try:
                # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
                if '```json' in content:
                    content = content.split('```json')[1].split('```')[0].strip()
                elif '```' in content:
                    content = content.split('```')[1].split('```')[0].strip()

                parsed_data = json.loads(content)
                parsed_data['source'] = 'image'
                parsed_data['raw_text'] = ''

                # íŒŒì‹± ê²°ê³¼ SavedJobPostingì— ì €ì¥
                saved_id = self._save_job_posting(request, parsed_data, source='image', source_url='')
                if saved_id:
                    parsed_data['saved_posting_id'] = saved_id

                return Response(parsed_data, status=status.HTTP_200_OK)
            except json.JSONDecodeError:
                return Response({
                    "error": "ì´ë¯¸ì§€ì—ì„œ ì±„ìš©ê³µê³  ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "raw_response": content
                }, status=status.HTTP_400_BAD_REQUEST)

        except Exception as e:
            return Response({
                "error": f"Vision API ì˜¤ë¥˜: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _parse_from_text(self, request):
        """í…ìŠ¤íŠ¸ì—ì„œ ì±„ìš©ê³µê³  íŒŒì‹±"""
        text = request.data.get('text')
        if not text:
            return Response({
                "error": "í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }, status=status.HTTP_400_BAD_REQUEST)

        parsed_data = self._extract_job_info_with_llm(text, source='text')

        # íŒŒì‹± ê²°ê³¼ SavedJobPostingì— ì €ì¥
        saved_id = self._save_job_posting(request, parsed_data, source='text', source_url='')
        if saved_id:
            parsed_data['saved_posting_id'] = saved_id

        return Response(parsed_data, status=status.HTTP_200_OK)

    def _save_job_posting(self, request, parsed_data: dict, source: str, source_url: str) -> int | None:
        """
        íŒŒì‹±ëœ ì±„ìš©ê³µê³ ë¥¼ SavedJobPostingì— ì €ì¥í•œë‹¤.
        ì„¸ì…˜ì— user_idê°€ ì—†ìœ¼ë©´ ì €ì¥í•˜ì§€ ì•ŠëŠ”ë‹¤.
        ë™ì¼ ì‚¬ìš©ì + ë™ì¼ URL â†’ update_or_create (ì¤‘ë³µ ì €ì¥ ë°©ì§€)

        Returns:
            ì €ì¥ëœ SavedJobPostingì˜ id (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            from core.models import SavedJobPosting, UserProfile

            # ì„¸ì…˜ì—ì„œ user_id ì¶”ì¶œ
            user_id = request.session.get('user_id') or request.session.get('_auth_user_id')
            if not user_id:
                return None

            user = UserProfile.objects.get(pk=user_id)

            defaults = {
                'company_name': parsed_data.get('company_name', ''),
                'position': parsed_data.get('position', ''),
                'job_responsibilities': parsed_data.get('job_responsibilities', ''),
                'required_qualifications': parsed_data.get('required_qualifications', ''),
                'preferred_qualifications': parsed_data.get('preferred_qualifications', ''),
                'required_skills': parsed_data.get('required_skills', []),
                'preferred_skills': parsed_data.get('preferred_skills', []),
                'experience_range': parsed_data.get('experience_range', ''),
                'deadline': parsed_data.get('deadline'),
                'source': source,
                'raw_text': parsed_data.get('raw_text', ''),
                'parsed_data': {k: v for k, v in parsed_data.items()
                                if k not in ('saved_posting_id',)},
            }

            if source == 'url' and source_url:
                saved, _ = SavedJobPosting.objects.update_or_create(
                    user=user, source_url=source_url, defaults=defaults
                )
            else:
                defaults['source_url'] = ''
                saved = SavedJobPosting.objects.create(user=user, **defaults)

            return saved.id

        except Exception as e:
            print(f"[JobPlanner] SavedJobPosting ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

    def _extract_job_info_with_llm(self, text, source='text'):
        """
        LLMìœ¼ë¡œ ì±„ìš©ê³µê³  ì •ë³´ ì¶”ì¶œ

        ë¹„ì •í˜• í…ìŠ¤íŠ¸ì—ì„œ OpenAI GPTë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ì±„ìš©ê³µê³  ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        íšŒì‚¬ëª…, í¬ì§€ì…˜, ì—…ë¬´ ë‚´ìš©, í•„ìˆ˜/ìš°ëŒ€ ìš”ê±´, ê¸°ìˆ  ìŠ¤íƒ ë“±ì„ JSON í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            text (str): ì±„ìš©ê³µê³  ì›ë¬¸ í…ìŠ¤íŠ¸
            source (str): ë°ì´í„° ì¶œì²˜ ('url', 'text', 'image')

        Returns:
            dict: êµ¬ì¡°í™”ëœ ì±„ìš©ê³µê³  ì •ë³´
        """
        print(f"\nğŸ“„ [LLM íŒŒì‹±] ì…ë ¥ í…ìŠ¤íŠ¸ ({len(text)}ì)")
        print(f"   ì• 500ì: {text[:500]}")

        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            # Fallback: API í‚¤ê°€ ì—†ì„ ë•Œ ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
            return {
                "source": source,
                "raw_text": text,
                "company_name": "ì•Œ ìˆ˜ ì—†ìŒ",
                "position": "ê°œë°œì",
                "job_responsibilities": text[:200] if len(text) > 200 else text,
                "required_qualifications": "ì •ë³´ ì—†ìŒ",
                "preferred_qualifications": "ì •ë³´ ì—†ìŒ",
                "required_skills": [],
                "preferred_skills": [],
                "experience_range": "",
                "deadline": None
            }

        try:
            client = openai.OpenAI(api_key=api_key)

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ì±„ìš©ê³µê³  íŒŒì‹± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ê·œì¹™ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:
1. í…ìŠ¤íŠ¸ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì •ë³´ë§Œ ì¶”ì¶œí•œë‹¤.
2. í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆë¼. ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´("") ë˜ëŠ” ë¹ˆ ë°°ì—´([])ë¡œ ë°˜í™˜í•œë‹¤.
3. ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•œë‹¤."""
                    },
                    {
                        "role": "user",
                        "content": f"""ë‹¤ìŒ ì±„ìš©ê³µê³  í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

{text[:5000]}

ìœ„ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ JSON í‚¤ë¥¼ ì±„ìš°ì„¸ìš”. í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” "" ë˜ëŠ” []ë¡œ ë‘ì„¸ìš”:
- company_name: string
- position: string
- job_responsibilities: string
- required_qualifications: string
- preferred_qualifications: string
- required_skills: array of strings
- preferred_skills: array of strings
- experience_range: string
- deadline: null"""
                    }
                ],
                response_format={"type": "json_object"},
                temperature=0.2,
                max_tokens=2000,
            )

            content = response.choices[0].message.content

            # JSON ì¶”ì¶œ
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0].strip()
            elif '```' in content:
                content = content.split('```')[1].split('```')[0].strip()

            parsed_data = json.loads(content)
            parsed_data['source'] = source
            parsed_data['raw_text'] = text

            # íŒŒì‹± ê²°ê³¼ ë¡œê·¸ ì¶œë ¥
            print(f"\nâœ… [LLM íŒŒì‹± ì™„ë£Œ]")
            print(f"   íšŒì‚¬ëª…: {parsed_data.get('company_name', 'ì—†ìŒ')}")
            print(f"   í¬ì§€ì…˜: {parsed_data.get('position', 'ì—†ìŒ')}")
            print(f"   í•„ìˆ˜ ìŠ¤í‚¬: {len(parsed_data.get('required_skills', []))}ê°œ - {parsed_data.get('required_skills', [])}")
            print(f"   ìš°ëŒ€ ìŠ¤í‚¬: {len(parsed_data.get('preferred_skills', []))}ê°œ - {parsed_data.get('preferred_skills', [])}")
            print(f"   ì£¼ìš” ì—…ë¬´: {len(parsed_data.get('job_responsibilities', ''))}ì - {parsed_data.get('job_responsibilities', '')[:100]}...")
            print(f"   í•„ìˆ˜ ìš”ê±´: {len(parsed_data.get('required_qualifications', ''))}ì - {parsed_data.get('required_qualifications', '')[:100]}...")

            return parsed_data

        except Exception as e:
            print(f"âš ï¸  LLM íŒŒì‹± ì‹¤íŒ¨: {e}")
            # Fallback
            return {
                "source": source,
                "raw_text": text,
                "company_name": "ì•Œ ìˆ˜ ì—†ìŒ",
                "position": "ê°œë°œì",
                "job_responsibilities": text[:200] if len(text) > 200 else text,
                "required_qualifications": "ì •ë³´ ì—†ìŒ",
                "preferred_qualifications": "ì •ë³´ ì—†ìŒ",
                "required_skills": [],
                "preferred_skills": [],
                "experience_range": "",
                "deadline": None
            }


@method_decorator(csrf_exempt, name='dispatch')
class JobPlannerAnalyzeView(APIView):
    """
    ìŠ¤í‚¬ ë§¤ì¹­ ë¶„ì„ API

    ì‚¬ìš©ìì˜ ìŠ¤í‚¬ì…‹ê³¼ ì±„ìš©ê³µê³ ì˜ ìš”êµ¬ ìŠ¤í‚¬ì„ ë¹„êµ ë¶„ì„í•˜ì—¬
    ì¤€ë¹„ë„ ì ìˆ˜, ìŠ¤í‚¬ ê°­, ë§¤ì¹­ ì •ë³´ ë“±ì„ ì œê³µí•©ë‹ˆë‹¤.

    ì£¼ìš” ê¸°ëŠ¥:
    1. 3ë‹¨ê³„ ìŠ¤í‚¬ ë§¤ì¹­ ì‹œìŠ¤í…œ (ì •í™• ì¼ì¹˜ â†’ ë™ì˜ì–´ â†’ ì„ë² ë”© ìœ ì‚¬ë„)
    2. í•œì˜ ìŠ¤í‚¬ ì •ê·œí™” (ì˜ˆ: "íŒŒì´ì¬" â†’ "python")
    3. ì¤€ë¹„ë„ ì ìˆ˜ ê³„ì‚° (ë§¤ì¹­ë¥  + ê²½ë ¥ ì í•©ë„ + ìˆ™ë ¨ë„)
    4. ë§ì¶¤í˜• ì¸ì‚¬ì´íŠ¸ ìƒì„±
    """
    authentication_classes = []
    permission_classes = [AllowAny]

    # í•œì˜ ìŠ¤í‚¬ ë™ì˜ì–´ ì‚¬ì „
    # ë‹¤ì–‘í•œ í‘œê¸°ë¥¼ í†µì¼ëœ í˜•íƒœë¡œ ì •ê·œí™”í•˜ê¸° ìœ„í•œ ë§¤í•‘ í…Œì´ë¸”
    # ì˜ˆ: "íŒŒì´ì¬", "Python", "python" â†’ ëª¨ë‘ "python"ìœ¼ë¡œ í†µì¼
    # ì°¸ê³ : 'python': 'python' ê°™ì€ ì¤‘ë³µì€ ë¶ˆí•„ìš” (_normalize_skillì—ì„œ ìë™ ì²˜ë¦¬)
    SKILL_SYNONYMS = {
        # í”„ë¡œê·¸ë˜ë° ì–¸ì–´
        'íŒŒì´ì¬': 'python',
        'ìë°”': 'java',
        'ìë°”ìŠ¤í¬ë¦½íŠ¸': 'javascript', 'js': 'javascript',
        'íƒ€ì…ìŠ¤í¬ë¦½íŠ¸': 'typescript', 'ts': 'typescript',
        'c++': 'cpp',
        'c#': 'csharp', 'ì”¨ìƒµ': 'csharp',
        'ê³ ': 'go', 'golang': 'go',
        'ì½”í‹€ë¦°': 'kotlin',
        'ìŠ¤ìœ„í”„íŠ¸': 'swift',
        'ë£¨ë¹„': 'ruby',

        # í”„ë ˆì„ì›Œí¬/ë¼ì´ë¸ŒëŸ¬ë¦¬
        'ì¥ê³ ': 'django',
        'í”Œë¼ìŠ¤í¬': 'flask',
        'ìŠ¤í”„ë§': 'spring', 'ìŠ¤í”„ë§ë¶€íŠ¸': 'springboot',
        'ë¦¬ì•¡íŠ¸': 'react', 'reactjs': 'react',
        'ë·°': 'vue', 'vuejs': 'vue',
        'ì•µê·¤ëŸ¬': 'angular',
        'ë…¸ë“œ': 'node', 'nodejs': 'node', 'node.js': 'node',
        'ìµìŠ¤í”„ë ˆìŠ¤': 'express', 'expressjs': 'express',
        'ë„¥ìŠ¤íŠ¸': 'next', 'nextjs': 'next', 'next.js': 'next',
        'ë„¥ìŠ¤íŠ¸ì œì´ì—ìŠ¤': 'next',
        'ë„¥ìŠ¤íŠ¸js': 'next',

        # ë°ì´í„°ë² ì´ìŠ¤
        'ë§ˆì´ì—ìŠ¤íì—˜': 'mysql',
        'í¬ìŠ¤íŠ¸ê·¸ë ˆ': 'postgresql',
        'ëª½ê³ ë””ë¹„': 'mongodb',
        'ë ˆë””ìŠ¤': 'redis',
        'ì˜¤ë¼í´': 'oracle',

        # í´ë¼ìš°ë“œ/ì¸í”„ë¼
        'ì• ì €': 'azure',
        'êµ¬ê¸€í´ë¼ìš°ë“œ': 'gcp',
        'ë„ì»¤': 'docker',
        'ì¿ ë²„ë„¤í‹°ìŠ¤': 'kubernetes', 'k8s': 'kubernetes',

        # AI/ML
        'í…ì„œí”Œë¡œ': 'tensorflow',
        'íŒŒì´í† ì¹˜': 'pytorch',
        'ì¼€ë¼ìŠ¤': 'keras',
        'ì‚¬ì´í‚·ëŸ°': 'sklearn', 'scikit-learn': 'sklearn',

        # ë„êµ¬
        'ê¹ƒ': 'git',
        'ê¹ƒí—ˆë¸Œ': 'github',
        'ì§€ë¼': 'jira',
    }

    def _normalize_skill(self, skill):
        """
        ìŠ¤í‚¬ëª…ì„ ì •ê·œí™” (í•œê¸€->ì˜ì–´, ì†Œë¬¸ì ë³€í™˜)

        ë™ì˜ì–´ ì‚¬ì „ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ í‘œê¸°ë¥¼ í†µì¼ëœ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        ì˜ˆ: "íŒŒì´ì¬" â†’ "python", "ì¥ê³ " â†’ "django", "JS" â†’ "javascript"

        Args:
            skill (str): ì›ë³¸ ìŠ¤í‚¬ëª…

        Returns:
            str: ì •ê·œí™”ëœ ìŠ¤í‚¬ëª… (ì†Œë¬¸ì)
        """
        skill_lower = skill.lower().strip()
        return self.SKILL_SYNONYMS.get(skill_lower, skill_lower)

    def _extract_skills_from_text(self, required_text, preferred_text, responsibilities_text):
        """
        í•„ìˆ˜/ìš°ëŒ€ ìš”ê±´ ë° ì—…ë¬´ í…ìŠ¤íŠ¸ì—ì„œ ê¸°ìˆ  ìŠ¤íƒê³¼ ì—­ëŸ‰ì„ ì¶”ì¶œ
        - ì •ê·œì‹ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì¶”ì¶œ
        - LLM ì—†ì´ë„ ì‘ë™í•˜ë„ë¡ êµ¬í˜„
        """
        import re

        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        full_text = f"{required_text} {preferred_text} {responsibilities_text}"

        # ì•Œë ¤ì§„ ê¸°ìˆ  ìŠ¤íƒ í‚¤ì›Œë“œ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
        tech_keywords = [
            # ì–¸ì–´
            'Python', 'Java', 'JavaScript', 'TypeScript', 'C++', 'C#', 'Go', 'Kotlin',
            'Swift', 'Ruby', 'PHP', 'Rust', 'Scala', 'R',
            'íŒŒì´ì¬', 'ìë°”', 'ìë°”ìŠ¤í¬ë¦½íŠ¸', 'íƒ€ì…ìŠ¤í¬ë¦½íŠ¸', 'ì½”í‹€ë¦°',

            # í”„ë ˆì„ì›Œí¬
            'Django', 'Flask', 'FastAPI', 'Spring', 'SpringBoot', 'React', 'Vue',
            'Angular', 'Next.js', 'Nuxt', 'Express', 'Node.js', 'Nest.js',
            'ì¥ê³ ', 'í”Œë¼ìŠ¤í¬', 'ìŠ¤í”„ë§', 'ë¦¬ì•¡íŠ¸', 'ë·°', 'ì•µê·¤ëŸ¬', 'ë…¸ë“œ',

            # ë°ì´í„°ë² ì´ìŠ¤
            'MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'Oracle', 'MariaDB',
            'SQLite', 'Elasticsearch', 'DynamoDB', 'Cassandra',
            'ë§ˆì´ì—ìŠ¤íì—˜', 'ëª½ê³ ë””ë¹„', 'ë ˆë””ìŠ¤', 'ì˜¤ë¼í´',

            # í´ë¼ìš°ë“œ/ì¸í”„ë¼
            'AWS', 'Azure', 'GCP', 'Docker', 'Kubernetes', 'Jenkins', 'GitLab CI',
            'Terraform', 'Ansible', 'Linux', 'Nginx', 'Apache',
            'ë„ì»¤', 'ì¿ ë²„ë„¤í‹°ìŠ¤', 'ë¦¬ëˆ…ìŠ¤',

            # AI/ML/Data
            'TensorFlow', 'PyTorch', 'Keras', 'scikit-learn', 'Pandas', 'NumPy',
            'Spark', 'Hadoop', 'Airflow', 'Kafka',
            'í…ì„œí”Œë¡œ', 'íŒŒì´í† ì¹˜',

            # ë„êµ¬
            'Git', 'GitHub', 'GitLab', 'Jira', 'Confluence', 'Slack', 'Notion',
            'Figma', 'Postman', 'Swagger',
            'ê¹ƒ', 'ê¹ƒí—ˆë¸Œ', 'ì§€ë¼',

            # ë°©ë²•ë¡ /ê°œë…
            'Agile', 'Scrum', 'Kanban', 'CI/CD', 'DevOps', 'TDD', 'DDD',
            'Microservices', 'REST', 'GraphQL', 'gRPC', 'WebSocket',
            'ì• ìì¼', 'ìŠ¤í¬ëŸ¼', 'ì¹¸ë°˜', 'ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤'
        ]

        found_skills = []

        # ê° í‚¤ì›Œë“œê°€ í…ìŠ¤íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸ (ë‹¨ì–´ ê²½ê³„ ê³ ë ¤)
        for keyword in tech_keywords:
            # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´, ë‹¨ì–´ ê²½ê³„ë¥¼ ê³ ë ¤í•œ ê²€ìƒ‰
            pattern = r'\b' + re.escape(keyword) + r'\b'
            if re.search(pattern, full_text, re.IGNORECASE):
                # ì´ë¯¸ ì¶”ê°€ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì¶”ê°€
                normalized = self._normalize_skill(keyword)
                if normalized not in [self._normalize_skill(s) for s in found_skills]:
                    found_skills.append(keyword)

        # í•„ìˆ˜ì™€ ìš°ëŒ€ êµ¬ë¶„ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        required_found = []
        preferred_found = []

        for skill in found_skills:
            # í•„ìˆ˜ ìš”ê±´ í…ìŠ¤íŠ¸ì— ìˆìœ¼ë©´ í•„ìˆ˜ë¡œ ë¶„ë¥˜
            pattern = r'\b' + re.escape(skill) + r'\b'
            if re.search(pattern, required_text, re.IGNORECASE):
                required_found.append(skill)
            elif re.search(pattern, preferred_text, re.IGNORECASE):
                preferred_found.append(skill)
            else:
                # ì—…ë¬´ ë‚´ìš©ì—ë§Œ ìˆìœ¼ë©´ í•„ìˆ˜ë¡œ ê°„ì£¼
                required_found.append(skill)

        return {
            'required': required_found,
            'preferred': preferred_found
        }

    def post(self, request):
        try:
            # ê¸°ë³¸ í”„ë¡œí•„
            user_skills = request.data.get('user_skills', [])
            skill_levels = request.data.get('skill_levels', {})  # {"Python": 4, "Django": 3}
            experience_years = int(request.data.get('experience_years', 0))

            # ìƒì„¸ í”„ë¡œí•„ (ì„ íƒì‚¬í•­)
            name = request.data.get('name', 'ì§€ì›ì')
            current_role = request.data.get('current_role', '')
            education = request.data.get('education', '')
            certifications = request.data.get('certifications', [])
            career_goals = request.data.get('career_goals', '')
            available_prep_days = request.data.get('available_prep_days', None)

            # ì±„ìš©ê³µê³  ì •ë³´
            required_skills = request.data.get('required_skills', [])
            preferred_skills = request.data.get('preferred_skills', [])
            experience_range = request.data.get('experience_range', '')

            # í•„ìˆ˜/ìš°ëŒ€ ìš”ê±´ ì „ì²´ í…ìŠ¤íŠ¸ (ì¶”ê°€ ì—­ëŸ‰ ì¶”ì¶œìš©)
            required_qualifications = request.data.get('required_qualifications', '')
            preferred_qualifications = request.data.get('preferred_qualifications', '')
            job_responsibilities = request.data.get('job_responsibilities', '')

            if not user_skills:
                return Response({
                    "error": "ì‚¬ìš©ì ìŠ¤í‚¬ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                }, status=status.HTTP_400_BAD_REQUEST)

            # í•„ìˆ˜ ìš”ê±´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ê°€ ìŠ¤í‚¬/ì—­ëŸ‰ ì¶”ì¶œ
            extracted_skills = self._extract_skills_from_text(
                required_qualifications,
                preferred_qualifications,
                job_responsibilities
            )

            # ê¸°ì¡´ ìŠ¤í‚¬ ë°°ì—´ê³¼ ì¶”ì¶œëœ ìŠ¤í‚¬ ê²°í•© (ì¤‘ë³µ ì œê±°)
            all_required_skills = list(set(required_skills + extracted_skills['required']))
            all_preferred_skills = list(set(preferred_skills + extracted_skills['preferred']))

            # ìµœì†Œ 1ê°œ ì´ìƒì˜ í•„ìˆ˜ ìŠ¤í‚¬ì´ ìˆì–´ì•¼ í•¨
            if not all_required_skills:
                all_required_skills = extracted_skills['required'] if extracted_skills['required'] else ['ê°œë°œ ì—­ëŸ‰']

            print(f"ğŸ“Š í•„ìˆ˜ ìŠ¤í‚¬: {len(required_skills)}ê°œ â†’ {len(all_required_skills)}ê°œ (í…ìŠ¤íŠ¸ ë¶„ì„ ì¶”ê°€)")

            # ìŠ¤í‚¬ ì •ê·œí™” (í•œì˜ í†µì¼)
            user_skills_normalized = [self._normalize_skill(s) for s in user_skills]
            required_skills_normalized = [self._normalize_skill(s) for s in all_required_skills]

            matched_skills = []
            missing_skills = []
            matched_indices = set()  # ì´ë¯¸ ë§¤ì¹­ëœ ì‚¬ìš©ì ìŠ¤í‚¬ ì¸ë±ìŠ¤

            # === 3ë‹¨ê³„ ë§¤ì¹­ ì‹œìŠ¤í…œ ===
            # ê° í•„ìˆ˜ ìŠ¤í‚¬ì— ëŒ€í•´ ì‚¬ìš©ì ìŠ¤í‚¬ ì¤‘ ê°€ì¥ ì í•©í•œ ê²ƒì„ ì°¾ìŠµë‹ˆë‹¤.
            # ë‹¨ê³„ë³„ë¡œ ì—„ê²©í•œ ê¸°ì¤€ë¶€í„° ì ìš©í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
            # Stage 1: ì •í™• ì¼ì¹˜ (100% ë§¤ì¹­)
            # Stage 2: ë™ì˜ì–´ ë§¤ì¹­ (95% ë§¤ì¹­)
            # Stage 3: ì„ë² ë”© ìœ ì‚¬ë„ (75%+ ë§¤ì¹­)

            # Stage 3 ë°°ì¹˜ ì„ë² ë”© ìºì‹œ (ë£¨í”„ ì‹œì‘ ì „ì—ëŠ” None, ì²« Stage 3 í•„ìš” ì‹œ ì¼ê´„ ê³„ì‚°)
            user_embeddings_cache = None
            req_embeddings_cache = None

            for i, req_skill in enumerate(all_required_skills):
                req_normalized = required_skills_normalized[i]
                best_match = None
                best_score = 0.0
                best_idx = -1
                match_type = None

                # 1ë‹¨ê³„: ì •í™• ì¼ì¹˜ (ì •ê·œí™” í›„)
                # ì˜ˆ: "Python" vs "python", "íŒŒì´ì¬" vs "Python" (ëª¨ë‘ "python"ìœ¼ë¡œ ì •ê·œí™”ë¨)
                for j, user_skill in enumerate(user_skills):
                    if j in matched_indices:
                        continue  # ì´ë¯¸ ë‹¤ë¥¸ ìŠ¤í‚¬ê³¼ ë§¤ì¹­ëœ ê²½ìš° ìŠ¤í‚µ (1:1 ë§¤ì¹­ ë³´ì¥)
                    user_normalized = user_skills_normalized[j]
                    if user_normalized == req_normalized:
                        best_match = user_skill
                        best_score = 1.0  # ì™„ë²½í•œ ë§¤ì¹­
                        best_idx = j
                        match_type = "exact"
                        break

                # 2ë‹¨ê³„: ë™ì˜ì–´ ë§¤ì¹­ (ì •í™• ì¼ì¹˜ ì‹¤íŒ¨ ì‹œ)
                # ì›ë³¸ ìŠ¤í‚¬ì„ ì •ê·œí™”í–ˆì„ ë•Œ ê°™ì€ ê°’ìœ¼ë¡œ ë³€í™˜ë˜ëŠ”ì§€ í™•ì¸
                # ì˜ˆ: "Node.js" vs "Node", "React" vs "ReactJS"
                if not best_match:
                    for j, user_skill in enumerate(user_skills):
                        if j in matched_indices:
                            continue
                        # ì›ë³¸ ìŠ¤í‚¬ë“¤ì´ ë™ì˜ì–´ ì‚¬ì „ì„ í†µí•´ ê°™ì€ ê°’ìœ¼ë¡œ ì •ê·œí™”ë˜ëŠ”ì§€ ì²´í¬
                        user_original_normalized = self._normalize_skill(user_skill)
                        req_original_normalized = self._normalize_skill(req_skill)

                        # ì •ê·œí™” ì „ì—ëŠ” ë‹¬ëì§€ë§Œ, ì •ê·œí™” í›„ ê°™ì•„ì§€ë©´ ë™ì˜ì–´ë¡œ ê°„ì£¼
                        if user_original_normalized == req_original_normalized and user_skill.lower() != req_skill.lower():
                            best_match = user_skill
                            best_score = 0.95  # ê±°ì˜ ì™„ë²½í•œ ë§¤ì¹­
                            best_idx = j
                            match_type = "synonym"
                            break

                # 3ë‹¨ê³„: ì„ë² ë”© ìœ ì‚¬ë„ (ë†’ì€ threshold)
                # ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ë¥¼ í†µí•´ ê´€ë ¨ ìŠ¤í‚¬ ë§¤ì¹­
                # ì˜ˆ: "Flask" vs "Django" (ë‘˜ ë‹¤ Python ì›¹ í”„ë ˆì„ì›Œí¬)
                if not best_match:
                    # ì²« Stage 3 ì§„ì… ì‹œ ëª¨ë“  ìŠ¤í‚¬ì„ í•œ ë²ˆì— ë°°ì¹˜ ì¸ì½”ë”©
                    if user_embeddings_cache is None:
                        all_texts = user_skills_normalized + required_skills_normalized
                        all_embs = _embed_texts(all_texts)
                        user_embeddings_cache = all_embs[:len(user_skills_normalized)]
                        req_embeddings_cache = all_embs[len(user_skills_normalized):]

                    req_emb = req_embeddings_cache[i:i+1]

                    for j, user_skill in enumerate(user_skills):
                        if j in matched_indices:
                            continue
                        user_emb = user_embeddings_cache[j:j+1]
                        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ì •ê·œí™”ëœ ë²¡í„°ì˜ ë‚´ì )
                        similarity = float((user_emb @ req_emb.T)[0][0])

                        # ë†’ì€ threshold (0.85) - ì •í™•í•œ ë§¤ì¹­ë§Œ í—ˆìš©
                        if similarity >= 0.85 and similarity > best_score:
                            best_match = user_skill
                            best_score = similarity
                            best_idx = j
                            match_type = "similar"

                # ë§¤ì¹­ ê²°ê³¼ ì €ì¥
                if best_match and best_score >= 0.85:  # ìµœì†Œ 85% ìœ ì‚¬ë„ ê¸°ì¤€
                    matched_skills.append({
                        "required": req_skill,        # ì±„ìš©ê³µê³ ì˜ í•„ìˆ˜ ìŠ¤í‚¬
                        "user_skill": best_match,     # ë§¤ì¹­ëœ ì‚¬ìš©ì ìŠ¤í‚¬
                        "similarity": round(best_score, 3),  # ìœ ì‚¬ë„ ì ìˆ˜ (0.85~1.0)
                        "match_type": match_type      # ë§¤ì¹­ ë°©ì‹ (exact/synonym/similar)
                    })
                    matched_indices.add(best_idx)  # ì¤‘ë³µ ë§¤ì¹­ ë°©ì§€
                else:
                    # ë§¤ì¹­ ì‹¤íŒ¨ - missing_skillsì— ì¶”ê°€
                    # ê°€ì¥ ê°€ê¹Œìš´ ìŠ¤í‚¬ì„ ì°¸ê³ ìš©ìœ¼ë¡œ ì €ì¥
                    closest_user = user_skills[0] if user_skills else "ì—†ìŒ"
                    closest_score = 0.0
                    if user_skills and best_idx >= 0:
                        closest_user = user_skills[best_idx] if best_idx < len(user_skills) else user_skills[0]
                        closest_score = best_score

                    missing_skills.append({
                        "required": req_skill,
                        "closest_match": closest_user,
                        "similarity": round(closest_score, 3)
                    })

            # === ì ìˆ˜ ê³„ì‚° ===

            # ë§¤ì¹­ë¥ : í•„ìˆ˜ ìŠ¤í‚¬ ì¤‘ ì–¼ë§ˆë‚˜ ë³´ìœ í•˜ê³  ìˆëŠ”ì§€
            match_rate = len(matched_skills) / len(all_required_skills) if all_required_skills else 0

            # ê²½ë ¥ ì í•©ë„: ìš”êµ¬ ê²½ë ¥ ë²”ìœ„ì™€ ì‚¬ìš©ì ê²½ë ¥ ë¹„êµ
            exp_fit = self._calculate_exp_fit(experience_years, experience_range)

            # ìˆ™ë ¨ë„ ê°€ì¤‘ì¹˜ (ìŠ¤í‚¬ ë ˆë²¨ì´ ìˆìœ¼ë©´ ë°˜ì˜)
            # ë‹¨ìˆœíˆ ìŠ¤í‚¬ì„ ë³´ìœ í•˜ëŠ” ê²ƒë¿ ì•„ë‹ˆë¼ ìˆ™ë ¨ë„ê¹Œì§€ ê³ ë ¤
            proficiency_score = 0.0
            if skill_levels and matched_skills:
                level_sum = 0
                for m in matched_skills:
                    user_skill = m["user_skill"]
                    level = skill_levels.get(user_skill, 3)  # ê¸°ë³¸ê°’ 3 (ì¤‘ê¸‰)
                    level_sum += level
                # í‰ê·  ìˆ™ë ¨ë„ë¥¼ 0.0-1.0 ë²”ìœ„ë¡œ ì •ê·œí™” (1-5 ë ˆë²¨ â†’ 0.2-1.0)
                proficiency_score = round(level_sum / len(matched_skills) / 5.0, 3) if matched_skills else 0.0

            # ì¤€ë¹„ë„ ì ìˆ˜ ê°œì„  (ë” ì§ê´€ì ì¸ ê³„ì‚°)
            # 1. ê¸°ë³¸: ë§¤ì¹­ë¥  (60%)
            # 2. ê²½ë ¥ ì í•©ë„ (25%)
            # 3. ìˆ™ë ¨ë„ (15%)
            base_score = match_rate * 0.60
            exp_score = exp_fit * 0.25
            skill_score = proficiency_score * 0.15 if proficiency_score > 0 else 0

            readiness = round(base_score + exp_score + skill_score, 3)

            # readinessê°€ 1.0ì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡
            readiness = min(readiness, 1.0)

            # skill_gap: ë§¤ì¹­ë˜ì§€ ì•Šì€ ë¹„ìœ¨
            skill_gap = round(1.0 - match_rate, 3)

            # ì¶”ê°€ ì¸ì‚¬ì´íŠ¸
            insights = self._generate_insights(
                name, current_role, education, certifications,
                career_goals, available_prep_days,
                matched_skills, missing_skills, readiness, skill_gap
            )

            return Response({
                "readiness_score": readiness,
                "skill_gap_score": skill_gap,
                "experience_fit": exp_fit,
                "proficiency_score": proficiency_score,
                "matched_skills": matched_skills,
                "missing_skills": missing_skills,
                "insights": insights,
                "profile_summary": {
                    "name": name,
                    "current_role": current_role,
                    "education": education,
                    "certifications": certifications,
                    "career_goals": career_goals,
                    "available_prep_days": available_prep_days
                }
            }, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"âŒ ë¶„ì„ ì—ëŸ¬: {e}")
            print(traceback.format_exc())
            return Response({
                "error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _calculate_exp_fit(self, years, req_range):
        """
        ê²½ë ¥ ì í•©ë„ ê³„ì‚°

        ì±„ìš©ê³µê³ ì˜ ìš”êµ¬ ê²½ë ¥ ë²”ìœ„ì™€ ì‚¬ìš©ìì˜ ê²½ë ¥ì„ ë¹„êµí•˜ì—¬
        ì í•©ë„ë¥¼ 0.0~1.0 ì‚¬ì´ì˜ ì ìˆ˜ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            years (int): ì‚¬ìš©ìì˜ ê²½ë ¥ (ë…„)
            req_range (str): ìš”êµ¬ ê²½ë ¥ ë²”ìœ„ (ì˜ˆ: "3-5ë…„", "5ë…„ ì´ìƒ", "ì‹ ì…")

        Returns:
            float: ê²½ë ¥ ì í•©ë„ ì ìˆ˜ (0.0-1.0)
                - 1.0: ìš”êµ¬ ë²”ìœ„ ë‚´ì— ì •í™•íˆ í¬í•¨
                - 0.7-1.0: ê²½ë ¥ ì´ˆê³¼ (ê²½í—˜ ë§ìŒ)
                - 0.0-1.0: ê²½ë ¥ ë¶€ì¡± (years/lo ë¹„ìœ¨)
        """
        import re
        # ì •ê·œì‹ìœ¼ë¡œ ìˆ«ì ì¶”ì¶œ (ì˜ˆ: "3-5ë…„" â†’ [3, 5], "ì‹ ì…" â†’ [])
        nums = re.findall(r'\d+', req_range)
        if not nums:
            # ìˆ«ì ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¤‘ê°„ ì ìˆ˜ ë°˜í™˜
            return 0.7

        # ìµœì†Œ ê²½ë ¥ê³¼ ìµœëŒ€ ê²½ë ¥ íŒŒì‹±
        lo = int(nums[0])
        hi = int(nums[-1]) if len(nums) > 1 else lo + 2  # ë‹¨ì¼ ìˆ«ìë©´ +2ë…„ ë²”ìœ„

        if lo <= years <= hi:
            # ìš”êµ¬ ë²”ìœ„ ë‚´: ì™„ë²½í•œ ì í•©
            return 1.0
        elif years < lo:
            # ê²½ë ¥ ë¶€ì¡±: ë¹„ìœ¨ë¡œ ê³„ì‚° (ì˜ˆ: 2ë…„ ê²½ë ¥ / 3ë…„ ìš”êµ¬ = 0.67)
            return max(0.0, years / lo)
        else:
            # ê²½ë ¥ ì´ˆê³¼: ì•½ê°„ì˜ ê°ì  (ê²½ë ¥ì´ ë„ˆë¬´ ë§ìœ¼ë©´ ì˜¤ë²„ìŠ¤í™)
            # ì˜ˆ: 8ë…„ ê²½ë ¥, 5ë…„ ìš”êµ¬ â†’ 1.0 - (8-5)*0.05 = 0.85
            return max(0.7, 1.0 - (years - hi) * 0.05)

    def _generate_insights(self, name, current_role, education, certifications,
                          career_goals, available_prep_days,
                          matched_skills, missing_skills, readiness, skill_gap):
        """
        í”„ë¡œí•„ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±

        ì‚¬ìš©ìì˜ í”„ë¡œí•„ ì •ë³´ì™€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ
        ë§ì¶¤í˜• ì¡°ì–¸ê³¼ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            name, current_role, education, certifications: í”„ë¡œí•„ ì •ë³´
            career_goals: ì»¤ë¦¬ì–´ ëª©í‘œ
            available_prep_days: ì¤€ë¹„ ê°€ëŠ¥í•œ ê¸°ê°„ (ì¼)
            matched_skills, missing_skills: ë§¤ì¹­ ê²°ê³¼
            readiness, skill_gap: ì¤€ë¹„ë„ ì ìˆ˜

        Returns:
            list: ì¸ì‚¬ì´íŠ¸ ëª©ë¡ (ê° ì¸ì‚¬ì´íŠ¸ëŠ” type, title, message í¬í•¨)
        """
        insights = []

        # ì¤€ë¹„ë„ ê¸°ë°˜ ì¡°ì–¸
        if readiness >= 0.7:
            insights.append({
                "type": "positive",
                "title": "ë†’ì€ ì¤€ë¹„ë„",
                "message": "í˜„ì¬ ìŠ¤í‚¬ì…‹ì´ ê³µê³  ìš”êµ¬ì‚¬í•­ê³¼ ì˜ ë§ìŠµë‹ˆë‹¤. ìì‹ ê°ì„ ê°–ê³  ì§€ì›í•˜ì„¸ìš”!"
            })
        elif readiness >= 0.5:
            insights.append({
                "type": "neutral",
                "title": "ì¤‘ê°„ ì¤€ë¹„ë„",
                "message": f"ë¶€ì¡±í•œ ìŠ¤í‚¬ {len(missing_skills)}ê°œë¥¼ ë³´ì™„í•˜ë©´ ê²½ìŸë ¥ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤."
            })
        else:
            insights.append({
                "type": "warning",
                "title": "ì¤€ë¹„ í•„ìš”",
                "message": "í•µì‹¬ ìŠ¤í‚¬ ë³´ì™„ì´ í•„ìš”í•©ë‹ˆë‹¤. ìš°ì„ ìˆœìœ„ë¥¼ ì •í•´ ì§‘ì¤‘ì ìœ¼ë¡œ í•™ìŠµí•˜ì„¸ìš”."
            })

        # ì¤€ë¹„ ê¸°ê°„ ì¡°ì–¸
        if available_prep_days:
            days = int(available_prep_days)
            if days < 7 and skill_gap > 0.4:
                insights.append({
                    "type": "warning",
                    "title": "ì‹œê°„ ë¶€ì¡±",
                    "message": f"ì¤€ë¹„ ê¸°ê°„({days}ì¼)ì´ ë¶€ì¡± ìŠ¤í‚¬ ìˆ˜({len(missing_skills)}ê°œ)ì— ë¹„í•´ ì§§ìŠµë‹ˆë‹¤. ê°€ì¥ ì¤‘ìš”í•œ ìŠ¤í‚¬ 1-2ê°œì— ì§‘ì¤‘í•˜ì„¸ìš”."
                })
            elif days >= 30:
                insights.append({
                    "type": "positive",
                    "title": "ì¶©ë¶„í•œ ì¤€ë¹„ ì‹œê°„",
                    "message": f"{days}ì¼ ë™ì•ˆ ì²´ê³„ì ìœ¼ë¡œ í•™ìŠµí•˜ë©´ ì¤€ë¹„ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                })

        # ìê²©ì¦ í™œìš©
        if certifications and len(certifications) > 0:
            insights.append({
                "type": "positive",
                "title": "ìê²©ì¦ ë³´ìœ ",
                "message": f"ë³´ìœ  ìê²©ì¦({', '.join(certifications)})ì„ ì´ë ¥ì„œì™€ ë©´ì ‘ì—ì„œ ì ê·¹ ì–´í•„í•˜ì„¸ìš”."
            })

        # ì»¤ë¦¬ì–´ ëª©í‘œ ì¼ì¹˜ì„±
        if career_goals:
            insights.append({
                "type": "neutral",
                "title": "ì»¤ë¦¬ì–´ ëª©í‘œ í™•ì¸",
                "message": f"ëª©í‘œ({career_goals})ì™€ ì´ í¬ì§€ì…˜ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•˜ì„¸ìš”."
            })

        # í˜„ì¬ ì§ë¬´ì™€ì˜ ì—°ê´€ì„±
        if current_role:
            insights.append({
                "type": "neutral",
                "title": "ê²½ë ¥ ì—°ì†ì„±",
                "message": f"í˜„ì¬ ì§ë¬´({current_role})ì™€ì˜ ì—°ê´€ì„±ì„ ë©´ì ‘ì—ì„œ ê°•ì¡°í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤."
            })

        return insights


@method_decorator(csrf_exempt, name='dispatch')
class JobPlannerAgentQuestionsView(APIView):
    """
    ë™ì  ì§ˆë¬¸ ìƒì„± API

    ë¶€ì¡±í•œ ìŠ¤í‚¬ì— ëŒ€í•´ LLMì„ í™œìš©í•˜ì—¬ ë§ì¶¤í˜• ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ í˜„ì¬ ìˆ˜ì¤€, í•™ìŠµ ê³„íš, ì‹¤ë¬´ ê²½í—˜ ë“±ì„ íŒŒì•…í•˜ê¸° ìœ„í•œ
    êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì§ˆë¬¸ì„ ì œê³µí•©ë‹ˆë‹¤.

    ì£¼ìš” ê¸°ëŠ¥:
    - ë¶€ì¡±í•œ ìŠ¤í‚¬ë³„ ë§ì¶¤ ì§ˆë¬¸ ìƒì„± (ìµœëŒ€ 5ê°œ)
    - êµ¬ì²´ì  ê²½í—˜ íŒŒì•… ì§ˆë¬¸
    - í•™ìŠµ ì¤€ë¹„ë„ í™•ì¸ ì§ˆë¬¸
    - ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„± í‰ê°€ ì§ˆë¬¸
    """
    authentication_classes = []
    permission_classes = [AllowAny]

    def post(self, request):
        try:
            missing_skills = request.data.get('missing_skills', [])
            matched_skills = request.data.get('matched_skills', [])
            user_profile = request.data.get('user_profile', {})

            if not missing_skills:
                return Response({
                    "questions": [],
                    "message": "ë¶€ì¡±í•œ ìŠ¤í‚¬ì´ ì—†ì–´ ì¶”ê°€ ì§ˆë¬¸ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                }, status=status.HTTP_200_OK)

            # LLMìœ¼ë¡œ ë™ì  ì§ˆë¬¸ ìƒì„±
            questions = self._generate_questions_with_llm(
                missing_skills, matched_skills, user_profile
            )

            return Response({
                "questions": questions,
                "total_questions": len(questions)
            }, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ìƒì„± ì—ëŸ¬: {e}")
            print(traceback.format_exc())
            return Response({
                "error": f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _generate_questions_with_llm(self, missing_skills, matched_skills, user_profile):
        """LLMìœ¼ë¡œ ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„±"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            # Fallback: ê¸°ë³¸ ì§ˆë¬¸
            return [
                {
                    "id": f"q_{i}",
                    "skill": skill['required'],
                    "question": f"{skill['required']}ì— ëŒ€í•œ ê²½í—˜ì´ë‚˜ í•™ìŠµ ê³„íšì„ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                    "type": "text",
                    "required": True
                }
                for i, skill in enumerate(missing_skills[:3])
            ]

        try:
            client = openai.OpenAI(api_key=api_key)

            # ìµœëŒ€ 5ê°œ ìŠ¤í‚¬ê¹Œì§€ë§Œ ì§ˆë¬¸ ìƒì„±
            skills_to_ask = missing_skills[:5]

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ IT ì±„ìš© ë° ì»¤ë¦¬ì–´ ì „ë¬¸ ì½”ì¹˜ì…ë‹ˆë‹¤.
ë¶€ì¡±í•œ ìŠ¤í‚¬ì— ëŒ€í•´ ì‹¤ì œ ê²½í—˜ê³¼ ì¤€ë¹„ ìƒíƒœë¥¼ íŒŒì•…í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.

**ì§ˆë¬¸ ìƒì„± ì›ì¹™**:
1. êµ¬ì²´ì  ê²½í—˜ íŒŒì•…: "í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•œ ê²½í—˜", "ë¬¸ì œ í•´ê²° ì‚¬ë¡€" ë“±
2. í•™ìŠµ ì¤€ë¹„ë„ í™•ì¸: "í˜„ì¬ í•™ìŠµ ì¤‘", "í•™ìŠµ ê³„íš", "ì˜ˆìƒ ì†Œìš” ê¸°ê°„" ë“±
3. ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„±: "ë¹„ìŠ·í•œ ê¸°ìˆ  ê²½í—˜", "ê´€ë ¨ ê°œë… ì´í•´ë„" ë“±
4. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±
5. ë©´ì ‘ê´€ì´ ë¬¼ì–´ë³¼ ë²•í•œ ì‹¤ìš©ì  ì§ˆë¬¸"""
                    },
                    {
                        "role": "user",
                        "content": f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”:

ë¶€ì¡±í•œ ìŠ¤í‚¬: {json.dumps([s['required'] for s in skills_to_ask], ensure_ascii=False)}
ë³´ìœ í•œ ìŠ¤í‚¬: {json.dumps([s['user_skill'] for s in matched_skills], ensure_ascii=False)}
ì‚¬ìš©ì í”„ë¡œí•„: {json.dumps(user_profile, ensure_ascii=False)}

ê° ë¶€ì¡±í•œ ìŠ¤í‚¬ì— ëŒ€í•´ 1ê°œì”© ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ì§ˆë¬¸ì€:
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì´ì–´ì•¼ í•¨
- í˜„ì¬ ìˆ˜ì¤€ íŒŒì•… ë˜ëŠ” í•™ìŠµ ê³„íš í™•ì¸
- í•œêµ­ì–´ë¡œ ì‘ì„±

JSON í˜•ì‹:
{{
  "questions": [
    {{
      "id": "q_0",
      "skill": "ìŠ¤í‚¬ëª…",
      "question": "ì§ˆë¬¸ ë‚´ìš©",
      "type": "text",
      "required": true
    }}
  ]
}}"""
                    }
                ],
                temperature=0.7
            )

            content = response.choices[0].message.content

            # JSON ì¶”ì¶œ
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0].strip()
            elif '```' in content:
                content = content.split('```')[1].split('```')[0].strip()

            data = json.loads(content)
            return data.get('questions', [])

        except Exception as e:
            print(f"âš ï¸  LLM ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            # Fallback
            return [
                {
                    "id": f"q_{i}",
                    "skill": skill['required'],
                    "question": f"{skill['required']}ì— ëŒ€í•œ ê²½í—˜ì´ë‚˜ í•™ìŠµ ê³„íšì„ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                    "type": "text",
                    "required": True
                }
                for i, skill in enumerate(skills_to_ask)
            ]


@method_decorator(csrf_exempt, name='dispatch')
class JobPlannerAgentReportView(APIView):
    """
    ìµœì¢… ì¢…í•© ë³´ê³ ì„œ ìƒì„± API
    - SWOT ë¶„ì„
    - ë©´ì ‘ ì˜ˆìƒ ì§ˆë¬¸ 5ê°œ
    - ê²½í—˜ í¬ì¥ ê°€ì´ë“œ
    - ì‹¤í–‰ ì „ëµ
    """
    authentication_classes = []
    permission_classes = [AllowAny]

    def post(self, request):
        try:
            # ë¶„ì„ ê²°ê³¼ ë°ì´í„°
            job_data = request.data.get('job_data', {})
            analysis_result = request.data.get('analysis_result', {})
            company_analysis = request.data.get('company_analysis', {})
            agent_answers = request.data.get('agent_answers', {})  # ì—ì´ì „íŠ¸ ì§ˆë¬¸ ë‹µë³€

            # LLMìœ¼ë¡œ ì¢…í•© ë³´ê³ ì„œ ìƒì„±
            available_prep_days = analysis_result.get('profile_summary', {}).get('available_prep_days')
            report = self._generate_report_with_llm(
                job_data, analysis_result, company_analysis, agent_answers, available_prep_days
            )

            return Response(report, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"âŒ ë³´ê³ ì„œ ìƒì„± ì—ëŸ¬: {e}")
            print(traceback.format_exc())
            return Response({
                "error": f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _generate_report_with_llm(self, job_data, analysis_result, company_analysis, agent_answers, available_prep_days=None):
        """LLMìœ¼ë¡œ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return {
                "error": "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "swot": {
                    "strengths": ["ìŠ¤í‚¬ ë§¤ì¹­ë¥ ì´ ë†’ìŠµë‹ˆë‹¤"],
                    "weaknesses": ["ì¼ë¶€ ìŠ¤í‚¬ì´ ë¶€ì¡±í•©ë‹ˆë‹¤"],
                    "opportunities": ["ì„±ì¥ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤"],
                    "threats": ["ê²½ìŸì´ ì¹˜ì—´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"]
                },
                "interview_questions": [],
                "experience_packaging": [],
                "execution_strategy": ""
            }

        try:
            client = openai.OpenAI(api_key=api_key)

            # ì¤€ë¹„ ê¸°ê°„ì— ë”°ë¥¸ ì „ëµ ê¸°ê°„ ë ˆì´ë¸” ìƒì„±
            print(f"[DEBUG] available_prep_days = {available_prep_days}, type = {type(available_prep_days)}")

            # íƒ€ì… ë³€í™˜ (ë¬¸ìì—´ì´ë‚˜ ìˆ«ì ëª¨ë‘ ì²˜ë¦¬)
            try:
                days = int(float(available_prep_days)) if available_prep_days else 0
            except (ValueError, TypeError):
                days = 0

            if days > 0:
                print(f"[INFO] ì¤€ë¹„ ê¸°ê°„ {days}ì¼ ê¸°ë°˜ìœ¼ë¡œ ì „ëµ ê¸°ê°„ ì„¤ì •")
                if days <= 7:
                    short_term_label = f"ë‹¨ê¸° ({days}ì¼)"
                    mid_term_label = "ì¤‘ê¸° (2ì£¼)"
                elif days <= 14:
                    short_term_label = "ë‹¨ê¸° (1ì£¼)"
                    mid_term_label = f"ì¤‘ê¸° ({days}ì¼)"
                elif days <= 21:
                    short_term_label = "ë‹¨ê¸° (1ì£¼)"
                    mid_term_label = f"ì¤‘ê¸° (3ì£¼, {days}ì¼)"
                elif days <= 30:
                    short_term_label = "ë‹¨ê¸° (1-2ì£¼)"
                    mid_term_label = f"ì¤‘ê¸° (1ê°œì›”, {days}ì¼)"
                else:
                    short_term_label = "ë‹¨ê¸° (1-2ì£¼)"
                    mid_term_label = f"ì¤‘ê¸° (1-2ê°œì›”, {days}ì¼)"
                prep_days_info = f"\n- ì¤€ë¹„ ê°€ëŠ¥ ê¸°ê°„: {days}ì¼"
            else:
                print(f"[WARN] ì¤€ë¹„ ê¸°ê°„ ì •ë³´ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©")
                short_term_label = "ë‹¨ê¸° (1-2ì£¼)"
                mid_term_label = "ì¤‘ê¸° (1ê°œì›”)"
                prep_days_info = ""

            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = f"""
ì±„ìš©ê³µê³ :
- íšŒì‚¬: {job_data.get('company_name', 'ë¯¸ì •')}
- í¬ì§€ì…˜: {job_data.get('position', 'ê°œë°œì')}
- í•„ìˆ˜ ìŠ¤í‚¬: {', '.join(job_data.get('required_skills', []))}
- ìš°ëŒ€ ìŠ¤í‚¬: {', '.join(job_data.get('preferred_skills', []))}

ë¶„ì„ ê²°ê³¼:
- ì¤€ë¹„ë„: {analysis_result.get('readiness_score', 0)}
- ìŠ¤í‚¬ ê°­: {analysis_result.get('skill_gap_score', 0)}
- ë§¤ì¹­ëœ ìŠ¤í‚¬: {len(analysis_result.get('matched_skills', []))}ê°œ
- ë¶€ì¡±í•œ ìŠ¤í‚¬: {len(analysis_result.get('missing_skills', []))}ê°œ{prep_days_info}

ì‚¬ìš©ì í”„ë¡œí•„:
{json.dumps(analysis_result.get('profile_summary', {}), ensure_ascii=False)}

ì—ì´ì „íŠ¸ ì§ˆë¬¸ ë‹µë³€:
{json.dumps(agent_answers, ensure_ascii=False)}

ê¸°ì—… ë¶„ì„:
{json.dumps(company_analysis, ensure_ascii=False) if company_analysis else 'ì •ë³´ ì—†ìŒ'}
"""

            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ì „ë¬¸ ì»¤ë¦¬ì–´ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì·¨ì—… ì¤€ë¹„ìƒì„ ìœ„í•œ ì¢…í•© ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤."""
                    },
                    {
                        "role": "user",
                        "content": f"""{context}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•œ ì¢…í•© ë³´ê³ ì„œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:

1. **SWOT ë¶„ì„**
   - Strengths: ê°•ì  3-5ê°œ (êµ¬ì²´ì ìœ¼ë¡œ)
   - Weaknesses: ì•½ì  2-4ê°œ (ë³´ì™„ ë°©ë²• í¬í•¨)
   - Opportunities: ê¸°íšŒ 2-3ê°œ
   - Threats: ìœ„í˜‘ ìš”ì†Œ 1-2ê°œ

2. **ë©´ì ‘ ì˜ˆìƒ ì§ˆë¬¸ 5ê°œ**
   - í•´ë‹¹ í¬ì§€ì…˜/íšŒì‚¬ì— íŠ¹í™”ëœ ì§ˆë¬¸
   - ë‹µë³€ ê°€ì´ë“œ í¬í•¨

3. **ê²½í—˜ í¬ì¥ ê°€ì´ë“œ**
   - ì´ë ¥ì„œ/í¬íŠ¸í´ë¦¬ì˜¤ì—ì„œ ê°•ì¡°í•  ì 
   - í”„ë¡œì íŠ¸ ê²½í—˜ ì–´í•„ ë°©ë²•
   - ë¶€ì¡±í•œ ìŠ¤í‚¬ì„ ë³´ì™„í•˜ëŠ” ë°©ë²•

4. **ì‹¤í–‰ ì „ëµ**
   - {short_term_label}: ì¦‰ì‹œ í•  ì¼
   - {mid_term_label}: ìŠ¤í‚¬ ë³´ì™„
   - ì§€ì› ì‹œì : ìµœì  íƒ€ì´ë°

JSON í˜•ì‹:
{{
  "swot": {{
    "strengths": ["ê°•ì 1", "ê°•ì 2", ...],
    "weaknesses": ["ì•½ì 1 (ë³´ì™„: ...)", "ì•½ì 2 (ë³´ì™„: ...)", ...],
    "opportunities": ["ê¸°íšŒ1", "ê¸°íšŒ2", ...],
    "threats": ["ìœ„í˜‘1", "ìœ„í˜‘2", ...]
  }},
  "interview_questions": [
    {{
      "question": "ì§ˆë¬¸ ë‚´ìš©",
      "answer_guide": "ë‹µë³€ ê°€ì´ë“œ (3-5ë¬¸ì¥)",
      "tips": "ì¶”ê°€ íŒ"
    }},
    ...5ê°œ
  ],
  "experience_packaging": {{
    "resume_highlights": ["ì´ë ¥ì„œì— ê°•ì¡°í•  ì 1", "ê°•ì¡°í•  ì 2", ...],
    "portfolio_tips": ["í¬íŠ¸í´ë¦¬ì˜¤ íŒ1", "íŒ2", ...],
    "skill_compensation": ["ë¶€ì¡± ìŠ¤í‚¬ ë³´ì™„ë²•1", "ë³´ì™„ë²•2", ...]
  }},
  "execution_strategy": {{
    "immediate": ["ì¦‰ì‹œ í•  ì¼1", "í•  ì¼2", ...],
    "short_term": ["{short_term_label} ë‚´ í•  ì¼1", "í•  ì¼2", ...],
    "mid_term": ["{mid_term_label} ë‚´ í•  ì¼1", "í•  ì¼2", ...],
    "application_timing": "ìµœì  ì§€ì› ì‹œì  ë° ì´ìœ "
  }},
  "final_message": "ìµœì¢… ê²©ë ¤ ë©”ì‹œì§€ (2-3ë¬¸ì¥)"
}}"""
                    }
                ],
                temperature=0.7
            )

            content = response.choices[0].message.content

            # JSON ì¶”ì¶œ
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0].strip()
            elif '```' in content:
                content = content.split('```')[1].split('```')[0].strip()

            report = json.loads(content)
            return report

        except Exception as e:
            print(f"âš ï¸  LLM ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "error": f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                "swot": {
                    "strengths": ["ë¶„ì„ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤"],
                    "weaknesses": [],
                    "opportunities": [],
                    "threats": []
                },
                "interview_questions": [],
                "experience_packaging": {
                    "resume_highlights": [],
                    "portfolio_tips": [],
                    "skill_compensation": []
                },
                "execution_strategy": {
                    "immediate": [],
                    "short_term": [],
                    "mid_term": [],
                    "application_timing": ""
                },
                "final_message": "ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ìƒì„¸ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }


@method_decorator(csrf_exempt, name='dispatch')
class JobPlannerRecommendView(APIView):
    """
    ì±„ìš©ê³µê³  ì¶”ì²œ API

    í˜„ì¬ ë¶„ì„ ì¤‘ì¸ ê³µê³ ë³´ë‹¤ ë” ì í•©í•œ ëŒ€ì•ˆ ê³µê³ ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
    ì‚¬ëŒì¸ì„ ì‹¤ì‹œê°„ í¬ë¡¤ë§í•˜ì—¬ ìµœì‹  ê³µê³ ë¥¼ ìˆ˜ì§‘í•˜ê³ ,
    3ë‹¨ê³„ ë§¤ì¹­ ì‹œìŠ¤í…œìœ¼ë¡œ ì‚¬ìš©ì ìŠ¤í‚¬ê³¼ ë¹„êµí•©ë‹ˆë‹¤.

    ì£¼ìš” ê¸°ëŠ¥:
    - ì‹¤ì‹œê°„ ì±„ìš©ê³µê³  í¬ë¡¤ë§ (ì‚¬ëŒì¸)
    - 3ë‹¨ê³„ ìŠ¤í‚¬ ë§¤ì¹­ ì‹œìŠ¤í…œ ì ìš©
    - ì¤‘ë³µ ê³µê³  í•„í„°ë§
    - ë§¤ì¹­ë¥  ê¸°ë°˜ ì •ë ¬ ë° ì¶”ì²œ ì´ìœ  ìƒì„±

    ì¶”ì²œ ì¡°ê±´:
    - ìµœì†Œ 30% ì´ìƒ ë§¤ì¹­
    - í˜„ì¬ ì¤€ë¹„ë„ë³´ë‹¤ ë†’ì€ ë§¤ì¹­ë¥ 
    - ë˜ëŠ” ë¹„ìŠ·í•œ ìˆ˜ì¤€ì´ë©´ì„œ ìƒˆë¡œìš´ ê¸°ìˆ  í•™ìŠµ ê¸°íšŒ ì œê³µ
    """
    authentication_classes = []
    permission_classes = [AllowAny]

    # JobPlannerAnalyzeViewì™€ ë™ì¼í•œ ìŠ¤í‚¬ ë™ì˜ì–´ ì‚¬ì „ ì¬ì‚¬ìš©
    SKILL_SYNONYMS = JobPlannerAnalyzeView.SKILL_SYNONYMS

    def _normalize_skill(self, skill):
        """
        ìŠ¤í‚¬ëª…ì„ ì •ê·œí™” (í•œê¸€->ì˜ì–´, ì†Œë¬¸ì ë³€í™˜)

        JobPlannerAnalyzeViewì™€ ë™ì¼í•œ ì •ê·œí™” ë¡œì§ì„ ì‚¬ìš©í•˜ì—¬
        ì¼ê´€ëœ ìŠ¤í‚¬ ë§¤ì¹­ì„ ë³´ì¥í•©ë‹ˆë‹¤.

        Args:
            skill (str): ì›ë³¸ ìŠ¤í‚¬ëª…

        Returns:
            str: ì •ê·œí™”ëœ ìŠ¤í‚¬ëª… (ì†Œë¬¸ì)
        """
        skill_lower = skill.lower().strip()
        return self.SKILL_SYNONYMS.get(skill_lower, skill_lower)

    def post(self, request):
        try:
            if not CRAWLER_AVAILABLE:
                return Response({
                    "error": "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

            # ì‚¬ìš©ì ì •ë³´
            user_skills = request.data.get('user_skills', [])
            skill_levels = request.data.get('skill_levels', {})
            readiness_score = float(request.data.get('readiness_score', 0.0))
            job_position = request.data.get('job_position', 'ê°œë°œì')  # ê´€ì‹¬ ì§ë¬´

            # í˜„ì¬ ë¶„ì„ ì¤‘ì¸ ê³µê³  ì •ë³´ (ì¤‘ë³µ ì œê±°ìš©)
            current_job_url = request.data.get('current_job_url', '')
            current_job_company = request.data.get('current_job_company', '')
            current_job_title = request.data.get('current_job_title', '')

            if not user_skills:
                return Response({
                    "error": "ì‚¬ìš©ì ìŠ¤í‚¬ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                }, status=status.HTTP_400_BAD_REQUEST)

            print(f"ğŸ” ì¶”ì²œ ê³µê³  ê²€ìƒ‰ ì‹œì‘ (ì¤€ë¹„ë„: {readiness_score}, ìŠ¤í‚¬: {user_skills})")
            print(f"ğŸ“ ì›ë³¸ ì§ë¬´: '{job_position}'")

            # ì§ë¬´ëª…ì„ ê²€ìƒ‰ì— ì í•©í•˜ê²Œ ì •ì œ
            search_keyword = self._simplify_job_position(job_position)
            print(f"ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: '{search_keyword}'")

            if current_job_url:
                print(f"ğŸš« ì œì™¸í•  ê³µê³ : {current_job_company} - {current_job_title}")

            # 1. ì‚¬ëŒì¸ì—ì„œ ê³µê³  í¬ë¡¤ë§ (ì •í™•ë„ìˆœ, ìµœëŒ€ 30ê°œ)
            job_listings = []

            # ì‚¬ëŒì¸ í¬ë¡¤ë§
            print(f"ğŸ” ì‚¬ëŒì¸ í¬ë¡¤ë§ ì‹œì‘: '{search_keyword}' ê²€ìƒ‰")
            saramin_jobs = self._crawl_saramin(search_keyword, limit=15)
            job_listings.extend(saramin_jobs)
            print(f"âœ… ì‚¬ëŒì¸: {len(saramin_jobs)}ê°œ ê³µê³ ")

            if not job_listings:
                return Response({
                    "recommendations": [],
                    "message": "í˜„ì¬ ì¶”ì²œ ê°€ëŠ¥í•œ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤."
                }, status=status.HTTP_200_OK)

            # 1.5. ì‚¬ìš©ìê°€ ì´ë¯¸ ë¶„ì„í•œ ê³µê³  ì œì™¸
            filtered_listings = self._filter_duplicate_jobs(
                job_listings, current_job_url, current_job_company, current_job_title
            )
            print(f"ğŸ” ì¤‘ë³µ ì œê±° í›„: {len(filtered_listings)}ê°œ ê³µê³ ")

            # 1.7. ê°œë³„ ê³µê³  í˜ì´ì§€ íŒŒì‹±ìœ¼ë¡œ ì‹¤ì œ ê¸°ìˆ  ìŠ¤í‚¬ ë³´ì™„ (ë³‘ë ¬)
            print(f"ğŸ” ê°œë³„ ê³µê³  ìƒì„¸ íŒŒì‹± ì‹œì‘ (5ê°œì”© ë³‘ë ¬)...")
            filtered_listings = self._enrich_jobs_with_detail_skills(filtered_listings)
            print(f"âœ… ìƒì„¸ íŒŒì‹± ì™„ë£Œ")

            # 2. ìŠ¤í‚¬ ë§¤ì¹­ìœ¼ë¡œ ì¶”ì²œ ê³µê³  ì„ ì •
            recommendations = self._match_jobs_with_skills(
                filtered_listings, user_skills, skill_levels, readiness_score
            )

            print(f"âœ… ìµœì¢… ì¶”ì²œ: {len(recommendations)}ê°œ")

            return Response({
                "recommendations": recommendations[:5],  # ìµœëŒ€ 10ê°œ
                "total_found": len(job_listings),
                "total_recommendations": len(recommendations)
            }, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"âŒ ì¶”ì²œ ì—ëŸ¬: {e}")
            print(traceback.format_exc())
            return Response({
                "error": f"ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _filter_duplicate_jobs(self, job_listings, current_url, current_company, current_title):
        """ì‚¬ìš©ìê°€ ì´ë¯¸ ë¶„ì„í•œ ê³µê³ ë¥¼ ì œì™¸"""
        filtered = []

        for job in job_listings:
            # URLì´ ì •í™•íˆ ì¼ì¹˜í•˜ë©´ ì œì™¸
            if current_url and job.get('url') == current_url:
                print(f"  âŒ URL ì¤‘ë³µ ì œì™¸: {job['title']}")
                continue

            # íšŒì‚¬ëª… + ì œëª©ì´ ë§¤ìš° ìœ ì‚¬í•˜ë©´ ì œì™¸
            if current_company and current_title:
                job_company = job.get('company_name', '').lower().strip()
                job_title = job.get('title', '').lower().strip()
                curr_company = current_company.lower().strip()
                curr_title = current_title.lower().strip()

                # íšŒì‚¬ëª…ê³¼ ì œëª©ì´ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
                if (curr_company in job_company or job_company in curr_company) and \
                   (curr_title in job_title or job_title in curr_title):
                    print(f"  âŒ ì œëª© ì¤‘ë³µ ì œì™¸: {job['company_name']} - {job['title']}")
                    continue

            filtered.append(job)

        return filtered

    def _simplify_job_position(self, job_position: str) -> str:
        """
        ì§ë¬´ëª…ì„ ê²€ìƒ‰ì— ì í•©í•œ ê°„ë‹¨í•œ í‚¤ì›Œë“œë¡œ ì •ì œí•©ë‹ˆë‹¤.

        ì˜ˆì‹œ:
        - "AIë¦¬ì„œì¹˜ì—”ì§€ë‹ˆì–´-LLMí¬ìŠ¤íŠ¸íŠ¸ë ˆì´ë‹" â†’ "AI ì—”ì§€ë‹ˆì–´"
        - "(ì£¼)í—¥í†  AIê°œë°œ" â†’ "AIê°œë°œ"
        - "ë°±ì—”ë“œ ê°œë°œì (Python/Django)" â†’ "ë°±ì—”ë“œ ê°œë°œì"
        - "ë°ì´í„° ë¶„ì„ê°€ [ì‹ ì…/ê²½ë ¥]" â†’ "ë°ì´í„° ë¶„ì„ê°€"

        Args:
            job_position (str): ì›ë³¸ ì§ë¬´ëª…

        Returns:
            str: ì •ì œëœ ê²€ìƒ‰ í‚¤ì›Œë“œ
        """
        import re

        # ê´„í˜¸ì™€ ê·¸ ë‚´ìš© ì œê±° (ì˜ì–´ ê´„í˜¸)
        simplified = re.sub(r'\([^)]*\)', '', job_position)
        # ëŒ€ê´„í˜¸ì™€ ê·¸ ë‚´ìš© ì œê±°
        simplified = re.sub(r'\[[^\]]*\]', '', simplified)
        # ì¤‘ê´„í˜¸ì™€ ê·¸ ë‚´ìš© ì œê±°
        simplified = re.sub(r'\{[^}]*\}', '', simplified)

        # í•˜ì´í”ˆ ì´í›„ ì œê±° (ë³´í†µ ìƒì„¸ ì„¤ëª…)
        if '-' in simplified:
            simplified = simplified.split('-')[0]

        # ìŠ¬ë˜ì‹œë¡œ êµ¬ë¶„ëœ ê²½ìš° ì²« ë²ˆì§¸ í•­ëª©ë§Œ
        if '/' in simplified:
            parts = simplified.split('/')
            # ê°€ì¥ ê¸´ ë¶€ë¶„ ì„ íƒ (ë³´í†µ ë©”ì¸ ì§ë¬´ëª…)
            simplified = max(parts, key=len)

        # íšŒì‚¬ëª… íŒ¨í„´ ì œê±°
        simplified = re.sub(r'(ì£¼\)|ãˆœ|\(ì£¼\))', '', simplified)

        # íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ë˜ ê³µë°±ì€ ìœ ì§€
        simplified = re.sub(r'[^\w\sê°€-í£]', ' ', simplified)

        # ë‹¤ì¤‘ ê³µë°±ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ
        simplified = ' '.join(simplified.split())

        # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„
        # AI/ë°ì´í„°/ê°œë°œ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
        keywords_priority = {
            'AI': ['AI', 'ì¸ê³µì§€ëŠ¥', 'LLM', 'GPT'],
            'ë¨¸ì‹ ëŸ¬ë‹': ['ë¨¸ì‹ ëŸ¬ë‹', 'ML', 'ê¸°ê³„í•™ìŠµ'],
            'ë”¥ëŸ¬ë‹': ['ë”¥ëŸ¬ë‹', 'DL', 'ì‹¬ì¸µí•™ìŠµ'],
            'ë°ì´í„°': ['ë°ì´í„°', 'Data'],
            'ë°±ì—”ë“œ': ['ë°±ì—”ë“œ', 'Backend', 'ì„œë²„'],
            'í”„ë¡ íŠ¸ì—”ë“œ': ['í”„ë¡ íŠ¸ì—”ë“œ', 'Frontend', 'í”„ë¡ íŠ¸'],
            'í’€ìŠ¤íƒ': ['í’€ìŠ¤íƒ', 'Full Stack', 'Fullstack'],
            'DevOps': ['DevOps', 'ë°ë¸Œì˜µìŠ¤'],
            'í´ë¼ìš°ë“œ': ['í´ë¼ìš°ë“œ', 'Cloud'],
            'QA': ['QA', 'í…ŒìŠ¤íŠ¸', 'Test']
        }

        for main_keyword, variants in keywords_priority.items():
            for variant in variants:
                if variant in simplified:
                    # í•´ë‹¹ í‚¤ì›Œë“œì™€ "ì—”ì§€ë‹ˆì–´", "ê°œë°œì", "ë¶„ì„ê°€" ë“±ì´ í•¨ê»˜ ìˆëŠ”ì§€ í™•ì¸
                    if any(role in simplified for role in ['ì—”ì§€ë‹ˆì–´', 'ê°œë°œì', 'ë¶„ì„ê°€', 'ë§¤ë‹ˆì €', 'Engineer', 'Developer', 'Analyst']):
                        # í‚¤ì›Œë“œì™€ ì—­í• ì„ í•¨ê»˜ ë°˜í™˜
                        for role in ['ì—”ì§€ë‹ˆì–´', 'ê°œë°œì', 'ë¶„ì„ê°€', 'ë§¤ë‹ˆì €', 'Engineer', 'Developer', 'Analyst']:
                            if role in simplified:
                                return f"{main_keyword} {role}"
                    # ì—­í• ì´ ì—†ìœ¼ë©´ í‚¤ì›Œë“œë§Œ ë°˜í™˜
                    return main_keyword

        # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì •ì œëœ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
        # ë‹¨, ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ (15ì ì œí•œ)
        if len(simplified) > 15:
            simplified = simplified[:15].strip()

        return simplified.strip() if simplified.strip() else 'ê°œë°œì'

    def _crawl_saramin(self, job_position, limit=15):
        """
        ì‚¬ëŒì¸ì—ì„œ ì±„ìš©ê³µê³  í¬ë¡¤ë§ (ì •í™•ë„ìˆœ)

        ì‚¬ëŒì¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ì±„ìš©ê³µê³  ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        íšŒì‚¬ëª…, ê³µê³  ì œëª©, URL, ìŠ¤í‚¬, ì§€ì—­, ì¡°ê±´ ë“±ì„ íŒŒì‹±í•©ë‹ˆë‹¤.

        Args:
            job_position (str): ê²€ìƒ‰í•  ì§ë¬´ (ì˜ˆ: "ë°±ì—”ë“œ ê°œë°œì", "Python ê°œë°œì")
            limit (int): ìµœëŒ€ ìˆ˜ì§‘ ê³µê³  ìˆ˜ (ê¸°ë³¸ê°’: 15)

        Returns:
            list: ì±„ìš©ê³µê³  ë¦¬ìŠ¤íŠ¸
        """
        jobs = []
        try:
            # ì‚¬ëŒì¸ ê²€ìƒ‰ URL (ì •í™•ë„ìˆœ - ê¸°ë³¸ê°’)
            # searchType=search : í†µí•©ê²€ìƒ‰
            # ì •í™•ë„ìˆœì´ ê¸°ë³¸ì´ë¯€ë¡œ sort íŒŒë¼ë¯¸í„° ìƒëµ
            search_url = f"https://www.saramin.co.kr/zf_user/search?searchType=search&searchword={job_position}"

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }

            response = requests.get(search_url, headers=headers, timeout=15)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, 'html.parser')

            # ì±„ìš©ê³µê³  ì•„ì´í…œ ì°¾ê¸° (ì‹¤ì œ HTML êµ¬ì¡°ì— ë§ê²Œ ì¡°ì • í•„ìš”)
            job_items = soup.select('.item_recruit')[:limit]

            for item in job_items:
                try:
                    # íšŒì‚¬ëª…
                    company_elem = item.select_one('.corp_name a')
                    company_name = company_elem.get_text(strip=True) if company_elem else "ì•Œ ìˆ˜ ì—†ìŒ"

                    # ì±„ìš© ì œëª©
                    title_elem = item.select_one('.job_tit a')
                    title = title_elem.get_text(strip=True) if title_elem else "ì±„ìš© ê³µê³ "
                    job_url = "https://www.saramin.co.kr" + title_elem['href'] if title_elem and title_elem.get('href') else ""

                    # ì¡°ê±´ (ê²½ë ¥, í•™ë ¥ ë“±)
                    conditions = item.select('.job_condition span')
                    conditions_text = [c.get_text(strip=True) for c in conditions]

                    # ìŠ¤í‚¬/ê¸°ìˆ  ìŠ¤íƒ
                    skills_elem = item.select('.job_sector a')
                    skills = [s.get_text(strip=True) for s in skills_elem]

                    # ë””ë²„ê·¸: ìŠ¤í‚¬ ì¶”ì¶œ ê²°ê³¼ í™•ì¸
                    print(f"  [ì‚¬ëŒì¸] {company_name} - ì¶”ì¶œëœ ìŠ¤í‚¬: {skills if skills else 'ì—†ìŒ'}")

                    # ì§€ì—­
                    location_elem = item.select_one('.job_condition span:first-child')
                    location = location_elem.get_text(strip=True) if location_elem else ""

                    jobs.append({
                        "source": "ì‚¬ëŒì¸",
                        "company_name": company_name,
                        "title": title,
                        "url": job_url,
                        "skills": skills if skills else [],
                        "location": location,
                        "conditions": conditions_text,
                        "description": f"{title} - {company_name}"
                    })

                except Exception as e:
                    print(f"âš ï¸  ì‚¬ëŒì¸ ì•„ì´í…œ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue

        except Exception as e:
            print(f"âš ï¸  ì‚¬ëŒì¸ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

        return jobs

    def _fetch_job_detail_skills(self, url):
        """ê°œë³„ ê³µê³  í˜ì´ì§€ ì „ë¬¸ì—ì„œ ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ"""
        import re
        if not url:
            return []
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
            response = requests.get(url, headers=headers, timeout=8)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            text = soup.get_text()

            tech_keywords = [
                'Python', 'Java', 'JavaScript', 'TypeScript', 'C\\+\\+', 'C#', 'Go', 'Kotlin',
                'Swift', 'Ruby', 'PHP', 'Rust', 'Scala',
                'Django', 'Flask', 'FastAPI', 'Spring', 'SpringBoot', 'React', 'Vue',
                'Angular', 'Next\\.js', 'Nuxt', 'Express', 'Node\\.js', 'Nest\\.js',
                'MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'Oracle', 'MariaDB',
                'Elasticsearch', 'DynamoDB',
                'AWS', 'Azure', 'GCP', 'Docker', 'Kubernetes', 'Jenkins',
                'Git', 'Linux', 'REST', 'GraphQL', 'gRPC', 'Kafka', 'RabbitMQ',
            ]
            found = []
            for kw in tech_keywords:
                display = kw.replace('\\+\\+', '++').replace('\\.', '.')
                if re.search(r'(?<![a-zA-Z])' + kw + r'(?![a-zA-Z])', text, re.IGNORECASE):
                    found.append(display)
            return found
        except Exception:
            return []

    def _enrich_jobs_with_detail_skills(self, jobs):
        """ê°œë³„ ê³µê³  í˜ì´ì§€ë¥¼ 5ê°œì”© ë³‘ë ¬ íŒŒì‹±í•˜ì—¬ ê¸°ìˆ  ìŠ¤í‚¬ ë³´ì™„"""
        from concurrent.futures import ThreadPoolExecutor, as_completed

        def enrich_one(job):
            detail_skills = self._fetch_job_detail_skills(job.get('url', ''))
            if detail_skills:
                existing_lower = {s.lower() for s in job.get('skills', [])}
                new_skills = [s for s in detail_skills if s.lower() not in existing_lower]
                job['skills'] = job.get('skills', []) + new_skills
            return job

        enriched = []
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = {executor.submit(enrich_one, job): job for job in jobs}
            for future in as_completed(futures):
                try:
                    enriched.append(future.result())
                except Exception:
                    enriched.append(futures[future])
        return enriched


    def _match_jobs_with_skills(self, job_listings, user_skills, skill_levels, readiness_score):
        """
        ì‚¬ìš©ì ìŠ¤í‚¬ê³¼ ê³µê³  ë§¤ì¹­ (3ë‹¨ê³„ ë§¤ì¹­ ì‹œìŠ¤í…œ)

        í¬ë¡¤ë§í•œ ì±„ìš©ê³µê³ ë“¤ê³¼ ì‚¬ìš©ì ìŠ¤í‚¬ì„ 3ë‹¨ê³„ ë§¤ì¹­ ì‹œìŠ¤í…œìœ¼ë¡œ ë¹„êµí•˜ì—¬
        ì í•©í•œ ê³µê³ ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.

        Args:
            job_listings: í¬ë¡¤ë§í•œ ì±„ìš©ê³µê³  ë¦¬ìŠ¤íŠ¸
            user_skills: ì‚¬ìš©ì ìŠ¤í‚¬ ë°°ì—´
            skill_levels: ìŠ¤í‚¬ë³„ ìˆ™ë ¨ë„
            readiness_score: í˜„ì¬ ë¶„ì„ ì¤‘ì¸ ê³µê³ ì˜ ì¤€ë¹„ë„ ì ìˆ˜

        Returns:
            list: ì¶”ì²œ ê³µê³  ë¦¬ìŠ¤íŠ¸ (ë§¤ì¹­ë¥  ìˆœìœ¼ë¡œ ì •ë ¬)
        """
        MIN_MATCH_RATE = 0.20  # ìµœì†Œ 20% ì´ìƒ ë§¤ì¹­ë˜ì–´ì•¼ ì¶”ì²œ (í¬ë¡¤ë§ ê³µê³ ëŠ” ìŠ¤í‚¬ ì •ë³´ê°€ ì ì–´ ì™„í™”)

        # ì‚¬ìš©ì ìŠ¤í‚¬ ì •ê·œí™”
        user_skills_normalized = [self._normalize_skill(s) for s in user_skills]

        recommendations = []
        # ì‚¬ìš©ì ìŠ¤í‚¬ ì„ë² ë”©ì„ jobs ë£¨í”„ ì „ì— í•œ ë²ˆë§Œ ê³„ì‚°
        user_embeddings_precomputed = None

        for job in job_listings:
            job_skills = job.get('skills', [])
            print(f"  ğŸ” [{job.get('source', '')}] {job['company_name']} - ìŠ¤í‚¬ ê°œìˆ˜: {len(job_skills)}")

            # ìŠ¤í‚¬ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì œëª©/ì„¤ëª…ì—ì„œ ì¶”ì¶œ ì‹œë„
            if not job_skills:
                job_text = f"{job['title']} {job['description']}"
                # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
                common_skills = ['Python', 'Java', 'JavaScript', 'React', 'Vue', 'Django',
                                'Spring', 'Node.js', 'Docker', 'Kubernetes', 'AWS', 'GCP']
                job_skills = [skill for skill in common_skills if skill.lower() in job_text.lower()]

            if not job_skills:
                # ìŠ¤í‚¬ ì •ë³´ê°€ ì „í˜€ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                continue

            # ê³µê³  ìŠ¤í‚¬ ì •ê·œí™”
            job_skills_normalized = [self._normalize_skill(s) for s in job_skills]

            # === 3ë‹¨ê³„ ë§¤ì¹­ ì‹œìŠ¤í…œìœ¼ë¡œ ê³µê³  ìŠ¤í‚¬ ë§¤ì¹­ ===
            # JobPlannerAnalyzeViewì™€ ë™ì¼í•œ ë§¤ì¹­ ë¡œì§ ì‚¬ìš©
            matched_skills = []
            matched_user_indices = set()  # ì´ë¯¸ ë§¤ì¹­ëœ ì‚¬ìš©ì ìŠ¤í‚¬ ì¸ë±ìŠ¤ (1:1 ë§¤ì¹­)

            for i, job_skill in enumerate(job_skills):
                job_normalized = job_skills_normalized[i]
                best_match = None
                best_score = 0.0
                best_user_idx = -1
                match_type = None

                # 1ë‹¨ê³„: ì •í™• ì¼ì¹˜
                for j, user_skill in enumerate(user_skills):
                    if j in matched_user_indices:
                        continue
                    user_normalized = user_skills_normalized[j]
                    if user_normalized == job_normalized:
                        best_match = user_skill
                        best_score = 1.0
                        best_user_idx = j
                        match_type = "exact"
                        break

                # 2ë‹¨ê³„: ë™ì˜ì–´ ë§¤ì¹­
                if not best_match:
                    for j, user_skill in enumerate(user_skills):
                        if j in matched_user_indices:
                            continue
                        # ì›ë³¸ ìŠ¤í‚¬ì„ ì •ê·œí™”í–ˆì„ ë•Œ ê°™ì€ ê°’ìœ¼ë¡œ ë³€í™˜ë˜ëŠ”ì§€ í™•ì¸
                        user_original_normalized = self._normalize_skill(user_skill)
                        job_original_normalized = self._normalize_skill(job_skill)

                        if user_original_normalized == job_original_normalized and user_skill.lower() != job_skill.lower():
                            best_match = user_skill
                            best_score = 0.95
                            best_user_idx = j
                            match_type = "synonym"
                            break

                # 3ë‹¨ê³„: ì„ë² ë”© ìœ ì‚¬ë„
                if not best_match:
                    # ì‚¬ìš©ì ìŠ¤í‚¬ ì„ë² ë”©: ì²˜ìŒ í•œ ë²ˆë§Œ ê³„ì‚° í›„ ì¬ì‚¬ìš©
                    if user_embeddings_precomputed is None:
                        user_embeddings_precomputed = _embed_texts(user_skills_normalized)
                    # í˜„ì¬ ê³µê³  ìŠ¤í‚¬ ì„ë² ë”©
                    job_emb = _embed_texts([job_normalized])

                    for j, user_skill in enumerate(user_skills):
                        if j in matched_user_indices:
                            continue
                        user_emb = user_embeddings_precomputed[j:j+1]
                        similarity = float((user_emb @ job_emb.T)[0][0])

                        # threshold 0.70 (recommendìš© - analyzeë³´ë‹¤ ì™„í™”)
                        if similarity >= 0.70 and similarity > best_score:
                            best_match = user_skill
                            best_score = similarity
                            best_user_idx = j
                            match_type = "similar"

                # ë§¤ì¹­ ì„±ê³µ ì‹œ ì €ì¥ (70% ì´ìƒ)
                if best_match and best_score >= 0.70:
                    matched_skills.append({
                        "job_skill": job_skill,
                        "user_skill": best_match,
                        "similarity": round(best_score, 3),
                        "match_type": match_type
                    })
                    matched_user_indices.add(best_user_idx)

            # ë§¤ì¹­ë¥  ê³„ì‚°
            matched_count = len(matched_skills)
            match_rate = matched_count / len(job_skills) if job_skills else 0

            # í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
            avg_similarity = sum([m['similarity'] for m in matched_skills]) / len(matched_skills) if matched_skills else 0

            # === ì¶”ì²œ ì¡°ê±´ íŒë‹¨ ===
            # í˜„ì¬ ë¶„ì„ ì¤‘ì¸ ê³µê³ ë³´ë‹¤ ë” ì í•©í•œ ê³µê³ ë¥¼ ì¶”ì²œí•˜ê¸° ìœ„í•œ ë¡œì§
            #
            # ì¡°ê±´ 1: ìµœì†Œ 30% ì´ìƒ ë§¤ì¹­ (ë„ˆë¬´ ë‚®ìœ¼ë©´ ë¶€ì í•©)
            # ì¡°ê±´ 2: ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ë§Œì¡±
            #   - í˜„ì¬ ì¤€ë¹„ë„ë³´ë‹¤ ë†’ì€ ë§¤ì¹­ë¥  (ë” ì í•©í•œ ê³µê³ )
            #   - ì¤€ë¹„ë„ì˜ 90% ì´ìƒì´ë©´ì„œ 95% ë¯¸ë§Œ (ë¹„ìŠ·í•œ ìˆ˜ì¤€ + ìƒˆ ê¸°ìˆ  í•™ìŠµ ê¸°íšŒ)

            # ë””ë²„ê·¸: ëª¨ë“  ê³µê³ ì˜ ë§¤ì¹­ë¥  ì¶œë ¥
            print(f"  ğŸ“Š [{job.get('source', '')}] {job['company_name']} - {job['title'][:30]}...")
            print(f"     ë§¤ì¹­: {matched_count}/{len(job_skills)} ({match_rate*100:.1f}%), í‰ê·  ìœ ì‚¬ë„: {avg_similarity*100:.1f}%")

            if match_rate >= MIN_MATCH_RATE:
                print(f"     âœ… ì¶”ì²œ ì¡°ê±´ ë§Œì¡±!")
                recommendations.append({
                    "source": job.get('source', ''),
                    "company_name": job['company_name'],
                    "title": job['title'],
                    "url": job['url'],
                    "skills": job_skills,
                    "location": job.get('location', ''),
                    "match_rate": round(match_rate, 3),
                    "avg_similarity": round(avg_similarity, 3),
                    "matched_skills": matched_skills,
                    "matched_count": matched_count,
                    "total_skills": len(job_skills),
                    "reason": self._generate_recommendation_reason(match_rate, readiness_score, matched_count, len(job_skills))
                })
            else:
                # í•„í„°ë§ ì´ìœ  ì¶œë ¥
                if match_rate < MIN_MATCH_RATE:
                    print(f"     âŒ í•„í„°ë§: ë§¤ì¹­ë¥  {match_rate*100:.1f}% < ìµœì†Œ {MIN_MATCH_RATE*100:.0f}%")
                else:
                    print(f"     âŒ í•„í„°ë§: í˜„ì¬ ê³µê³ ({readiness_score*100:.1f}%)ë³´ë‹¤ ìœ ì˜ë¯¸í•˜ê²Œ ë†’ì§€ ì•ŠìŒ")

        # ë§¤ì¹­ë¥  ìˆœìœ¼ë¡œ ì •ë ¬ (ê°€ì¥ ì í•©í•œ ê³µê³ ê°€ ë§¨ ìœ„ë¡œ)
        recommendations.sort(key=lambda x: x['match_rate'], reverse=True)

        return recommendations

    def _generate_recommendation_reason(self, match_rate, readiness_score, matched_count, total_skills):
        """ì¶”ì²œ ì´ìœ  ìƒì„±"""
        if match_rate > readiness_score + 0.2:
            return f"í˜„ì¬ë³´ë‹¤ {int((match_rate - readiness_score) * 100)}% ë†’ì€ ë§¤ì¹­ë¥ ë¡œ ë” ì í•©í•œ ê³µê³ ì…ë‹ˆë‹¤."
        elif match_rate > readiness_score + 0.1:
            return f"ë³´ìœ  ìŠ¤í‚¬ê³¼ ì˜ ë§ê³ , {matched_count}/{total_skills}ê°œ ìŠ¤í‚¬ì´ ì¼ì¹˜í•©ë‹ˆë‹¤."
        else:
            return f"í˜„ì¬ ìˆ˜ì¤€ê³¼ ë¹„ìŠ·í•˜ë©´ì„œ ìƒˆë¡œìš´ ê¸°ìˆ ì„ ë°°ìš¸ ìˆ˜ ìˆëŠ” ê¸°íšŒì…ë‹ˆë‹¤."


@method_decorator(csrf_exempt, name='dispatch')
class JobPlannerCompanyAnalyzeView(APIView):
    """
    ê¸°ì—… ë¶„ì„ API
    - URL í¬ë¡¤ë§ ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥ìœ¼ë¡œ íšŒì‚¬ ì •ë³´ ìˆ˜ì§‘
    - LLMìœ¼ë¡œ ì¢…í•© ë¶„ì„:
      1. íšŒì‚¬ ê°œìš” ë° ë¹„ì „
      2. ê¸°ìˆ  ìŠ¤íƒ ë° ê°œë°œ ë¬¸í™”
      3. ì„±ì¥ì„± ë° ì•ˆì •ì„±
      4. ë³µì§€ ë° ê·¼ë¬´í™˜ê²½
    """
    authentication_classes = []
    permission_classes = [AllowAny]

    def post(self, request):
        try:
            input_type = request.data.get('type')  # 'url' or 'text'
            company_name = request.data.get('company_name', 'íšŒì‚¬')

            # íšŒì‚¬ ì •ë³´ ìˆ˜ì§‘
            if input_type == 'url':
                company_info = self._fetch_from_url(request.data.get('url'))
            elif input_type == 'text':
                company_info = request.data.get('text', '')
            else:
                return Response({
                    "error": "Invalid input type. Use 'url' or 'text'."
                }, status=status.HTTP_400_BAD_REQUEST)

            # LLMìœ¼ë¡œ ì¢…í•© ë¶„ì„
            analysis = self._analyze_company_with_llm(company_name, company_info)

            return Response(analysis, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"âŒ ê¸°ì—…ë¶„ì„ ì—ëŸ¬: {e}")
            print(traceback.format_exc())
            return Response({
                "error": f"ê¸°ì—…ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _fetch_from_url(self, url):
        """URLì—ì„œ íšŒì‚¬ ì •ë³´ í¬ë¡¤ë§"""
        if not CRAWLER_AVAILABLE:
            raise Exception("í¬ë¡¤ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        if not url:
            raise Exception("URLì´ í•„ìš”í•©ë‹ˆë‹¤.")

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'html.parser')

        # ìŠ¤í¬ë¦½íŠ¸ì™€ ìŠ¤íƒ€ì¼ ì œê±°
        for script in soup(["script", "style"]):
            script.decompose()

        text = soup.get_text(separator='\n', strip=True)
        return text

    def _analyze_company_with_llm(self, company_name, company_info):
        """LLMìœ¼ë¡œ ê¸°ì—… ì¢…í•© ë¶„ì„"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return {
                "error": "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "company_name": company_name,
                "overview": "",
                "tech_stack": {},
                "growth": {},
                "welfare": {}
            }

        try:
            client = openai.OpenAI(api_key=api_key)

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ IT ê¸°ì—… ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
íšŒì‚¬ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ 4ê°€ì§€ í•­ëª©ì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
1. íšŒì‚¬ ê°œìš” ë° ë¹„ì „
2. ê¸°ìˆ  ìŠ¤íƒ ë° ê°œë°œ ë¬¸í™”
3. ì„±ì¥ì„± ë° ì•ˆì •ì„±
4. ë³µì§€ ë° ê·¼ë¬´í™˜ê²½

ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ì¼ë°˜ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”."""
                    },
                    {
                        "role": "user",
                        "content": f"""ë‹¤ìŒ íšŒì‚¬ ì •ë³´ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

íšŒì‚¬ëª…: {company_name}

ì •ë³´:
{company_info[:3000]}

JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
{{
  "company_name": "{company_name}",
  "overview": {{
    "description": "íšŒì‚¬ ì†Œê°œ (2-3ë¬¸ì¥)",
    "vision": "ë¹„ì „ ë° ë¯¸ì…˜",
    "industry": "ì‚°ì—… ë¶„ì•¼",
    "founded_year": "ì„¤ë¦½ì—°ë„ (ì•Œ ìˆ˜ ì—†ìœ¼ë©´ null)",
    "size": "íšŒì‚¬ ê·œëª¨ (ì˜ˆ: 50-100ëª…)"
  }},
  "tech_stack": {{
    "languages": ["ì£¼ìš” í”„ë¡œê·¸ë˜ë° ì–¸ì–´"],
    "frameworks": ["ì£¼ìš” í”„ë ˆì„ì›Œí¬"],
    "tools": ["ê°œë°œ ë„êµ¬ ë° í˜‘ì—… íˆ´"],
    "culture": "ê°œë°œ ë¬¸í™” ì„¤ëª… (2-3ë¬¸ì¥)",
    "tech_blog": "ê¸°ìˆ  ë¸”ë¡œê·¸ í™œë™ ì—¬ë¶€ ë° í‰ê°€"
  }},
  "growth": {{
    "funding": "íˆ¬ì ìœ ì¹˜ í˜„í™©",
    "market_position": "ì‹œì¥ ìœ„ì¹˜ ë° ê²½ìŸë ¥",
    "growth_potential": "ì„±ì¥ ê°€ëŠ¥ì„± í‰ê°€ (ìƒ/ì¤‘/í•˜)",
    "stability": "ì•ˆì •ì„± í‰ê°€ (ìƒ/ì¤‘/í•˜)"
  }},
  "welfare": {{
    "salary_level": "ì—°ë´‰ ìˆ˜ì¤€ (í‰ê·  ë˜ëŠ” ë²”ìœ„)",
    "benefits": ["ë³µì§€ í˜œíƒ ë¦¬ìŠ¤íŠ¸"],
    "work_life_balance": "ì›Œë¼ë°¸ í‰ê°€ ë° ì„¤ëª…",
    "remote_work": "ë¦¬ëª¨íŠ¸ ê·¼ë¬´ ê°€ëŠ¥ ì—¬ë¶€"
  }},
  "overall_score": {{
    "tech_score": 0.0-1.0,
    "growth_score": 0.0-1.0,
    "welfare_score": 0.0-1.0,
    "total_score": 0.0-1.0
  }},
  "recommendation": "ì´ íšŒì‚¬ì— ì§€ì›í•˜ë©´ ì¢‹ì€ ì´ìœ  ë˜ëŠ” ì£¼ì˜ì‚¬í•­ (3-4ë¬¸ì¥)"
}}"""
                    }
                ],
                temperature=0.5
            )

            content = response.choices[0].message.content

            # JSON ì¶”ì¶œ
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0].strip()
            elif '```' in content:
                content = content.split('```')[1].split('```')[0].strip()

            analysis = json.loads(content)
            return analysis

        except Exception as e:
            print(f"âš ï¸  LLM ê¸°ì—…ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "error": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                "company_name": company_name,
                "overview": {"description": "ì •ë³´ ë¶€ì¡±", "vision": "", "industry": "", "founded_year": None, "size": ""},
                "tech_stack": {"languages": [], "frameworks": [], "tools": [], "culture": "", "tech_blog": ""},
                "growth": {"funding": "", "market_position": "", "growth_potential": "ì¤‘", "stability": "ì¤‘"},
                "welfare": {"salary_level": "", "benefits": [], "work_life_balance": "", "remote_work": ""},
                "overall_score": {"tech_score": 0.5, "growth_score": 0.5, "welfare_score": 0.5, "total_score": 0.5},
                "recommendation": "ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
