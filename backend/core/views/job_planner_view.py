# job_planner_view.py
"""
Job Planner Agent - Django REST API
ì›ë³¸ v3.1 ê¸°ë°˜ - URL í¬ë¡¤ë§ ë° ì´ë¯¸ì§€ OCR ì§€ì›
"""
import os
import json
import base64
import traceback
from django.conf import settings
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import AllowAny
from django.views.decorators.csrf import csrf_exempt
from django.utils.decorators import method_decorator

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import requests
    from bs4 import BeautifulSoup
    import openai
    CRAWLER_AVAILABLE = True
except ImportError:
    CRAWLER_AVAILABLE = False

# Sentence Transformers (ìŠ¤í‚¬ ë§¤ì¹­ìš©)
try:
    from sentence_transformers import SentenceTransformer
    import torch
    EMBEDDING_AVAILABLE = True
except ImportError:
    EMBEDDING_AVAILABLE = False


@method_decorator(csrf_exempt, name='dispatch')
class JobPlannerParseView(APIView):
    """
    ì±„ìš©ê³µê³  íŒŒì‹± API
    - URL í¬ë¡¤ë§
    - ì´ë¯¸ì§€ OCR (OpenAI Vision)
    - í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥
    """
    authentication_classes = []
    permission_classes = [AllowAny]

    def post(self, request):
        input_type = request.data.get('type')  # 'url', 'image', 'text'

        try:
            if input_type == 'url':
                return self._parse_from_url(request)
            elif input_type == 'image':
                return self._parse_from_image(request)
            elif input_type == 'text':
                return self._parse_from_text(request)
            else:
                return Response({
                    "error": "Invalid input type. Use 'url', 'image', or 'text'."
                }, status=status.HTTP_400_BAD_REQUEST)
        except Exception as e:
            print(f"âŒ Parse ì—ëŸ¬: {e}")
            print(traceback.format_exc())
            return Response({
                "error": f"íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _parse_from_url(self, request):
        """URL í¬ë¡¤ë§ìœ¼ë¡œ ì±„ìš©ê³µê³  íŒŒì‹±"""
        if not CRAWLER_AVAILABLE:
            return Response({
                "error": "í¬ë¡¤ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        url = request.data.get('url')
        if not url:
            return Response({
                "error": "URLì´ í•„ìš”í•©ë‹ˆë‹¤."
            }, status=status.HTTP_400_BAD_REQUEST)

        try:
            # ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, 'html.parser')

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            # ìŠ¤í¬ë¦½íŠ¸ì™€ ìŠ¤íƒ€ì¼ ì œê±°
            for script in soup(["script", "style"]):
                script.decompose()

            text = soup.get_text(separator='\n', strip=True)

            # OpenAIë¡œ êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œ
            parsed_data = self._extract_job_info_with_llm(text, source='url')

            return Response(parsed_data, status=status.HTTP_200_OK)

        except requests.RequestException as e:
            return Response({
                "error": f"URL ì ‘ê·¼ ì‹¤íŒ¨: {str(e)}"
            }, status=status.HTTP_400_BAD_REQUEST)

    def _parse_from_image(self, request):
        """ì´ë¯¸ì§€ OCRë¡œ ì±„ìš©ê³µê³  íŒŒì‹± (OpenAI Vision)"""
        image_data = request.data.get('image')  # base64 encoded
        if not image_data:
            return Response({
                "error": "ì´ë¯¸ì§€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }, status=status.HTTP_400_BAD_REQUEST)

        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return Response({
                "error": "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        try:
            client = openai.OpenAI(api_key=api_key)

            # Vision API í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": """ë‹¹ì‹ ì€ ì±„ìš©ê³µê³  ì´ë¯¸ì§€ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì´ë¯¸ì§€ì—ì„œ ì±„ìš©ê³µê³  ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
1. íšŒì‚¬ëª…ê³¼ í¬ì§€ì…˜
2. ì£¼ìš” ì—…ë¬´ (ë‹´ë‹¹í•  ì—…ë¬´, í•˜ê²Œ ë  ì¼)
3. í•„ìˆ˜ ìš”ê±´ (ìê²© ìš”ê±´, í•„ìˆ˜ ì¡°ê±´)
4. ìš°ëŒ€ ì¡°ê±´ (ìš°ëŒ€ ì‚¬í•­, í”ŒëŸ¬ìŠ¤ ìš”ì†Œ)
5. ê¸°ìˆ  ìŠ¤íƒ (ê° í•­ëª©ì—ì„œ ì–¸ê¸‰ëœ í”„ë¡œê·¸ë˜ë° ì–¸ì–´, í”„ë ˆì„ì›Œí¬, ë„êµ¬)

JSON í˜•ì‹:
{
  "company_name": "íšŒì‚¬ëª…",
  "position": "í¬ì§€ì…˜",

  "job_responsibilities": "ì£¼ìš” ì—…ë¬´ ë‚´ìš© (ì›ë¬¸ ê·¸ëŒ€ë¡œ, 3-5ê°œ í•­ëª©)",
  "required_qualifications": "í•„ìˆ˜ ìš”ê±´ (ì›ë¬¸ ê·¸ëŒ€ë¡œ, ìê²© ìš”ê±´)",
  "preferred_qualifications": "ìš°ëŒ€ ì¡°ê±´ (ì›ë¬¸ ê·¸ëŒ€ë¡œ, í”ŒëŸ¬ìŠ¤ ìš”ì†Œ)",

  "required_skills": ["í•„ìˆ˜ ìŠ¤í‚¬ ë°°ì—´ - ê¸°ìˆ  ìŠ¤íƒë§Œ ì¶”ì¶œ"],
  "preferred_skills": ["ìš°ëŒ€ ìŠ¤í‚¬ ë°°ì—´ - ê¸°ìˆ  ìŠ¤íƒë§Œ ì¶”ì¶œ"],

  "experience_range": "ê²½ë ¥ ìš”êµ¬ì‚¬í•­ (ì˜ˆ: ì‹ ì…, 2-4ë…„, 5ë…„ ì´ìƒ)",
  "deadline": "ë§ˆê°ì¼ (YYYY-MM-DD ë˜ëŠ” null)"
}

ì¤‘ìš” ì‚¬í•­:
- job_responsibilities: "ë‹´ë‹¹ ì—…ë¬´", "ì£¼ìš” ì—…ë¬´", "í•˜ê²Œ ë  ì¼" ì„¹ì…˜ì˜ ë‚´ìš©ì„ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì¶”ì¶œ
- required_qualifications: "í•„ìˆ˜ ìê²© ìš”ê±´", "ì§€ì› ìê²©", "í•„ìˆ˜ ìš”ê±´" ì„¹ì…˜ì˜ ë‚´ìš©ì„ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì¶”ì¶œ
- preferred_qualifications: "ìš°ëŒ€ ì‚¬í•­", "ìš°ëŒ€ ì¡°ê±´", "ê°€ì‚°ì " ì„¹ì…˜ì˜ ë‚´ìš©ì„ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì¶”ì¶œ
- required_skills: í•„ìˆ˜ ìš”ê±´ì—ì„œ ì–¸ê¸‰ëœ ê¸°ìˆ ë§Œ ë°°ì—´ë¡œ ì¶”ì¶œ (ì˜ˆ: Python, Java, React, Docker, AWS)
- preferred_skills: ìš°ëŒ€ ì¡°ê±´ì—ì„œ ì–¸ê¸‰ëœ ê¸°ìˆ ë§Œ ë°°ì—´ë¡œ ì¶”ì¶œ
- ê° ê¸°ìˆ ì€ ì •í™•í•œ ì´ë¦„ìœ¼ë¡œ ì¶”ì¶œ (ì˜ˆ: "íŒŒì´ì¬" â†’ "Python", "ë¦¬ì•¡íŠ¸" â†’ "React")
- ê¸°ìˆ ì´ ì•„ë‹Œ ê²ƒì€ ì œì™¸ (ì˜ˆ: "íŒ€ì›Œí¬", "ì„±ì‹¤ì„±", "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜" ë“±)

ì´ë¯¸ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì£¼ì˜ ê¹Šê²Œ ì½ê³  ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”."""
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": image_data  # data:image/jpeg;base64,... í˜•ì‹
                                }
                            }
                        ]
                    }
                ],
                max_tokens=2000,
                temperature=0.3
            )

            content = response.choices[0].message.content

            # JSON ì¶”ì¶œ
            try:
                # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
                if '```json' in content:
                    content = content.split('```json')[1].split('```')[0].strip()
                elif '```' in content:
                    content = content.split('```')[1].split('```')[0].strip()

                parsed_data = json.loads(content)
                parsed_data['source'] = 'image'
                parsed_data['raw_text'] = ''

                return Response(parsed_data, status=status.HTTP_200_OK)
            except json.JSONDecodeError:
                return Response({
                    "error": "ì´ë¯¸ì§€ì—ì„œ ì±„ìš©ê³µê³  ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "raw_response": content
                }, status=status.HTTP_400_BAD_REQUEST)

        except Exception as e:
            return Response({
                "error": f"Vision API ì˜¤ë¥˜: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _parse_from_text(self, request):
        """í…ìŠ¤íŠ¸ì—ì„œ ì±„ìš©ê³µê³  íŒŒì‹±"""
        text = request.data.get('text')
        if not text:
            return Response({
                "error": "í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }, status=status.HTTP_400_BAD_REQUEST)

        parsed_data = self._extract_job_info_with_llm(text, source='text')
        return Response(parsed_data, status=status.HTTP_200_OK)

    def _extract_job_info_with_llm(self, text, source='text'):
        """LLMìœ¼ë¡œ ì±„ìš©ê³µê³  ì •ë³´ ì¶”ì¶œ"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            # Fallback: ê¸°ë³¸ íŒŒì‹±
            return {
                "source": source,
                "raw_text": text,
                "company_name": "ì•Œ ìˆ˜ ì—†ìŒ",
                "position": "ê°œë°œì",
                "job_responsibilities": text[:200] if len(text) > 200 else text,
                "required_qualifications": "ì •ë³´ ì—†ìŒ",
                "preferred_qualifications": "ì •ë³´ ì—†ìŒ",
                "required_skills": [],
                "preferred_skills": [],
                "experience_range": "",
                "deadline": None
            }

        try:
            client = openai.OpenAI(api_key=api_key)

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ì±„ìš©ê³µê³  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì±„ìš©ê³µê³ ì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
1. ì£¼ìš” ì—…ë¬´ (ë‹´ë‹¹ ì—…ë¬´, í•˜ê²Œ ë  ì¼)
2. í•„ìˆ˜ ìš”ê±´ (ìê²© ìš”ê±´, í•„ìˆ˜ ì¡°ê±´)
3. ìš°ëŒ€ ì¡°ê±´ (ìš°ëŒ€ ì‚¬í•­, í”ŒëŸ¬ìŠ¤ ìš”ì†Œ)

ê° í•­ëª©ì€ ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë˜, ê¸°ìˆ  ìŠ¤íƒì€ ë³„ë„ ë°°ì—´ë¡œ ì¶”ì¶œí•˜ì„¸ìš”.
ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ë¹ˆ ë°°ì—´ì„ ì‚¬ìš©í•˜ì„¸ìš”."""
                    },
                    {
                        "role": "user",
                        "content": f"""ë‹¤ìŒ ì±„ìš©ê³µê³ ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:

{text}

JSON í˜•ì‹:
{{
  "company_name": "íšŒì‚¬ëª…",
  "position": "í¬ì§€ì…˜",

  "job_responsibilities": "ì£¼ìš” ì—…ë¬´ ë‚´ìš© (ì›ë¬¸ ê·¸ëŒ€ë¡œ, 3-5ê°œ í•­ëª©)",
  "required_qualifications": "í•„ìˆ˜ ìš”ê±´ (ì›ë¬¸ ê·¸ëŒ€ë¡œ, ìê²© ìš”ê±´)",
  "preferred_qualifications": "ìš°ëŒ€ ì¡°ê±´ (ì›ë¬¸ ê·¸ëŒ€ë¡œ, í”ŒëŸ¬ìŠ¤ ìš”ì†Œ)",

  "required_skills": ["í•„ìˆ˜ ìŠ¤í‚¬ ë°°ì—´ - ê¸°ìˆ  ìŠ¤íƒë§Œ ì¶”ì¶œ"],
  "preferred_skills": ["ìš°ëŒ€ ìŠ¤í‚¬ ë°°ì—´ - ê¸°ìˆ  ìŠ¤íƒë§Œ ì¶”ì¶œ"],

  "experience_range": "ê²½ë ¥ ìš”êµ¬ì‚¬í•­ (ì˜ˆ: ì‹ ì…, 2-4ë…„, 5ë…„ ì´ìƒ)",
  "deadline": "ë§ˆê°ì¼ (YYYY-MM-DD ë˜ëŠ” null)"
}}

ì£¼ì˜ì‚¬í•­:
- job_responsibilities: ë‹´ë‹¹ ì—…ë¬´, í•˜ê²Œ ë  ì¼ ë“±ì„ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì‘ì„±
- required_qualifications: í•„ìˆ˜ ìê²© ìš”ê±´, ì§€ì› ìê²©ì„ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì‘ì„±
- preferred_qualifications: ìš°ëŒ€ ì‚¬í•­, ê°€ì‚°ì  í•­ëª©ì„ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì‘ì„±
- required_skills/preferred_skills: ìœ„ ë‚´ìš©ì—ì„œ ê¸°ìˆ  ìŠ¤íƒë§Œ ë°°ì—´ë¡œ ì¶”ì¶œ (ì˜ˆ: Python, Django, React)"""
                    }
                ],
                temperature=0.3
            )

            content = response.choices[0].message.content

            # JSON ì¶”ì¶œ
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0].strip()
            elif '```' in content:
                content = content.split('```')[1].split('```')[0].strip()

            parsed_data = json.loads(content)
            parsed_data['source'] = source
            parsed_data['raw_text'] = text

            return parsed_data

        except Exception as e:
            print(f"âš ï¸  LLM íŒŒì‹± ì‹¤íŒ¨: {e}")
            # Fallback
            return {
                "source": source,
                "raw_text": text,
                "company_name": "ì•Œ ìˆ˜ ì—†ìŒ",
                "position": "ê°œë°œì",
                "job_responsibilities": text[:200] if len(text) > 200 else text,
                "required_qualifications": "ì •ë³´ ì—†ìŒ",
                "preferred_qualifications": "ì •ë³´ ì—†ìŒ",
                "required_skills": [],
                "preferred_skills": [],
                "experience_range": "",
                "deadline": None
            }


@method_decorator(csrf_exempt, name='dispatch')
class JobPlannerAnalyzeView(APIView):
    """
    ìŠ¤í‚¬ ë§¤ì¹­ ë¶„ì„ API
    """
    authentication_classes = []
    permission_classes = [AllowAny]

    # í•œì˜ ìŠ¤í‚¬ ë™ì˜ì–´ ì‚¬ì „
    SKILL_SYNONYMS = {
        # í”„ë¡œê·¸ë˜ë° ì–¸ì–´
        'íŒŒì´ì¬': 'python', 'python': 'python',
        'ìë°”': 'java', 'java': 'java',
        'ìë°”ìŠ¤í¬ë¦½íŠ¸': 'javascript', 'javascript': 'javascript', 'js': 'javascript',
        'íƒ€ì…ìŠ¤í¬ë¦½íŠ¸': 'typescript', 'typescript': 'typescript', 'ts': 'typescript',
        'C++': 'cpp', 'c++': 'cpp', 'cpp': 'cpp',
        'C#': 'csharp', 'c#': 'csharp', 'csharp': 'csharp', 'ì”¨ìƒµ': 'csharp',
        'ê³ ': 'go', 'go': 'go', 'golang': 'go',
        'ì½”í‹€ë¦°': 'kotlin', 'kotlin': 'kotlin',
        'ìŠ¤ìœ„í”„íŠ¸': 'swift', 'swift': 'swift',
        'R': 'r', 'r': 'r',
        'ë£¨ë¹„': 'ruby', 'ruby': 'ruby',
        'PHP': 'php', 'php': 'php',

        # í”„ë ˆì„ì›Œí¬/ë¼ì´ë¸ŒëŸ¬ë¦¬
        'ì¥ê³ ': 'django', 'django': 'django',
        'í”Œë¼ìŠ¤í¬': 'flask', 'flask': 'flask',
        'ìŠ¤í”„ë§': 'spring', 'spring': 'spring', 'ìŠ¤í”„ë§ë¶€íŠ¸': 'springboot', 'springboot': 'springboot',
        'ë¦¬ì•¡íŠ¸': 'react', 'react': 'react', 'reactjs': 'react',
        'ë·°': 'vue', 'vue': 'vue', 'vuejs': 'vue',
        'ì•µê·¤ëŸ¬': 'angular', 'angular': 'angular',
        'ë…¸ë“œ': 'node', 'node': 'node', 'nodejs': 'node', 'node.js': 'node',
        'ìµìŠ¤í”„ë ˆìŠ¤': 'express', 'express': 'express', 'expressjs': 'express',
        'ë„¥ìŠ¤íŠ¸': 'next', 'next': 'next', 'nextjs': 'next', 'next.js': 'next',
        'ë„¥ìŠ¤íŠ¸ì œì´ì—ìŠ¤': 'next',
        'ë„¥ìŠ¤íŠ¸js': 'next',

        # ë°ì´í„°ë² ì´ìŠ¤
        'MySQL': 'mysql', 'mysql': 'mysql', 'ë§ˆì´ì—ìŠ¤íì—˜': 'mysql',
        'PostgreSQL': 'postgresql', 'postgresql': 'postgresql', 'í¬ìŠ¤íŠ¸ê·¸ë ˆ': 'postgresql',
        'MongoDB': 'mongodb', 'mongodb': 'mongodb', 'ëª½ê³ ë””ë¹„': 'mongodb',
        'Redis': 'redis', 'redis': 'redis', 'ë ˆë””ìŠ¤': 'redis',
        'Oracle': 'oracle', 'oracle': 'oracle', 'ì˜¤ë¼í´': 'oracle',

        # í´ë¼ìš°ë“œ/ì¸í”„ë¼
        'AWS': 'aws', 'aws': 'aws',
        'Azure': 'azure', 'azure': 'azure', 'ì• ì €': 'azure',
        'GCP': 'gcp', 'gcp': 'gcp', 'êµ¬ê¸€í´ë¼ìš°ë“œ': 'gcp',
        'ë„ì»¤': 'docker', 'docker': 'docker',
        'ì¿ ë²„ë„¤í‹°ìŠ¤': 'kubernetes', 'kubernetes': 'kubernetes', 'k8s': 'kubernetes',

        # AI/ML
        'í…ì„œí”Œë¡œ': 'tensorflow', 'tensorflow': 'tensorflow',
        'íŒŒì´í† ì¹˜': 'pytorch', 'pytorch': 'pytorch',
        'ì¼€ë¼ìŠ¤': 'keras', 'keras': 'keras',
        'ì‚¬ì´í‚·ëŸ°': 'sklearn', 'sklearn': 'sklearn', 'scikit-learn': 'sklearn',

        # ë„êµ¬
        'ê¹ƒ': 'git', 'git': 'git',
        'ê¹ƒí—ˆë¸Œ': 'github', 'github': 'github',
        'ì§€ë¼': 'jira', 'jira': 'jira',
    }

    def _normalize_skill(self, skill):
        """ìŠ¤í‚¬ëª…ì„ ì •ê·œí™” (í•œê¸€->ì˜ì–´, ì†Œë¬¸ì ë³€í™˜)"""
        skill_lower = skill.lower().strip()
        return self.SKILL_SYNONYMS.get(skill_lower, skill_lower)

    def _extract_skills_from_text(self, required_text, preferred_text, responsibilities_text):
        """
        í•„ìˆ˜/ìš°ëŒ€ ìš”ê±´ ë° ì—…ë¬´ í…ìŠ¤íŠ¸ì—ì„œ ê¸°ìˆ  ìŠ¤íƒê³¼ ì—­ëŸ‰ì„ ì¶”ì¶œ
        - ì •ê·œì‹ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì¶”ì¶œ
        - LLM ì—†ì´ë„ ì‘ë™í•˜ë„ë¡ êµ¬í˜„
        """
        import re

        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        full_text = f"{required_text} {preferred_text} {responsibilities_text}"

        # ì•Œë ¤ì§„ ê¸°ìˆ  ìŠ¤íƒ í‚¤ì›Œë“œ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
        tech_keywords = [
            # ì–¸ì–´
            'Python', 'Java', 'JavaScript', 'TypeScript', 'C++', 'C#', 'Go', 'Kotlin',
            'Swift', 'Ruby', 'PHP', 'Rust', 'Scala', 'R',
            'íŒŒì´ì¬', 'ìë°”', 'ìë°”ìŠ¤í¬ë¦½íŠ¸', 'íƒ€ì…ìŠ¤í¬ë¦½íŠ¸', 'ì½”í‹€ë¦°',

            # í”„ë ˆì„ì›Œí¬
            'Django', 'Flask', 'FastAPI', 'Spring', 'SpringBoot', 'React', 'Vue',
            'Angular', 'Next.js', 'Nuxt', 'Express', 'Node.js', 'Nest.js',
            'ì¥ê³ ', 'í”Œë¼ìŠ¤í¬', 'ìŠ¤í”„ë§', 'ë¦¬ì•¡íŠ¸', 'ë·°', 'ì•µê·¤ëŸ¬', 'ë…¸ë“œ',

            # ë°ì´í„°ë² ì´ìŠ¤
            'MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'Oracle', 'MariaDB',
            'SQLite', 'Elasticsearch', 'DynamoDB', 'Cassandra',
            'ë§ˆì´ì—ìŠ¤íì—˜', 'ëª½ê³ ë””ë¹„', 'ë ˆë””ìŠ¤', 'ì˜¤ë¼í´',

            # í´ë¼ìš°ë“œ/ì¸í”„ë¼
            'AWS', 'Azure', 'GCP', 'Docker', 'Kubernetes', 'Jenkins', 'GitLab CI',
            'Terraform', 'Ansible', 'Linux', 'Nginx', 'Apache',
            'ë„ì»¤', 'ì¿ ë²„ë„¤í‹°ìŠ¤', 'ë¦¬ëˆ…ìŠ¤',

            # AI/ML/Data
            'TensorFlow', 'PyTorch', 'Keras', 'scikit-learn', 'Pandas', 'NumPy',
            'Spark', 'Hadoop', 'Airflow', 'Kafka',
            'í…ì„œí”Œë¡œ', 'íŒŒì´í† ì¹˜',

            # ë„êµ¬
            'Git', 'GitHub', 'GitLab', 'Jira', 'Confluence', 'Slack', 'Notion',
            'Figma', 'Postman', 'Swagger',
            'ê¹ƒ', 'ê¹ƒí—ˆë¸Œ', 'ì§€ë¼'
        ]

        found_skills = []

        # ê° í‚¤ì›Œë“œê°€ í…ìŠ¤íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸ (ë‹¨ì–´ ê²½ê³„ ê³ ë ¤)
        for keyword in tech_keywords:
            # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´, ë‹¨ì–´ ê²½ê³„ë¥¼ ê³ ë ¤í•œ ê²€ìƒ‰
            pattern = r'\b' + re.escape(keyword) + r'\b'
            if re.search(pattern, full_text, re.IGNORECASE):
                # ì´ë¯¸ ì¶”ê°€ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì¶”ê°€
                normalized = self._normalize_skill(keyword)
                if normalized not in [self._normalize_skill(s) for s in found_skills]:
                    found_skills.append(keyword)

        # í•„ìˆ˜ì™€ ìš°ëŒ€ êµ¬ë¶„ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        required_found = []
        preferred_found = []

        for skill in found_skills:
            # í•„ìˆ˜ ìš”ê±´ í…ìŠ¤íŠ¸ì— ìˆìœ¼ë©´ í•„ìˆ˜ë¡œ ë¶„ë¥˜
            pattern = r'\b' + re.escape(skill) + r'\b'
            if re.search(pattern, required_text, re.IGNORECASE):
                required_found.append(skill)
            elif re.search(pattern, preferred_text, re.IGNORECASE):
                preferred_found.append(skill)
            else:
                # ì—…ë¬´ ë‚´ìš©ì—ë§Œ ìˆìœ¼ë©´ í•„ìˆ˜ë¡œ ê°„ì£¼
                required_found.append(skill)

        return {
            'required': required_found,
            'preferred': preferred_found
        }

    def post(self, request):
        if not EMBEDDING_AVAILABLE:
            return Response({
                "error": "Sentence Transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        try:
            # ê¸°ë³¸ í”„ë¡œí•„
            user_skills = request.data.get('user_skills', [])
            skill_levels = request.data.get('skill_levels', {})  # {"Python": 4, "Django": 3}
            experience_years = int(request.data.get('experience_years', 0))

            # ìƒì„¸ í”„ë¡œí•„ (ì„ íƒì‚¬í•­)
            name = request.data.get('name', 'ì§€ì›ì')
            current_role = request.data.get('current_role', '')
            education = request.data.get('education', '')
            certifications = request.data.get('certifications', [])
            career_goals = request.data.get('career_goals', '')
            available_prep_days = request.data.get('available_prep_days', None)

            # ì±„ìš©ê³µê³  ì •ë³´
            required_skills = request.data.get('required_skills', [])
            preferred_skills = request.data.get('preferred_skills', [])
            experience_range = request.data.get('experience_range', '')

            # í•„ìˆ˜/ìš°ëŒ€ ìš”ê±´ ì „ì²´ í…ìŠ¤íŠ¸ (ì¶”ê°€ ì—­ëŸ‰ ì¶”ì¶œìš©)
            required_qualifications = request.data.get('required_qualifications', '')
            preferred_qualifications = request.data.get('preferred_qualifications', '')
            job_responsibilities = request.data.get('job_responsibilities', '')

            if not user_skills:
                return Response({
                    "error": "ì‚¬ìš©ì ìŠ¤í‚¬ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                }, status=status.HTTP_400_BAD_REQUEST)

            # í•„ìˆ˜ ìš”ê±´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ê°€ ìŠ¤í‚¬/ì—­ëŸ‰ ì¶”ì¶œ
            extracted_skills = self._extract_skills_from_text(
                required_qualifications,
                preferred_qualifications,
                job_responsibilities
            )

            # ê¸°ì¡´ ìŠ¤í‚¬ ë°°ì—´ê³¼ ì¶”ì¶œëœ ìŠ¤í‚¬ ê²°í•© (ì¤‘ë³µ ì œê±°)
            all_required_skills = list(set(required_skills + extracted_skills['required']))
            all_preferred_skills = list(set(preferred_skills + extracted_skills['preferred']))

            # ìµœì†Œ 1ê°œ ì´ìƒì˜ í•„ìˆ˜ ìŠ¤í‚¬ì´ ìˆì–´ì•¼ í•¨
            if not all_required_skills:
                all_required_skills = extracted_skills['required'] if extracted_skills['required'] else ['ê°œë°œ ì—­ëŸ‰']

            print(f"ğŸ“Š í•„ìˆ˜ ìŠ¤í‚¬: {len(required_skills)}ê°œ â†’ {len(all_required_skills)}ê°œ (í…ìŠ¤íŠ¸ ë¶„ì„ ì¶”ê°€)")

            # ìŠ¤í‚¬ ì •ê·œí™” (í•œì˜ í†µì¼)
            user_skills_normalized = [self._normalize_skill(s) for s in user_skills]
            required_skills_normalized = [self._normalize_skill(s) for s in all_required_skills]

            # ìŠ¤í‚¬ ë§¤ì¹­ ì—”ì§„
            model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
            threshold = 0.50  # 0.65 â†’ 0.50ìœ¼ë¡œ ë‚®ì¶¤

            # í•„ìˆ˜ ìŠ¤í‚¬ ë§¤ì¹­
            user_emb = model.encode(user_skills_normalized, normalize_embeddings=True)
            req_emb = model.encode(required_skills_normalized, normalize_embeddings=True)
            sim_matrix = user_emb @ req_emb.T

            matched_skills = []
            missing_skills = []

            for i, req in enumerate(required_skills):
                best_idx = sim_matrix[:, i].argmax()
                best_score = float(sim_matrix[best_idx, i])

                if best_score >= threshold:
                    matched_skills.append({
                        "required": req,
                        "user_skill": user_skills[best_idx],
                        "similarity": round(best_score, 3)
                    })
                else:
                    missing_skills.append({
                        "required": req,
                        "closest_match": user_skills[best_idx],
                        "similarity": round(best_score, 3)
                    })

            # ì ìˆ˜ ê³„ì‚°
            match_rate = len(matched_skills) / len(required_skills) if required_skills else 0

            # ê²½ë ¥ ì í•©ë„
            exp_fit = self._calculate_exp_fit(experience_years, experience_range)

            # ìˆ™ë ¨ë„ ê°€ì¤‘ì¹˜ (ìŠ¤í‚¬ ë ˆë²¨ì´ ìˆìœ¼ë©´ ë°˜ì˜)
            proficiency_score = 0.0
            if skill_levels and matched_skills:
                matched_skill_names = [m["required"] for m in matched_skills]
                level_sum = sum(skill_levels.get(user_skills[user_skills.index(m["user_skill"])], 3)
                               for m in matched_skills if m["user_skill"] in user_skills)
                proficiency_score = round(level_sum / len(matched_skills) / 5.0, 3) if matched_skills else 0.0

            # ì¤€ë¹„ë„ ì ìˆ˜ (ìˆ™ë ¨ë„ ë°˜ì˜)
            if proficiency_score > 0:
                readiness = round(match_rate * 0.5 + exp_fit * 0.2 + proficiency_score * 0.3, 3)
            else:
                readiness = round(match_rate * 0.7 + exp_fit * 0.3, 3)

            skill_gap = round(1.0 - match_rate, 3)

            # ì¶”ê°€ ì¸ì‚¬ì´íŠ¸
            insights = self._generate_insights(
                name, current_role, education, certifications,
                career_goals, available_prep_days,
                matched_skills, missing_skills, readiness, skill_gap
            )

            return Response({
                "readiness_score": readiness,
                "skill_gap_score": skill_gap,
                "experience_fit": exp_fit,
                "proficiency_score": proficiency_score,
                "matched_skills": matched_skills,
                "missing_skills": missing_skills,
                "insights": insights,
                "profile_summary": {
                    "name": name,
                    "current_role": current_role,
                    "education": education,
                    "certifications": certifications,
                    "career_goals": career_goals,
                    "available_prep_days": available_prep_days
                }
            }, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"âŒ ë¶„ì„ ì—ëŸ¬: {e}")
            print(traceback.format_exc())
            return Response({
                "error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _calculate_exp_fit(self, years, req_range):
        """ê²½ë ¥ ì í•©ë„ ê³„ì‚°"""
        import re
        nums = re.findall(r'\d+', req_range)
        if not nums:
            return 0.7

        lo = int(nums[0])
        hi = int(nums[-1]) if len(nums) > 1 else lo + 2

        if lo <= years <= hi:
            return 1.0
        elif years < lo:
            return max(0.0, years / lo)
        else:
            return max(0.7, 1.0 - (years - hi) * 0.05)

    def _generate_insights(self, name, current_role, education, certifications,
                          career_goals, available_prep_days,
                          matched_skills, missing_skills, readiness, skill_gap):
        """í”„ë¡œí•„ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []

        # ì¤€ë¹„ë„ ê¸°ë°˜ ì¡°ì–¸
        if readiness >= 0.7:
            insights.append({
                "type": "positive",
                "title": "ë†’ì€ ì¤€ë¹„ë„",
                "message": "í˜„ì¬ ìŠ¤í‚¬ì…‹ì´ ê³µê³  ìš”êµ¬ì‚¬í•­ê³¼ ì˜ ë§ìŠµë‹ˆë‹¤. ìì‹ ê°ì„ ê°–ê³  ì§€ì›í•˜ì„¸ìš”!"
            })
        elif readiness >= 0.5:
            insights.append({
                "type": "neutral",
                "title": "ì¤‘ê°„ ì¤€ë¹„ë„",
                "message": f"ë¶€ì¡±í•œ ìŠ¤í‚¬ {len(missing_skills)}ê°œë¥¼ ë³´ì™„í•˜ë©´ ê²½ìŸë ¥ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤."
            })
        else:
            insights.append({
                "type": "warning",
                "title": "ì¤€ë¹„ í•„ìš”",
                "message": "í•µì‹¬ ìŠ¤í‚¬ ë³´ì™„ì´ í•„ìš”í•©ë‹ˆë‹¤. ìš°ì„ ìˆœìœ„ë¥¼ ì •í•´ ì§‘ì¤‘ì ìœ¼ë¡œ í•™ìŠµí•˜ì„¸ìš”."
            })

        # ì¤€ë¹„ ê¸°ê°„ ì¡°ì–¸
        if available_prep_days:
            days = int(available_prep_days)
            if days < 7 and skill_gap > 0.4:
                insights.append({
                    "type": "warning",
                    "title": "ì‹œê°„ ë¶€ì¡±",
                    "message": f"ì¤€ë¹„ ê¸°ê°„({days}ì¼)ì´ ë¶€ì¡± ìŠ¤í‚¬ ìˆ˜({len(missing_skills)}ê°œ)ì— ë¹„í•´ ì§§ìŠµë‹ˆë‹¤. ê°€ì¥ ì¤‘ìš”í•œ ìŠ¤í‚¬ 1-2ê°œì— ì§‘ì¤‘í•˜ì„¸ìš”."
                })
            elif days >= 30:
                insights.append({
                    "type": "positive",
                    "title": "ì¶©ë¶„í•œ ì¤€ë¹„ ì‹œê°„",
                    "message": f"{days}ì¼ ë™ì•ˆ ì²´ê³„ì ìœ¼ë¡œ í•™ìŠµí•˜ë©´ ì¤€ë¹„ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                })

        # ìê²©ì¦ í™œìš©
        if certifications and len(certifications) > 0:
            insights.append({
                "type": "positive",
                "title": "ìê²©ì¦ ë³´ìœ ",
                "message": f"ë³´ìœ  ìê²©ì¦({', '.join(certifications)})ì„ ì´ë ¥ì„œì™€ ë©´ì ‘ì—ì„œ ì ê·¹ ì–´í•„í•˜ì„¸ìš”."
            })

        # ì»¤ë¦¬ì–´ ëª©í‘œ ì¼ì¹˜ì„±
        if career_goals:
            insights.append({
                "type": "neutral",
                "title": "ì»¤ë¦¬ì–´ ëª©í‘œ í™•ì¸",
                "message": f"ëª©í‘œ({career_goals})ì™€ ì´ í¬ì§€ì…˜ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•˜ì„¸ìš”."
            })

        # í˜„ì¬ ì§ë¬´ì™€ì˜ ì—°ê´€ì„±
        if current_role:
            insights.append({
                "type": "neutral",
                "title": "ê²½ë ¥ ì—°ì†ì„±",
                "message": f"í˜„ì¬ ì§ë¬´({current_role})ì™€ì˜ ì—°ê´€ì„±ì„ ë©´ì ‘ì—ì„œ ê°•ì¡°í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤."
            })

        return insights


@method_decorator(csrf_exempt, name='dispatch')
class JobPlannerAgentQuestionsView(APIView):
    """
    ë™ì  ì§ˆë¬¸ ìƒì„± API
    - ë¶€ì¡±í•œ ìŠ¤í‚¬ì— ëŒ€í•œ ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„±
    - ì‚¬ìš©ìì˜ í˜„ì¬ ìˆ˜ì¤€ê³¼ í•™ìŠµ ê³„íš íŒŒì•…
    """
    authentication_classes = []
    permission_classes = [AllowAny]

    def post(self, request):
        try:
            missing_skills = request.data.get('missing_skills', [])
            matched_skills = request.data.get('matched_skills', [])
            user_profile = request.data.get('user_profile', {})

            if not missing_skills:
                return Response({
                    "questions": [],
                    "message": "ë¶€ì¡±í•œ ìŠ¤í‚¬ì´ ì—†ì–´ ì¶”ê°€ ì§ˆë¬¸ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                }, status=status.HTTP_200_OK)

            # LLMìœ¼ë¡œ ë™ì  ì§ˆë¬¸ ìƒì„±
            questions = self._generate_questions_with_llm(
                missing_skills, matched_skills, user_profile
            )

            return Response({
                "questions": questions,
                "total_questions": len(questions)
            }, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ìƒì„± ì—ëŸ¬: {e}")
            print(traceback.format_exc())
            return Response({
                "error": f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _generate_questions_with_llm(self, missing_skills, matched_skills, user_profile):
        """LLMìœ¼ë¡œ ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„±"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            # Fallback: ê¸°ë³¸ ì§ˆë¬¸
            return [
                {
                    "id": f"q_{i}",
                    "skill": skill['required'],
                    "question": f"{skill['required']}ì— ëŒ€í•œ ê²½í—˜ì´ë‚˜ í•™ìŠµ ê³„íšì„ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                    "type": "text",
                    "required": True
                }
                for i, skill in enumerate(missing_skills[:3])
            ]

        try:
            client = openai.OpenAI(api_key=api_key)

            # ìµœëŒ€ 5ê°œ ìŠ¤í‚¬ê¹Œì§€ë§Œ ì§ˆë¬¸ ìƒì„±
            skills_to_ask = missing_skills[:5]

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ì»¤ë¦¬ì–´ ì½”ì¹­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë¶€ì¡±í•œ ìŠ¤í‚¬ì— ëŒ€í•´ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.
ì§ˆë¬¸ì€ ì‚¬ìš©ìì˜ í˜„ì¬ ìˆ˜ì¤€, í•™ìŠµ ê³„íš, ì¤€ë¹„ ì „ëµì„ íŒŒì•…í•˜ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤."""
                    },
                    {
                        "role": "user",
                        "content": f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”:

ë¶€ì¡±í•œ ìŠ¤í‚¬: {json.dumps([s['required'] for s in skills_to_ask], ensure_ascii=False)}
ë³´ìœ í•œ ìŠ¤í‚¬: {json.dumps([s['user_skill'] for s in matched_skills], ensure_ascii=False)}
ì‚¬ìš©ì í”„ë¡œí•„: {json.dumps(user_profile, ensure_ascii=False)}

ê° ë¶€ì¡±í•œ ìŠ¤í‚¬ì— ëŒ€í•´ 1ê°œì”© ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”. ì§ˆë¬¸ì€:
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì´ì–´ì•¼ í•¨
- í˜„ì¬ ìˆ˜ì¤€ íŒŒì•… ë˜ëŠ” í•™ìŠµ ê³„íš í™•ì¸
- í•œêµ­ì–´ë¡œ ì‘ì„±

JSON í˜•ì‹:
{{
  "questions": [
    {{
      "id": "q_0",
      "skill": "ìŠ¤í‚¬ëª…",
      "question": "ì§ˆë¬¸ ë‚´ìš©",
      "type": "text",
      "required": true
    }}
  ]
}}"""
                    }
                ],
                temperature=0.7
            )

            content = response.choices[0].message.content

            # JSON ì¶”ì¶œ
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0].strip()
            elif '```' in content:
                content = content.split('```')[1].split('```')[0].strip()

            data = json.loads(content)
            return data.get('questions', [])

        except Exception as e:
            print(f"âš ï¸  LLM ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            # Fallback
            return [
                {
                    "id": f"q_{i}",
                    "skill": skill['required'],
                    "question": f"{skill['required']}ì— ëŒ€í•œ ê²½í—˜ì´ë‚˜ í•™ìŠµ ê³„íšì„ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                    "type": "text",
                    "required": True
                }
                for i, skill in enumerate(skills_to_ask)
            ]


@method_decorator(csrf_exempt, name='dispatch')
class JobPlannerAgentReportView(APIView):
    """
    ìµœì¢… ì¢…í•© ë³´ê³ ì„œ ìƒì„± API
    - SWOT ë¶„ì„
    - ë©´ì ‘ ì˜ˆìƒ ì§ˆë¬¸ 5ê°œ
    - ê²½í—˜ í¬ì¥ ê°€ì´ë“œ
    - ì‹¤í–‰ ì „ëµ
    """
    authentication_classes = []
    permission_classes = [AllowAny]

    def post(self, request):
        try:
            # ë¶„ì„ ê²°ê³¼ ë°ì´í„°
            job_data = request.data.get('job_data', {})
            analysis_result = request.data.get('analysis_result', {})
            company_analysis = request.data.get('company_analysis', {})
            agent_answers = request.data.get('agent_answers', {})  # ì—ì´ì „íŠ¸ ì§ˆë¬¸ ë‹µë³€

            # LLMìœ¼ë¡œ ì¢…í•© ë³´ê³ ì„œ ìƒì„±
            report = self._generate_report_with_llm(
                job_data, analysis_result, company_analysis, agent_answers
            )

            return Response(report, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"âŒ ë³´ê³ ì„œ ìƒì„± ì—ëŸ¬: {e}")
            print(traceback.format_exc())
            return Response({
                "error": f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _generate_report_with_llm(self, job_data, analysis_result, company_analysis, agent_answers):
        """LLMìœ¼ë¡œ ìµœì¢… ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return {
                "error": "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "swot": {
                    "strengths": ["ìŠ¤í‚¬ ë§¤ì¹­ë¥ ì´ ë†’ìŠµë‹ˆë‹¤"],
                    "weaknesses": ["ì¼ë¶€ ìŠ¤í‚¬ì´ ë¶€ì¡±í•©ë‹ˆë‹¤"],
                    "opportunities": ["ì„±ì¥ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤"],
                    "threats": ["ê²½ìŸì´ ì¹˜ì—´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"]
                },
                "interview_questions": [],
                "experience_packaging": [],
                "execution_strategy": ""
            }

        try:
            client = openai.OpenAI(api_key=api_key)

            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = f"""
ì±„ìš©ê³µê³ :
- íšŒì‚¬: {job_data.get('company_name', 'ë¯¸ì •')}
- í¬ì§€ì…˜: {job_data.get('position', 'ê°œë°œì')}
- í•„ìˆ˜ ìŠ¤í‚¬: {', '.join(job_data.get('required_skills', []))}
- ìš°ëŒ€ ìŠ¤í‚¬: {', '.join(job_data.get('preferred_skills', []))}

ë¶„ì„ ê²°ê³¼:
- ì¤€ë¹„ë„: {analysis_result.get('readiness_score', 0)}
- ìŠ¤í‚¬ ê°­: {analysis_result.get('skill_gap_score', 0)}
- ë§¤ì¹­ëœ ìŠ¤í‚¬: {len(analysis_result.get('matched_skills', []))}ê°œ
- ë¶€ì¡±í•œ ìŠ¤í‚¬: {len(analysis_result.get('missing_skills', []))}ê°œ

ì‚¬ìš©ì í”„ë¡œí•„:
{json.dumps(analysis_result.get('profile_summary', {}), ensure_ascii=False)}

ì—ì´ì „íŠ¸ ì§ˆë¬¸ ë‹µë³€:
{json.dumps(agent_answers, ensure_ascii=False)}

ê¸°ì—… ë¶„ì„:
{json.dumps(company_analysis, ensure_ascii=False) if company_analysis else 'ì •ë³´ ì—†ìŒ'}
"""

            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ ì „ë¬¸ ì»¤ë¦¬ì–´ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì·¨ì—… ì¤€ë¹„ìƒì„ ìœ„í•œ ì¢…í•© ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤."""
                    },
                    {
                        "role": "user",
                        "content": f"""{context}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•œ ì¢…í•© ë³´ê³ ì„œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:

1. **SWOT ë¶„ì„**
   - Strengths: ê°•ì  3-5ê°œ (êµ¬ì²´ì ìœ¼ë¡œ)
   - Weaknesses: ì•½ì  2-4ê°œ (ë³´ì™„ ë°©ë²• í¬í•¨)
   - Opportunities: ê¸°íšŒ 2-3ê°œ
   - Threats: ìœ„í˜‘ ìš”ì†Œ 1-2ê°œ

2. **ë©´ì ‘ ì˜ˆìƒ ì§ˆë¬¸ 5ê°œ**
   - í•´ë‹¹ í¬ì§€ì…˜/íšŒì‚¬ì— íŠ¹í™”ëœ ì§ˆë¬¸
   - ë‹µë³€ ê°€ì´ë“œ í¬í•¨

3. **ê²½í—˜ í¬ì¥ ê°€ì´ë“œ**
   - ì´ë ¥ì„œ/í¬íŠ¸í´ë¦¬ì˜¤ì—ì„œ ê°•ì¡°í•  ì 
   - í”„ë¡œì íŠ¸ ê²½í—˜ ì–´í•„ ë°©ë²•
   - ë¶€ì¡±í•œ ìŠ¤í‚¬ì„ ë³´ì™„í•˜ëŠ” ë°©ë²•

4. **ì‹¤í–‰ ì „ëµ**
   - ë‹¨ê¸° (1-2ì£¼): ì¦‰ì‹œ í•  ì¼
   - ì¤‘ê¸° (1ê°œì›”): ìŠ¤í‚¬ ë³´ì™„
   - ì§€ì› ì‹œì : ìµœì  íƒ€ì´ë°

JSON í˜•ì‹:
{{
  "swot": {{
    "strengths": ["ê°•ì 1", "ê°•ì 2", ...],
    "weaknesses": ["ì•½ì 1 (ë³´ì™„: ...)", "ì•½ì 2 (ë³´ì™„: ...)", ...],
    "opportunities": ["ê¸°íšŒ1", "ê¸°íšŒ2", ...],
    "threats": ["ìœ„í˜‘1", "ìœ„í˜‘2", ...]
  }},
  "interview_questions": [
    {{
      "question": "ì§ˆë¬¸ ë‚´ìš©",
      "answer_guide": "ë‹µë³€ ê°€ì´ë“œ (3-5ë¬¸ì¥)",
      "tips": "ì¶”ê°€ íŒ"
    }},
    ...5ê°œ
  ],
  "experience_packaging": {{
    "resume_highlights": ["ì´ë ¥ì„œì— ê°•ì¡°í•  ì 1", "ê°•ì¡°í•  ì 2", ...],
    "portfolio_tips": ["í¬íŠ¸í´ë¦¬ì˜¤ íŒ1", "íŒ2", ...],
    "skill_compensation": ["ë¶€ì¡± ìŠ¤í‚¬ ë³´ì™„ë²•1", "ë³´ì™„ë²•2", ...]
  }},
  "execution_strategy": {{
    "immediate": ["ì¦‰ì‹œ í•  ì¼1", "í•  ì¼2", ...],
    "short_term": ["1-2ì£¼ ë‚´ í•  ì¼1", "í•  ì¼2", ...],
    "mid_term": ["1ê°œì›” ë‚´ í•  ì¼1", "í•  ì¼2", ...],
    "application_timing": "ìµœì  ì§€ì› ì‹œì  ë° ì´ìœ "
  }},
  "final_message": "ìµœì¢… ê²©ë ¤ ë©”ì‹œì§€ (2-3ë¬¸ì¥)"
}}"""
                    }
                ],
                temperature=0.7
            )

            content = response.choices[0].message.content

            # JSON ì¶”ì¶œ
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0].strip()
            elif '```' in content:
                content = content.split('```')[1].split('```')[0].strip()

            report = json.loads(content)
            return report

        except Exception as e:
            print(f"âš ï¸  LLM ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "error": f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}",
                "swot": {
                    "strengths": ["ë¶„ì„ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤"],
                    "weaknesses": [],
                    "opportunities": [],
                    "threats": []
                },
                "interview_questions": [],
                "experience_packaging": {
                    "resume_highlights": [],
                    "portfolio_tips": [],
                    "skill_compensation": []
                },
                "execution_strategy": {
                    "immediate": [],
                    "short_term": [],
                    "mid_term": [],
                    "application_timing": ""
                },
                "final_message": "ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ìƒì„¸ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }


@method_decorator(csrf_exempt, name='dispatch')
class JobPlannerRecommendView(APIView):
    """
    ì±„ìš©ê³µê³  ì¶”ì²œ API
    - ë§¤ì¹­ë¥ ì´ ë‚®ì„ ë•Œ (readiness_score < 0.6) ì¶”ì²œ ê³µê³  ì œê³µ
    - ì‚¬ëŒì¸, ì¡ì½”ë¦¬ì•„ ì‹¤ì œ í¬ë¡¤ë§
    - ì‚¬ìš©ì ìŠ¤í‚¬ ê¸°ë°˜ ë§¤ì¹­
    """
    authentication_classes = []
    permission_classes = [AllowAny]

    # JobPlannerAnalyzeViewì™€ ë™ì¼í•œ ìŠ¤í‚¬ ë™ì˜ì–´ ì‚¬ì „
    SKILL_SYNONYMS = JobPlannerAnalyzeView.SKILL_SYNONYMS

    def _normalize_skill(self, skill):
        """ìŠ¤í‚¬ëª…ì„ ì •ê·œí™” (í•œê¸€->ì˜ì–´, ì†Œë¬¸ì ë³€í™˜)"""
        skill_lower = skill.lower().strip()
        return self.SKILL_SYNONYMS.get(skill_lower, skill_lower)

    def post(self, request):
        try:
            if not CRAWLER_AVAILABLE or not EMBEDDING_AVAILABLE:
                return Response({
                    "error": "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

            # ì‚¬ìš©ì ì •ë³´
            user_skills = request.data.get('user_skills', [])
            skill_levels = request.data.get('skill_levels', {})
            readiness_score = float(request.data.get('readiness_score', 0.0))
            job_position = request.data.get('job_position', 'ê°œë°œì')  # ê´€ì‹¬ ì§ë¬´

            # í˜„ì¬ ë¶„ì„ ì¤‘ì¸ ê³µê³  ì •ë³´ (ì¤‘ë³µ ì œê±°ìš©)
            current_job_url = request.data.get('current_job_url', '')
            current_job_company = request.data.get('current_job_company', '')
            current_job_title = request.data.get('current_job_title', '')

            if not user_skills:
                return Response({
                    "error": "ì‚¬ìš©ì ìŠ¤í‚¬ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                }, status=status.HTTP_400_BAD_REQUEST)

            print(f"ğŸ” ì¶”ì²œ ê³µê³  ê²€ìƒ‰ ì‹œì‘ (ì¤€ë¹„ë„: {readiness_score}, ìŠ¤í‚¬: {user_skills})")
            if current_job_url:
                print(f"ğŸš« ì œì™¸í•  ê³µê³ : {current_job_company} - {current_job_title}")

            # 1. ì‚¬ëŒì¸ê³¼ ì¡ì½”ë¦¬ì•„ì—ì„œ ê³µê³  í¬ë¡¤ë§ (ì •í™•ë„ìˆœ, ê° ìµœëŒ€ 15ê°œ)
            job_listings = []

            # ì‚¬ëŒì¸ í¬ë¡¤ë§
            saramin_jobs = self._crawl_saramin(job_position)
            job_listings.extend(saramin_jobs)
            print(f"âœ… ì‚¬ëŒì¸: {len(saramin_jobs)}ê°œ ê³µê³ ")

            # ì¡ì½”ë¦¬ì•„ í¬ë¡¤ë§
            jobkorea_jobs = self._crawl_jobkorea(job_position)
            job_listings.extend(jobkorea_jobs)
            print(f"âœ… ì¡ì½”ë¦¬ì•„: {len(jobkorea_jobs)}ê°œ ê³µê³ ")

            if not job_listings:
                return Response({
                    "recommendations": [],
                    "message": "í˜„ì¬ ì¶”ì²œ ê°€ëŠ¥í•œ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤."
                }, status=status.HTTP_200_OK)

            # 1.5. ì‚¬ìš©ìê°€ ì´ë¯¸ ë¶„ì„í•œ ê³µê³  ì œì™¸
            filtered_listings = self._filter_duplicate_jobs(
                job_listings, current_job_url, current_job_company, current_job_title
            )
            print(f"ğŸ” ì¤‘ë³µ ì œê±° í›„: {len(filtered_listings)}ê°œ ê³µê³ ")

            # 2. ìŠ¤í‚¬ ë§¤ì¹­ìœ¼ë¡œ ì¶”ì²œ ê³µê³  ì„ ì •
            recommendations = self._match_jobs_with_skills(
                filtered_listings, user_skills, skill_levels, readiness_score
            )

            print(f"âœ… ìµœì¢… ì¶”ì²œ: {len(recommendations)}ê°œ")

            return Response({
                "recommendations": recommendations[:10],  # ìµœëŒ€ 10ê°œ
                "total_found": len(job_listings),
                "total_recommendations": len(recommendations)
            }, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"âŒ ì¶”ì²œ ì—ëŸ¬: {e}")
            print(traceback.format_exc())
            return Response({
                "error": f"ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _filter_duplicate_jobs(self, job_listings, current_url, current_company, current_title):
        """ì‚¬ìš©ìê°€ ì´ë¯¸ ë¶„ì„í•œ ê³µê³ ë¥¼ ì œì™¸"""
        filtered = []

        for job in job_listings:
            # URLì´ ì •í™•íˆ ì¼ì¹˜í•˜ë©´ ì œì™¸
            if current_url and job.get('url') == current_url:
                print(f"  âŒ URL ì¤‘ë³µ ì œì™¸: {job['title']}")
                continue

            # íšŒì‚¬ëª… + ì œëª©ì´ ë§¤ìš° ìœ ì‚¬í•˜ë©´ ì œì™¸
            if current_company and current_title:
                job_company = job.get('company_name', '').lower().strip()
                job_title = job.get('title', '').lower().strip()
                curr_company = current_company.lower().strip()
                curr_title = current_title.lower().strip()

                # íšŒì‚¬ëª…ê³¼ ì œëª©ì´ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
                if (curr_company in job_company or job_company in curr_company) and \
                   (curr_title in job_title or job_title in curr_title):
                    print(f"  âŒ ì œëª© ì¤‘ë³µ ì œì™¸: {job['company_name']} - {job['title']}")
                    continue

            filtered.append(job)

        return filtered

    def _crawl_saramin(self, job_position):
        """ì‚¬ëŒì¸ì—ì„œ ì±„ìš©ê³µê³  í¬ë¡¤ë§ (ì •í™•ë„ìˆœ)"""
        jobs = []
        try:
            # ì‚¬ëŒì¸ ê²€ìƒ‰ URL (ì •í™•ë„ìˆœ - ê¸°ë³¸ê°’)
            # searchType=search : í†µí•©ê²€ìƒ‰
            # ì •í™•ë„ìˆœì´ ê¸°ë³¸ì´ë¯€ë¡œ sort íŒŒë¼ë¯¸í„° ìƒëµ
            search_url = f"https://www.saramin.co.kr/zf_user/search?searchType=search&searchword={job_position}"

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }

            response = requests.get(search_url, headers=headers, timeout=15)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, 'html.parser')

            # ì±„ìš©ê³µê³  ì•„ì´í…œ ì°¾ê¸° (ì‹¤ì œ HTML êµ¬ì¡°ì— ë§ê²Œ ì¡°ì • í•„ìš”)
            job_items = soup.select('.item_recruit')[:15]  # ìµœëŒ€ 15ê°œ

            for item in job_items:
                try:
                    # íšŒì‚¬ëª…
                    company_elem = item.select_one('.corp_name a')
                    company_name = company_elem.get_text(strip=True) if company_elem else "ì•Œ ìˆ˜ ì—†ìŒ"

                    # ì±„ìš© ì œëª©
                    title_elem = item.select_one('.job_tit a')
                    title = title_elem.get_text(strip=True) if title_elem else "ì±„ìš© ê³µê³ "
                    job_url = "https://www.saramin.co.kr" + title_elem['href'] if title_elem and title_elem.get('href') else ""

                    # ì¡°ê±´ (ê²½ë ¥, í•™ë ¥ ë“±)
                    conditions = item.select('.job_condition span')
                    conditions_text = [c.get_text(strip=True) for c in conditions]

                    # ìŠ¤í‚¬/ê¸°ìˆ  ìŠ¤íƒ
                    skills_elem = item.select('.job_sector a')
                    skills = [s.get_text(strip=True) for s in skills_elem]

                    # ì§€ì—­
                    location_elem = item.select_one('.job_condition span:first-child')
                    location = location_elem.get_text(strip=True) if location_elem else ""

                    jobs.append({
                        "source": "ì‚¬ëŒì¸",
                        "company_name": company_name,
                        "title": title,
                        "url": job_url,
                        "skills": skills if skills else [],
                        "location": location,
                        "conditions": conditions_text,
                        "description": f"{title} - {company_name}"
                    })

                except Exception as e:
                    print(f"âš ï¸  ì‚¬ëŒì¸ ì•„ì´í…œ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue

        except Exception as e:
            print(f"âš ï¸  ì‚¬ëŒì¸ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

        return jobs

    def _crawl_jobkorea(self, job_position):
        """ì¡ì½”ë¦¬ì•„ì—ì„œ ì±„ìš©ê³µê³  í¬ë¡¤ë§ (ì •í™•ë„ìˆœ)"""
        jobs = []
        try:
            # ì¡ì½”ë¦¬ì•„ ê²€ìƒ‰ URL (ì •í™•ë„ìˆœ - ê¸°ë³¸ê°’)
            search_url = f"https://www.jobkorea.co.kr/Search/?stext={job_position}"

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }

            response = requests.get(search_url, headers=headers, timeout=15)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, 'html.parser')

            # ì±„ìš©ê³µê³  ì•„ì´í…œ ì°¾ê¸°
            job_items = soup.select('.list-post article')[:15]  # ìµœëŒ€ 15ê°œ

            for item in job_items:
                try:
                    # íšŒì‚¬ëª…
                    company_elem = item.select_one('.name')
                    company_name = company_elem.get_text(strip=True) if company_elem else "ì•Œ ìˆ˜ ì—†ìŒ"

                    # ì±„ìš© ì œëª©
                    title_elem = item.select_one('.title a')
                    title = title_elem.get_text(strip=True) if title_elem else "ì±„ìš© ê³µê³ "
                    job_url = title_elem['href'] if title_elem and title_elem.get('href') else ""
                    if job_url and not job_url.startswith('http'):
                        job_url = "https://www.jobkorea.co.kr" + job_url

                    # ì¡°ê±´
                    conditions_elem = item.select('.option li')
                    conditions = [c.get_text(strip=True) for c in conditions_elem]

                    # ê¸°ìˆ  ìŠ¤íƒ (ìˆìœ¼ë©´)
                    skills_elem = item.select('.etc .tag')
                    skills = [s.get_text(strip=True) for s in skills_elem]

                    # ì§€ì—­
                    location = conditions[0] if conditions else ""

                    jobs.append({
                        "source": "ì¡ì½”ë¦¬ì•„",
                        "company_name": company_name,
                        "title": title,
                        "url": job_url,
                        "skills": skills if skills else [],
                        "location": location,
                        "conditions": conditions,
                        "description": f"{title} - {company_name}"
                    })

                except Exception as e:
                    print(f"âš ï¸  ì¡ì½”ë¦¬ì•„ ì•„ì´í…œ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue

        except Exception as e:
            print(f"âš ï¸  ì¡ì½”ë¦¬ì•„ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

        return jobs

    def _match_jobs_with_skills(self, job_listings, user_skills, skill_levels, readiness_score):
        """ì‚¬ìš©ì ìŠ¤í‚¬ê³¼ ê³µê³  ë§¤ì¹­"""
        model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        threshold = 0.50  # 0.55 â†’ 0.50ìœ¼ë¡œ ë‚®ì¶¤ (ë¶„ì„ê³¼ ë™ì¼)

        # ì‚¬ìš©ì ìŠ¤í‚¬ ì •ê·œí™”
        user_skills_normalized = [self._normalize_skill(s) for s in user_skills]

        recommendations = []
        user_emb = model.encode(user_skills_normalized, normalize_embeddings=True)

        for job in job_listings:
            job_skills = job.get('skills', [])

            # ìŠ¤í‚¬ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì œëª©/ì„¤ëª…ì—ì„œ ì¶”ì¶œ ì‹œë„
            if not job_skills:
                job_text = f"{job['title']} {job['description']}"
                # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” LLM ì‚¬ìš© ê°€ëŠ¥)
                common_skills = ['Python', 'Java', 'JavaScript', 'React', 'Vue', 'Django',
                                'Spring', 'Node.js', 'Docker', 'Kubernetes', 'AWS', 'GCP']
                job_skills = [skill for skill in common_skills if skill.lower() in job_text.lower()]

            if not job_skills:
                # ìŠ¤í‚¬ ì •ë³´ê°€ ì „í˜€ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                continue

            # ê³µê³  ìŠ¤í‚¬ ì •ê·œí™”
            job_skills_normalized = [self._normalize_skill(s) for s in job_skills]

            # ìŠ¤í‚¬ ë§¤ì¹­
            job_emb = model.encode(job_skills_normalized, normalize_embeddings=True)
            sim_matrix = user_emb @ job_emb.T

            # í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
            avg_similarity = float(sim_matrix.max(axis=0).mean())

            # ë§¤ì¹­ëœ ìŠ¤í‚¬ ì°¾ê¸°
            matched_count = 0
            matched_skills = []
            for i, job_skill in enumerate(job_skills):
                best_idx = sim_matrix[:, i].argmax()
                best_score = float(sim_matrix[best_idx, i])
                if best_score >= threshold:
                    matched_count += 1
                    matched_skills.append({
                        "job_skill": job_skill,
                        "user_skill": user_skills[best_idx],
                        "similarity": round(best_score, 3)
                    })

            # ë§¤ì¹­ë¥  ê³„ì‚°
            match_rate = matched_count / len(job_skills) if job_skills else 0

            # í˜„ì¬ ì¤€ë¹„ë„ë³´ë‹¤ ë†’ì€ ë§¤ì¹­ë¥ ì„ ê°€ì§„ ê³µê³ ë§Œ ì¶”ì²œ
            # ë˜ëŠ” ë§¤ì¹­ë¥ ì´ ë¹„ìŠ·í•˜ì§€ë§Œ ë°°ìš¸ ë§Œí•œ ìƒˆë¡œìš´ ìŠ¤í‚¬ì´ ìˆëŠ” ê²½ìš°
            if match_rate > readiness_score or (match_rate >= readiness_score * 0.9 and match_rate < 0.95):
                recommendations.append({
                    "source": job.get('source', ''),
                    "company_name": job['company_name'],
                    "title": job['title'],
                    "url": job['url'],
                    "skills": job_skills,
                    "location": job.get('location', ''),
                    "match_rate": round(match_rate, 3),
                    "avg_similarity": round(avg_similarity, 3),
                    "matched_skills": matched_skills,
                    "matched_count": matched_count,
                    "total_skills": len(job_skills),
                    "reason": self._generate_recommendation_reason(match_rate, readiness_score, matched_count, len(job_skills))
                })

        # ë§¤ì¹­ë¥  ìˆœìœ¼ë¡œ ì •ë ¬
        recommendations.sort(key=lambda x: x['match_rate'], reverse=True)

        return recommendations

    def _generate_recommendation_reason(self, match_rate, readiness_score, matched_count, total_skills):
        """ì¶”ì²œ ì´ìœ  ìƒì„±"""
        if match_rate > readiness_score + 0.2:
            return f"í˜„ì¬ë³´ë‹¤ {int((match_rate - readiness_score) * 100)}% ë†’ì€ ë§¤ì¹­ë¥ ë¡œ ë” ì í•©í•œ ê³µê³ ì…ë‹ˆë‹¤."
        elif match_rate > readiness_score + 0.1:
            return f"ë³´ìœ  ìŠ¤í‚¬ê³¼ ì˜ ë§ê³ , {matched_count}/{total_skills}ê°œ ìŠ¤í‚¬ì´ ì¼ì¹˜í•©ë‹ˆë‹¤."
        else:
            return f"í˜„ì¬ ìˆ˜ì¤€ê³¼ ë¹„ìŠ·í•˜ë©´ì„œ ìƒˆë¡œìš´ ê¸°ìˆ ì„ ë°°ìš¸ ìˆ˜ ìˆëŠ” ê¸°íšŒì…ë‹ˆë‹¤."


@method_decorator(csrf_exempt, name='dispatch')
class JobPlannerCompanyAnalyzeView(APIView):
    """
    ê¸°ì—… ë¶„ì„ API
    - URL í¬ë¡¤ë§ ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥ìœ¼ë¡œ íšŒì‚¬ ì •ë³´ ìˆ˜ì§‘
    - LLMìœ¼ë¡œ ì¢…í•© ë¶„ì„:
      1. íšŒì‚¬ ê°œìš” ë° ë¹„ì „
      2. ê¸°ìˆ  ìŠ¤íƒ ë° ê°œë°œ ë¬¸í™”
      3. ì„±ì¥ì„± ë° ì•ˆì •ì„±
      4. ë³µì§€ ë° ê·¼ë¬´í™˜ê²½
    """
    authentication_classes = []
    permission_classes = [AllowAny]

    def post(self, request):
        try:
            input_type = request.data.get('type')  # 'url' or 'text'
            company_name = request.data.get('company_name', 'íšŒì‚¬')

            # íšŒì‚¬ ì •ë³´ ìˆ˜ì§‘
            if input_type == 'url':
                company_info = self._fetch_from_url(request.data.get('url'))
            elif input_type == 'text':
                company_info = request.data.get('text', '')
            else:
                return Response({
                    "error": "Invalid input type. Use 'url' or 'text'."
                }, status=status.HTTP_400_BAD_REQUEST)

            # LLMìœ¼ë¡œ ì¢…í•© ë¶„ì„
            analysis = self._analyze_company_with_llm(company_name, company_info)

            return Response(analysis, status=status.HTTP_200_OK)

        except Exception as e:
            print(f"âŒ ê¸°ì—…ë¶„ì„ ì—ëŸ¬: {e}")
            print(traceback.format_exc())
            return Response({
                "error": f"ê¸°ì—…ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def _fetch_from_url(self, url):
        """URLì—ì„œ íšŒì‚¬ ì •ë³´ í¬ë¡¤ë§"""
        if not CRAWLER_AVAILABLE:
            raise Exception("í¬ë¡¤ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        if not url:
            raise Exception("URLì´ í•„ìš”í•©ë‹ˆë‹¤.")

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'html.parser')

        # ìŠ¤í¬ë¦½íŠ¸ì™€ ìŠ¤íƒ€ì¼ ì œê±°
        for script in soup(["script", "style"]):
            script.decompose()

        text = soup.get_text(separator='\n', strip=True)
        return text

    def _analyze_company_with_llm(self, company_name, company_info):
        """LLMìœ¼ë¡œ ê¸°ì—… ì¢…í•© ë¶„ì„"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return {
                "error": "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "company_name": company_name,
                "overview": "",
                "tech_stack": {},
                "growth": {},
                "welfare": {}
            }

        try:
            client = openai.OpenAI(api_key=api_key)

            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ IT ê¸°ì—… ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
íšŒì‚¬ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ 4ê°€ì§€ í•­ëª©ì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
1. íšŒì‚¬ ê°œìš” ë° ë¹„ì „
2. ê¸°ìˆ  ìŠ¤íƒ ë° ê°œë°œ ë¬¸í™”
3. ì„±ì¥ì„± ë° ì•ˆì •ì„±
4. ë³µì§€ ë° ê·¼ë¬´í™˜ê²½

ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ì¼ë°˜ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”."""
                    },
                    {
                        "role": "user",
                        "content": f"""ë‹¤ìŒ íšŒì‚¬ ì •ë³´ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:

íšŒì‚¬ëª…: {company_name}

ì •ë³´:
{company_info[:3000]}

JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
{{
  "company_name": "{company_name}",
  "overview": {{
    "description": "íšŒì‚¬ ì†Œê°œ (2-3ë¬¸ì¥)",
    "vision": "ë¹„ì „ ë° ë¯¸ì…˜",
    "industry": "ì‚°ì—… ë¶„ì•¼",
    "founded_year": "ì„¤ë¦½ì—°ë„ (ì•Œ ìˆ˜ ì—†ìœ¼ë©´ null)",
    "size": "íšŒì‚¬ ê·œëª¨ (ì˜ˆ: 50-100ëª…)"
  }},
  "tech_stack": {{
    "languages": ["ì£¼ìš” í”„ë¡œê·¸ë˜ë° ì–¸ì–´"],
    "frameworks": ["ì£¼ìš” í”„ë ˆì„ì›Œí¬"],
    "tools": ["ê°œë°œ ë„êµ¬ ë° í˜‘ì—… íˆ´"],
    "culture": "ê°œë°œ ë¬¸í™” ì„¤ëª… (2-3ë¬¸ì¥)",
    "tech_blog": "ê¸°ìˆ  ë¸”ë¡œê·¸ í™œë™ ì—¬ë¶€ ë° í‰ê°€"
  }},
  "growth": {{
    "funding": "íˆ¬ì ìœ ì¹˜ í˜„í™©",
    "market_position": "ì‹œì¥ ìœ„ì¹˜ ë° ê²½ìŸë ¥",
    "growth_potential": "ì„±ì¥ ê°€ëŠ¥ì„± í‰ê°€ (ìƒ/ì¤‘/í•˜)",
    "stability": "ì•ˆì •ì„± í‰ê°€ (ìƒ/ì¤‘/í•˜)"
  }},
  "welfare": {{
    "salary_level": "ì—°ë´‰ ìˆ˜ì¤€ (í‰ê·  ë˜ëŠ” ë²”ìœ„)",
    "benefits": ["ë³µì§€ í˜œíƒ ë¦¬ìŠ¤íŠ¸"],
    "work_life_balance": "ì›Œë¼ë°¸ í‰ê°€ ë° ì„¤ëª…",
    "remote_work": "ë¦¬ëª¨íŠ¸ ê·¼ë¬´ ê°€ëŠ¥ ì—¬ë¶€"
  }},
  "overall_score": {{
    "tech_score": 0.0-1.0,
    "growth_score": 0.0-1.0,
    "welfare_score": 0.0-1.0,
    "total_score": 0.0-1.0
  }},
  "recommendation": "ì´ íšŒì‚¬ì— ì§€ì›í•˜ë©´ ì¢‹ì€ ì´ìœ  ë˜ëŠ” ì£¼ì˜ì‚¬í•­ (3-4ë¬¸ì¥)"
}}"""
                    }
                ],
                temperature=0.5
            )

            content = response.choices[0].message.content

            # JSON ì¶”ì¶œ
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0].strip()
            elif '```' in content:
                content = content.split('```')[1].split('```')[0].strip()

            analysis = json.loads(content)
            return analysis

        except Exception as e:
            print(f"âš ï¸  LLM ê¸°ì—…ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "error": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}",
                "company_name": company_name,
                "overview": {"description": "ì •ë³´ ë¶€ì¡±", "vision": "", "industry": "", "founded_year": None, "size": ""},
                "tech_stack": {"languages": [], "frameworks": [], "tools": [], "culture": "", "tech_blog": ""},
                "growth": {"funding": "", "market_position": "", "growth_potential": "ì¤‘", "stability": "ì¤‘"},
                "welfare": {"salary_level": "", "benefits": [], "work_life_balance": "", "remote_work": ""},
                "overall_score": {"tech_score": 0.5, "growth_score": 0.5, "welfare_score": 0.5, "total_score": 0.5},
                "recommendation": "ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
