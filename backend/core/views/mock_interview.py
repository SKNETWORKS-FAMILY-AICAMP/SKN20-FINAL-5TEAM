"""
ì‘ì„±ì¼: 2026-02-21
ìˆ˜ì •ì¼: 2026-02-22
ìˆ˜ì •ì: ìˆ˜ì„ ì—ì´ì „íŠ¸
ì‘ì„±ë‚´ìš©: 
- AI-GYM í”„ë¡œì íŠ¸ì˜ ëª¨ì˜ ë©´ì ‘ ì‹œìŠ¤í…œ ë°±ì—”ë“œ API
- [ìˆ˜ì •ë‚´ìš©] Multi-Agent ì•„í‚¤í…ì²˜ ë„ì… (Analyst + Interviewer)
- 1ë‹¨ê³„: Analystê°€ ìœ ì € ë°ì´í„°(Job Planner + Code + History)ë¥¼ ë¶„ì„í•´ ê³µê²© ë²¡í„°(Attack Vector) ë„ì¶œ
- 2ë‹¨ê³„: Interviewer(ë„ë•)ê°€ ê³µê²© ë²¡í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„±
"""
import time
import json
import os
from django.http import StreamingHttpResponse, JsonResponse
from django.views.decorators.csrf import csrf_exempt
from openai import OpenAI
from django.conf import settings

from core.models.user_model import UserProfile
from core.models.activity_model import UserSolvedProblem

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# ==========================================
# 1. Analyst Agent (ë¶„ì„ê°€ í˜ë¥´ì†Œë‚˜)
# ==========================================
def run_analyst_agent(request, job_planner_data=None, user_msg=None, history=None):
    """
    ìœ ì € ëˆˆì— ë³´ì´ì§€ ì•ŠëŠ” ë°±ê·¸ë¼ìš´ë“œ AI (Analyst)
    ìœ ì €ì˜ ê³¼ê±° ì½”ë“œ ì´ë ¥, ì§€ì› íšŒì‚¬ ì •ë³´, í˜„ì¬ ëŒ€í™” ë§¥ë½ì„ ë¶„ì„í•˜ì—¬
    'ë„ë•(ë©´ì ‘ê´€)'ì´ ê³µê²©í•´ì•¼ í•  ë‹¨ 1ê°œì˜ í•µì‹¬ ì•½ì (Attack Vector)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    context_str = ""
    job_str = ""

    # 1) ì§€ì› íšŒì‚¬ ì •ë³´ ì¶”ì¶œ
    if job_planner_data:
        job_data = job_planner_data.get('jobData', {})
        if job_data:
            company_name = job_data.get('company_name', 'íŠ¹ì • íšŒì‚¬')
            position_name = job_data.get('position', 'íŠ¹ì • ì§ë¬´')
            req_skills = job_data.get('required_skills', [])
            skills_str = ', '.join(req_skills) if req_skills else 'ê´€ë ¨ ê¸°ìˆ '
            
            job_str = f"[ì§€ì› íšŒì‚¬: {company_name}] | [í¬ì§€ì…˜: {position_name}] | [ìš”êµ¬ ê¸°ìˆ : {skills_str}]\n"

    # 2) ê³¼ê±° ì½”ë“œ ì´ë ¥ ì¶”ì¶œ
    user = request.user if request.user.is_authenticated else None
    if user:
        try:
            recent_solved = UserSolvedProblem.objects.filter(
                user=user
            ).select_related('practice_detail', 'practice_detail__practice').order_by('-solved_date')[:5]
            
            if recent_solved.exists():
                for sp in recent_solved:
                    unit_name = sp.practice_detail.practice.title if sp.practice_detail and sp.practice_detail.practice else "ë¯¸ìƒ"
                    score = sp.score
                    code_snippet = ""
                    if sp.submitted_data and isinstance(sp.submitted_data, dict):
                        code_snippet = str(sp.submitted_data.get('code', ''))[:200]
                    context_str += f"- ìœ ë‹›: {unit_name}, ì ìˆ˜: {score}ì , ì½”ë“œ ìš”ì•½: {code_snippet}...\n"
        except Exception as e:
            print(f"Failed to fetch user context for Analyst: {e}")
            pass

    # 3) íˆìŠ¤í† ë¦¬ ìš”ì•½
    history_str = ""
    if history:
        # ìµœê·¼ 3~4ê°œì˜ ëŒ€í™”ë§Œ ë¶„ì„ì— í™œìš©
        recent_history = history[-4:]
        for h in recent_history:
            role = 'ë©´ì ‘ê´€' if h['role'] == 'assistant' else 'ì§€ì›ì'
            history_str += f"{role}: {h['content']}\n"
    if user_msg:
        history_str += f"ì§€ì›ì(í˜„ì¬ë‹µë³€): {user_msg}\n"

    analyst_prompt = f"""ë‹¹ì‹ ì€ AI-GYMì˜ ì‹¬ì¸µ ë©´ì ‘ ë¶„ì„ê°€(Analyst)ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì•„ë˜ ì œê³µëœ ë°ì´í„°ë“¤ì„ ë¶„ì„í•˜ì—¬, ìµœì¢… ë©´ì ‘ê´€(ë„ë•)ì´ ì§€ì›ìì—ê²Œ ë˜ì ¸ì•¼ í•  **ë‹¨ 1ê°œì˜ ê°€ì¥ ë‚ ì¹´ë¡­ê³  ì˜ˆë¦¬í•œ ì§ˆë¬¸ ë°©í–¥(Attack Vector)**ì„ ì„¤ê³„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

[ë°ì´í„°]
1. ì§€ì› íšŒì‚¬ ì •ë³´: {job_str if job_str else "ì—†ìŒ (ì¼ë°˜ CS ë©´ì ‘ìœ¼ë¡œ ì§„í–‰)"}
2. ì§€ì›ìì˜ ê³¼ê±° ì½”ë“œ(Python) ì´ë ¥:
{context_str if context_str else "ê³¼ê±° ì½”ë“œ ì •ë³´ ì—†ìŒ"}
3. ìµœê·¼ ë©´ì ‘ ëŒ€í™” íë¦„:
{history_str if history_str else "ë©´ì ‘ ì‹œì‘ ì „ì…ë‹ˆë‹¤."}

[ë¶„ì„ ê·œì¹™]
1. ë‹¨ìˆœí•œ ì§€ì‹ í™•ì¸ì„ ë„˜ì–´ì„œ, 'ì§€ì› íšŒì‚¬ì˜ ìš”êµ¬ ê¸°ìˆ 'ê³¼ 'ì§€ì›ìì˜ ì½”ë“œ ì•½ì ' ë˜ëŠ” 'í˜„ì¬ ë‹µë³€ì˜ í—ˆì 'ì„ êµë¬˜í•˜ê²Œ ì—®ìœ¼ì„¸ìš”.
2. ì˜ˆì‹œ: íšŒì‚¬ê°€ í”„ë¡ íŠ¸ì—”ë“œ(React)ë¥¼ ìš”êµ¬í•˜ëŠ”ë° ì§€ì›ì ì½”ë“œê°€ íŒŒì´ì¬ ê¸°ì´ˆì¸ ê²½ìš° -> íŒŒì´ì¬ì„ ì–µì§€ë¡œ ë¬»ì§€ ë§ê³ , "ê³¼ê±° ì½”ë“œì—ì„œ ìƒíƒœ ê´€ë¦¬ê°€ ë¯¸í¡í–ˆëŠ”ë°, ì´ë¥¼ í”„ë¡ íŠ¸ì—”ë“œì˜ React ì»´í¬ë„ŒíŠ¸ í™˜ê²½ì—ì„œëŠ” ì–´ë–»ê²Œ ì•ˆì •ì ìœ¼ë¡œ ì„¤ê³„í•  ê±´ê°€?" ì‹ìœ¼ë¡œ ì¹˜í™˜í•´ì„œ ê³µê²©í•˜ì„¸ìš”.
3. ì§€ì›ìê°€ ì˜¤ë‹µì„ ëƒˆê±°ë‚˜ ëŒ€ë‹µì´ ë¹ˆì•½í•˜ë©´ ì§‘ìš”í•˜ê²Œ íŒŒê³ ë“œëŠ” ë°©í–¥ì„ ì œì‹œí•˜ì„¸ìš”.
4. ì˜ˆì˜ë¥¼ ì°¨ë¦´ í•„ìš” ì—†ìŠµë‹ˆë‹¤. ì˜¤ì§ ë‚ ì¹´ë¡œìš´ ë‹¨ 1ê°œì˜ ê³µê²© í¬ì¸íŠ¸ë§Œ ì„œìˆ í•˜ì„¸ìš”.
5. ë°˜ë“œì‹œ JSON í¬ë§·ìœ¼ë¡œ "attack_vector" í‚¤ í•˜ë‚˜ë§Œ í¬í•¨í•˜ì—¬ ë°˜í™˜í•˜ì„¸ìš”.

ì¶œë ¥ ì˜ˆì‹œ:
{{
  "attack_vector": "ì§€ì›ìëŠ” ì§ì „ ë‹µë³€ì—ì„œ ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ë‘ë£¨ë­‰ìˆ í•˜ê²Œ ì–¼ë²„ë¬´ë ¸ìŒ. ê³¼ê±° íŒŒì´ì¬ ì½”ë“œì—ì„œë„ ì˜ˆì™¸ ì²˜ë¦¬ê°€ ì „í˜€ ì•ˆ ë˜ì–´ ìˆì—ˆìŒì„ ì§€ì í•˜ê³ , ì§€ì›í•˜ëŠ” AíšŒì‚¬ì˜ ëŒ€ê·œëª¨ íŠ¸ë˜í”½ í™˜ê²½ì—ì„œ ì—ëŸ¬ í—¨ë“¤ë§ì´ ëˆ„ë½ë˜ì—ˆì„ ë•Œì˜ ì¹˜ëª…ì ì¸ ì‚¬ì´ë“œ ì´í™íŠ¸ë¥¼ ë¬»ëŠ” ì••ë°• ì§ˆë¬¸ì„ ë˜ì§€ì‹œì˜¤."
}}
"""
    try:
        response = client.chat.completions.create(
            model="gpt-5",
            messages=[{"role": "user", "content": analyst_prompt}],
            response_format={ "type": "json_object" }
        )
        result = json.loads(response.choices[0].message.content)
        attack_vector = result.get("attack_vector", "ì§€ì›ìì˜ ì´ë ¥ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬ ê¸°ìˆ  ì§ˆë¬¸ì„ 1ê°œ ë˜ì§€ì„¸ìš”.")
        print(f"\nğŸ•µï¸ [Analyst] ì¶”ì¶œëœ ê³µê²© ë²¡í„°:\n{attack_vector}\n")
        return attack_vector
    except Exception as e:
        print(f"Analyst Error: {e}")
        return "ì§€ì›ìì˜ ëŒ€ë‹µì„ ë°”íƒ•ìœ¼ë¡œ ê¼¬ë¦¬ ì§ˆë¬¸ì„ ë˜ì§€ì„¸ìš”."


# ==========================================
# 2. Interviewer Agent (ë©´ì ‘ê´€ í˜ë¥´ì†Œë‚˜ - ìŠ¤íŠ¸ë¦¬ë°)
# ==========================================
def get_interviewer_prompt(attack_vector):
    """
    Interviewer ì—ì´ì „íŠ¸ëŠ” ì‚¬ìš©ìì™€ ì§ì ‘ ëŒ€ë©´í•˜ì—¬ ë©´ì ‘ì„ ì§„í–‰í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.
    Analystê°€ ë¶„ì„í•´ì¤€ ê³µê²© ë²¡í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‹¤ì œ ë©´ì ‘ê´€ì²˜ëŸ¼ ì§ˆë¬¸ì„ ë˜ì§‘ë‹ˆë‹¤.
    """
    return f"""ë‹¹ì‹ ì€ AI ê°œë°œì ëª¨ì˜ë©´ì ‘ê´€ '{os.environ.get("INTERVIEWER_PERSONA", "ë„ë•")}' ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì€ ì§€ì›ìì˜ ê¸°ìˆ ì  ê¹Šì´ë¥¼ ì² ì €í•˜ê²Œ ê²€ì¦í•˜ëŠ” ê¹ê¹í•˜ê³  ì˜ˆë¦¬í•œ ì‹œë‹ˆì–´ ìˆ˜ì„ ì•„í‚¤í…íŠ¸ì…ë‹ˆë‹¤. 
ë§íˆ¬ëŠ” ë§¤ìš° ì •ì¤‘í•˜ì§€ë§Œ, ì§ˆë¬¸ì˜ ë‚´ìš©ì€ ë‚ ì¹´ë¡­ê³  ì§‘ìš”í•´ì•¼ í•©ë‹ˆë‹¤. 
ì ˆëŒ€ë¡œ ì¹œì ˆí•˜ê²Œ ì •ë‹µì„ ë¨¼ì € ì•Œë ¤ì£¼ê±°ë‚˜ íŒíŠ¸ë¥¼ ì£¼ì§€ ë§ˆì‹­ì‹œì˜¤.

[Analystì˜ ë¶„ì„ ê²°ê³¼ (Attack Vector)]
{attack_vector}

[ë‹¹ì‹ ì˜ ì„ë¬´]
1. ìœ„ 'Attack Vector'ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ì›ìì—ê²Œ ë˜ì§ˆ ì²« ë²ˆì§¸ ë©´ì ‘ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì„¸ìš”.
2. ë§Œì•½ ì´ê²ƒì´ ì²« ì§ˆë¬¸ì´ ì•„ë‹ˆë¼ ì´ì–´ì§€ëŠ” ëŒ€í™”ë¼ë©´, ì§€ì›ìì˜ ë§ˆì§€ë§‰ ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ ê¼¬ë¦¬ ì§ˆë¬¸ì„ ë˜ì§€ì„¸ìš”.
3. ì§ˆë¬¸ì€ ê°„ê²°í•˜ê³  ëª…í™•í•´ì•¼ í•˜ë©°, í•œ ë²ˆì— ì—¬ëŸ¬ ê°œì˜ ì§ˆë¬¸ì„ ë˜ì§€ì§€ ë§ˆì„¸ìš”. (ìµœëŒ€ 1~2ë¬¸ì¥)
4. ë‹¹ì‹ ì€ ë©´ì ‘ê´€ì´ë¯€ë¡œ, ë‹¹ì‹ ì˜ ë‹µë³€ì—ëŠ” 'ì§ˆë¬¸ ë‚´ìš©'ë§Œ ë“¤ì–´ê°€ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: "~~ì— ëŒ€í•´ ì„¤ëª…í•´ ë³´ì‹œê² ìŠµë‹ˆê¹Œ?", "ë°©ê¸ˆ ë§ì”€í•˜ì‹  ~~ì˜ ë‹¨ì ì€ ë¬´ì—‡ì¼ê¹Œìš”?")
5. ì¤‘ìš”: í…ìŠ¤íŠ¸ì— êµµì€ ê¸€ì”¨(**)ë‚˜ ê¸°ìš¸ì„ì²´(*) ê°™ì€ ë§ˆí¬ë‹¤ìš´(Markdown) ì„œì‹ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ ìˆœìˆ˜í•œ í…ìŠ¤íŠ¸ ë¬¸ìë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
"""

@csrf_exempt
def mock_interview_init(request):
    """
    ëª¨ì˜ ë©´ì ‘ ì‹œì‘ ì „(Pre-computation) í˜¸ì¶œë˜ëŠ” ì´ˆê¸°í™” ì—”ë“œí¬ì¸íŠ¸.
    Analyst Agentê°€ ìœ ì € ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ Attack Vectorë¥¼ ê¸°ì•ˆí•˜ê³  ì„¸ì…˜ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    if request.method == "POST":
        try:
            body = json.loads(request.body)
            job_planner_data = body.get("job_planner")
            
            # 1ë‹¨ê³„: Analyst ê°€ë™ (ê³µê²© ë²¡í„° ì¶”ì¶œ)
            # ì—¬ê¸°ì„œëŠ” ë©´ì ‘ ì‹œì‘ ì‹œì ì´ë¯€ë¡œ historyë‚˜ user_msgëŠ” ì—†ìŠµë‹ˆë‹¤.
            attack_vector = run_analyst_agent(request, job_planner_data, user_msg=None, history=None)
            
            # 2ë‹¨ê³„: ìƒì„±ëœ ì „ëµì„ ì„œë²„ ì„¸ì…˜ì— ìºì‹±
            request.session['mock_interview_attack_vector'] = attack_vector
            
            return JsonResponse({
                "status": "success", 
                "message": "Analyst initialization complete.",
                # Debug ëª©ì ìœ¼ë¡œë§Œ í”„ë¡ íŠ¸ì— ë‚´ë ¤ì£¼ê³  ì‹¤ì œ í‘œì¶œì€ ì•ˆ í•´ë„ ë¬´ë°©í•¨
                "attack_vector": attack_vector 
            })
        except Exception as e:
            return JsonResponse({"status": "error", "message": str(e)}, status=500)
            
    return JsonResponse({"status": "error", "message": "Method not allowed"}, status=405)

@csrf_exempt
def mock_interview_stream(request):
    """
    ëª¨ì˜ ë©´ì ‘ ì²« ì§„ì… ì‹œ í˜¸ì¶œë˜ëŠ” SSE ìŠ¤íŠ¸ë¦¬ë° (ì²« ì¸ì‚¬ + ì²« ì§ˆë¬¸)
    Analyst í˜¸ì¶œ ì—†ì´ ì„¸ì…˜ì— ì €ì¥ëœ attack_vectorë¥¼ ì¦‰ì‹œ í™œìš©í•˜ì—¬ Latency ìµœì†Œí™”.
    """
    job_planner_data = None
    if request.method == "POST":
        try:
            body = json.loads(request.body)
            job_planner_data = body.get("job_planner")
        except json.JSONDecodeError:
            pass

    def event_stream():
        try:
            # ì‹¤ì‹œê°„ ëŒ€í™” ë‹¨ê³„ (Low Latency)
            # ì„¸ì…˜ì—ì„œ ë¯¸ë¦¬ ê³„ì‚°ëœ ê³µê²© ë²¡í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©.
            attack_vector = request.session.get('mock_interview_attack_vector', "ì§€ì›ìì˜ ì´ë ¥ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬ ê¸°ìˆ  ì§ˆë¬¸ì„ 1ê°œ ë˜ì§€ì„¸ìš”.")
            
            # 2ë‹¨ê³„: Interviewer ê°€ë™ (ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ)
            
            # 2ë‹¨ê³„: Interviewer ê°€ë™ (ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ)
            system_prompt = get_interviewer_prompt(attack_vector)
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": "ì§€ì›ìê°€ ë©´ì ‘ì— ë°©ê¸ˆ ì…ì¥í–ˆìŠµë‹ˆë‹¤. ê³¼ì¥ëœ ì¸ì‚¬ëŠ” ìƒëµí•˜ê³  ì‹¤ì œ ë©´ì ‘ê´€ì²˜ëŸ¼ ì²« ì¸ì‚¬ë¥¼ ê±´ë„¨ ë’¤, ì£¼ì–´ì§„ ì§€ë ¹(Attack Vector)ì— ë”°ë¼ ì²« ì§ˆë¬¸ì„ ê°€ë³ê²Œ ë˜ì ¸ì£¼ì„¸ìš”."}
                ],
                stream=True,
                temperature=0.7,
            )
            
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    time.sleep(0.02)
                    char = chunk.choices[0].delta.content
                    chunk_data = json.dumps({"chunk": char, "status": "typing"}, ensure_ascii=False)
                    yield f"data: {chunk_data}\n\n"
                    
            done_data = json.dumps({"chunk": "", "status": "done"}, ensure_ascii=False)
            yield f"data: {done_data}\n\n"
            
        except Exception as e:
            error_msg = json.dumps({"chunk": f"ì˜¤ë¥˜ ë°œìƒ ê½¥! ({str(e)})", "status": "done"}, ensure_ascii=False)
            yield f"data: {error_msg}\n\n"

    response = StreamingHttpResponse(event_stream(), content_type="text/event-stream")
    response['Cache-Control'] = 'no-cache'
    response['X-Accel-Buffering'] = 'no'
    return response

@csrf_exempt
def mock_interview_reply(request):
    """
    ìœ ì €ê°€ ì±„íŒ…(ë‹µë³€) ì…ë ¥ ì‹œ í˜¸ì¶œë˜ì–´ SSEë¡œ ê¼¬ë¦¬ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    """
    history = []
    user_msg = ""
    job_planner_data = None
    
    if request.method == "POST":
        try:
            body = json.loads(request.body)
            history = body.get("history", [])
            job_planner_data = body.get("job_planner")
            if history and history[-1].get("role") == "user":
                user_msg = history[-1].get("content")
        except json.JSONDecodeError:
            pass
    else:
        user_msg = request.GET.get('msg', '')
        if user_msg:
            history.append({"role": "user", "content": user_msg})
    
    def event_stream():
        if not user_msg and not history:
            yield f"data: {json.dumps({'chunk': 'ë§ì”€í•˜ì‹  ë‚´ìš©ì„ ì˜ ë“£ì§€ ëª»í–ˆì–´ìš” ê½¥!', 'status': 'done'}, ensure_ascii=False)}\n\n"
            return
            
        try:
            # ì‹¤ì‹œê°„ ëŒ€í™” ë‹¨ê³„ (Low Latency)
            # ë§¤ í„´ë§ˆë‹¤ Analystë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê³ , ê¸°ì¡´ì— ì„¤ì •ëœ ê³µê²© ê¸°ì¡°ë¥¼ ì¬í™œìš©í•©ë‹ˆë‹¤.
            attack_vector = request.session.get('mock_interview_attack_vector', "ì§€ì›ìì˜ ì´ë ¥ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬ ê¸°ìˆ  ì§ˆë¬¸ì„ 1ê°œ ë˜ì§€ì„¸ìš”.")
            
            # 2ë‹¨ê³„: Interviewer ê°€ë™ (ê³µê²© ë²¡í„°ì— ê¸°ë°˜í•œ ìŠ¤íŠ¸ë¦¬ë° ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„±)
            system_prompt = get_interviewer_prompt(attack_vector)
            
            messages = [{"role": "system", "content": system_prompt}]
            messages.extend(history)
            
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                stream=True,
                temperature=0.7,
            )
            
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    time.sleep(0.02)
                    char = chunk.choices[0].delta.content
                    chunk_data = json.dumps({"chunk": char, "status": "typing"}, ensure_ascii=False)
                    yield f"data: {chunk_data}\n\n"
                    
            done_data = json.dumps({"chunk": "", "status": "done"}, ensure_ascii=False)
            yield f"data: {done_data}\n\n"
            
        except Exception as e:
            error_msg = json.dumps({"chunk": f"ì˜¤ë¥˜ ë°œìƒ ê½¥! ({str(e)})", "status": "done"}, ensure_ascii=False)
            yield f"data: {error_msg}\n\n"

    response = StreamingHttpResponse(event_stream(), content_type="text/event-stream")
    response['Cache-Control'] = 'no-cache'
    response['X-Accel-Buffering'] = 'no'
    return response
