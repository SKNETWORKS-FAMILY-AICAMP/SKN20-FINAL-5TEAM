"""
ì‘ì„±ì¼: 2026-02-21
ìˆ˜ì •ì¼: 2026-02-22
ìˆ˜ì •ì: ìˆ˜ì„ ì—ì´ì „íŠ¸
ì‘ì„±ë‚´ìš©: 
- AI-GYM í”„ë¡œì íŠ¸ì˜ ëª¨ì˜ ë©´ì ‘ ì‹œìŠ¤í…œ ë°±ì—”ë“œ API
- [ìˆ˜ì •ë‚´ìš©] Multi-Agent ì•„í‚¤í…ì²˜ ë„ì… (Analyst + Interviewer)
- 1ë‹¨ê³„: Analystê°€ ìœ ì € ë°ì´í„°(Job Planner + Code + History)ë¥¼ ë¶„ì„í•´ ê³µê²© ë²¡í„°(Attack Vector) ë„ì¶œ
- 2ë‹¨ê³„: Interviewer(ë„ë•)ê°€ ê³µê²© ë²¡í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„±
"""
import time
import json
import os
from django.http import StreamingHttpResponse
from django.views.decorators.csrf import csrf_exempt
from openai import OpenAI
from django.conf import settings

from core.models.user_model import UserProfile
from core.models.activity_model import UserSolvedProblem

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# ==========================================
# 1. Analyst Agent (ë¶„ì„ê°€ í˜ë¥´ì†Œë‚˜)
# ==========================================
def run_analyst_agent(request, job_planner_data=None, user_msg=None, history=None):
    """
    ìœ ì € ëˆˆì— ë³´ì´ì§€ ì•ŠëŠ” ë°±ê·¸ë¼ìš´ë“œ AI (Analyst)
    ìœ ì €ì˜ ê³¼ê±° ì½”ë“œ ì´ë ¥, ì§€ì› íšŒì‚¬ ì •ë³´, í˜„ì¬ ëŒ€í™” ë§¥ë½ì„ ë¶„ì„í•˜ì—¬
    'ë„ë•(ë©´ì ‘ê´€)'ì´ ê³µê²©í•´ì•¼ í•  ë‹¨ 1ê°œì˜ í•µì‹¬ ì•½ì (Attack Vector)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    context_str = ""
    job_str = ""

    # 1) ì§€ì› íšŒì‚¬ ì •ë³´ ì¶”ì¶œ
    if job_planner_data:
        job_data = job_planner_data.get('jobData', {})
        if job_data:
            company_name = job_data.get('company_name', 'íŠ¹ì • íšŒì‚¬')
            position_name = job_data.get('position', 'íŠ¹ì • ì§ë¬´')
            req_skills = job_data.get('required_skills', [])
            skills_str = ', '.join(req_skills) if req_skills else 'ê´€ë ¨ ê¸°ìˆ '
            
            job_str = f"[ì§€ì› íšŒì‚¬: {company_name}] | [í¬ì§€ì…˜: {position_name}] | [ìš”êµ¬ ê¸°ìˆ : {skills_str}]\n"

    # 2) ê³¼ê±° ì½”ë“œ ì´ë ¥ ì¶”ì¶œ
    user = request.user if request.user.is_authenticated else None
    if user:
        try:
            recent_solved = UserSolvedProblem.objects.filter(
                user=user
            ).select_related('practice_detail', 'practice_detail__practice').order_by('-solved_date')[:5]
            
            if recent_solved.exists():
                for sp in recent_solved:
                    unit_name = sp.practice_detail.practice.title if sp.practice_detail and sp.practice_detail.practice else "ë¯¸ìƒ"
                    score = sp.score
                    code_snippet = ""
                    if sp.submitted_data and isinstance(sp.submitted_data, dict):
                        code_snippet = str(sp.submitted_data.get('code', ''))[:200]
                    context_str += f"- ìœ ë‹›: {unit_name}, ì ìˆ˜: {score}ì , ì½”ë“œ ìš”ì•½: {code_snippet}...\n"
        except Exception as e:
            print(f"Failed to fetch user context for Analyst: {e}")
            pass

    # 3) íˆìŠ¤í† ë¦¬ ìš”ì•½
    history_str = ""
    if history:
        # ìµœê·¼ 3~4ê°œì˜ ëŒ€í™”ë§Œ ë¶„ì„ì— í™œìš©
        recent_history = history[-4:]
        for h in recent_history:
            role = 'ë©´ì ‘ê´€' if h['role'] == 'assistant' else 'ì§€ì›ì'
            history_str += f"{role}: {h['content']}\n"
    if user_msg:
        history_str += f"ì§€ì›ì(í˜„ì¬ë‹µë³€): {user_msg}\n"

    analyst_prompt = f"""ë‹¹ì‹ ì€ AI-GYMì˜ ì‹¬ì¸µ ë©´ì ‘ ë¶„ì„ê°€(Analyst)ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì•„ë˜ ì œê³µëœ ë°ì´í„°ë“¤ì„ ë¶„ì„í•˜ì—¬, ìµœì¢… ë©´ì ‘ê´€(ë„ë•)ì´ ì§€ì›ìì—ê²Œ ë˜ì ¸ì•¼ í•  **ë‹¨ 1ê°œì˜ ê°€ì¥ ë‚ ì¹´ë¡­ê³  ì˜ˆë¦¬í•œ ì§ˆë¬¸ ë°©í–¥(Attack Vector)**ì„ ì„¤ê³„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

[ë°ì´í„°]
1. ì§€ì› íšŒì‚¬ ì •ë³´: {job_str if job_str else "ì—†ìŒ (ì¼ë°˜ CS ë©´ì ‘ìœ¼ë¡œ ì§„í–‰)"}
2. ì§€ì›ìì˜ ê³¼ê±° ì½”ë“œ(Python) ì´ë ¥:
{context_str if context_str else "ê³¼ê±° ì½”ë“œ ì •ë³´ ì—†ìŒ"}
3. ìµœê·¼ ë©´ì ‘ ëŒ€í™” íë¦„:
{history_str if history_str else "ë©´ì ‘ ì‹œì‘ ì „ì…ë‹ˆë‹¤."}

[ë¶„ì„ ê·œì¹™]
1. ë‹¨ìˆœí•œ ì§€ì‹ í™•ì¸ì„ ë„˜ì–´ì„œ, 'ì§€ì› íšŒì‚¬ì˜ ìš”êµ¬ ê¸°ìˆ 'ê³¼ 'ì§€ì›ìì˜ ì½”ë“œ ì•½ì ' ë˜ëŠ” 'í˜„ì¬ ë‹µë³€ì˜ í—ˆì 'ì„ êµë¬˜í•˜ê²Œ ì—®ìœ¼ì„¸ìš”.
2. ì˜ˆì‹œ: íšŒì‚¬ê°€ í”„ë¡ íŠ¸ì—”ë“œ(React)ë¥¼ ìš”êµ¬í•˜ëŠ”ë° ì§€ì›ì ì½”ë“œê°€ íŒŒì´ì¬ ê¸°ì´ˆì¸ ê²½ìš° -> íŒŒì´ì¬ì„ ì–µì§€ë¡œ ë¬»ì§€ ë§ê³ , "ê³¼ê±° ì½”ë“œì—ì„œ ìƒíƒœ ê´€ë¦¬ê°€ ë¯¸í¡í–ˆëŠ”ë°, ì´ë¥¼ í”„ë¡ íŠ¸ì—”ë“œì˜ React ì»´í¬ë„ŒíŠ¸ í™˜ê²½ì—ì„œëŠ” ì–´ë–»ê²Œ ì•ˆì •ì ìœ¼ë¡œ ì„¤ê³„í•  ê±´ê°€?" ì‹ìœ¼ë¡œ ì¹˜í™˜í•´ì„œ ê³µê²©í•˜ì„¸ìš”.
3. ì§€ì›ìê°€ ì˜¤ë‹µì„ ëƒˆê±°ë‚˜ ëŒ€ë‹µì´ ë¹ˆì•½í•˜ë©´ ì§‘ìš”í•˜ê²Œ íŒŒê³ ë“œëŠ” ë°©í–¥ì„ ì œì‹œí•˜ì„¸ìš”.
4. ì˜ˆì˜ë¥¼ ì°¨ë¦´ í•„ìš” ì—†ìŠµë‹ˆë‹¤. ì˜¤ì§ ë‚ ì¹´ë¡œìš´ ë‹¨ 1ê°œì˜ ê³µê²© í¬ì¸íŠ¸ë§Œ ì„œìˆ í•˜ì„¸ìš”.
5. ë°˜ë“œì‹œ JSON í¬ë§·ìœ¼ë¡œ "attack_vector" í‚¤ í•˜ë‚˜ë§Œ í¬í•¨í•˜ì—¬ ë°˜í™˜í•˜ì„¸ìš”.

ì¶œë ¥ ì˜ˆì‹œ:
{{
  "attack_vector": "ì§€ì›ìëŠ” ì§ì „ ë‹µë³€ì—ì„œ ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ë‘ë£¨ë­‰ìˆ í•˜ê²Œ ì–¼ë²„ë¬´ë ¸ìŒ. ê³¼ê±° íŒŒì´ì¬ ì½”ë“œì—ì„œë„ ì˜ˆì™¸ ì²˜ë¦¬ê°€ ì „í˜€ ì•ˆ ë˜ì–´ ìˆì—ˆìŒì„ ì§€ì í•˜ê³ , ì§€ì›í•˜ëŠ” AíšŒì‚¬ì˜ ëŒ€ê·œëª¨ íŠ¸ë˜í”½ í™˜ê²½ì—ì„œ ì—ëŸ¬ í—¨ë“¤ë§ì´ ëˆ„ë½ë˜ì—ˆì„ ë•Œì˜ ì¹˜ëª…ì ì¸ ì‚¬ì´ë“œ ì´í™íŠ¸ë¥¼ ë¬»ëŠ” ì••ë°• ì§ˆë¬¸ì„ ë˜ì§€ì‹œì˜¤."
}}
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": analyst_prompt}],
            response_format={ "type": "json_object" },
            temperature=0.7,
        )
        result = json.loads(response.choices[0].message.content)
        attack_vector = result.get("attack_vector", "ì§€ì›ìì˜ ì´ë ¥ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬ ê¸°ìˆ  ì§ˆë¬¸ì„ 1ê°œ ë˜ì§€ì„¸ìš”.")
        print(f"\nğŸ•µï¸ [Analyst] ì¶”ì¶œëœ ê³µê²© ë²¡í„°:\n{attack_vector}\n")
        return attack_vector
    except Exception as e:
        print(f"Analyst Error: {e}")
        return "ì§€ì›ìì˜ ëŒ€ë‹µì„ ë°”íƒ•ìœ¼ë¡œ ê¼¬ë¦¬ ì§ˆë¬¸ì„ ë˜ì§€ì„¸ìš”."


# ==========================================
# 2. Interviewer Agent (ë©´ì ‘ê´€ í˜ë¥´ì†Œë‚˜ - ìŠ¤íŠ¸ë¦¬ë°)
# ==========================================
def get_interviewer_prompt(attack_vector):
    """
    ìµœì¢… ë©´ì ‘ê´€ 'ë„ë•'ì˜ ê¹ê¹í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸.
    Analystê°€ ë„˜ê²¨ì¤€ ì§€ë ¹(attack_vector)ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    return f"""ë‹¹ì‹ ì€ í”½ì‚¬ ê°ì„±ì˜ ì˜¤ë¦¬ ìºë¦­í„°ì´ì AI-GYMì˜ ìˆ˜ì„ ê¸°ìˆ  ë©´ì ‘ê´€ 'ë„ë•(Coduck)'ì…ë‹ˆë‹¤.
ì§„ì¤‘í•˜ê³  í”„ë¡œí˜ì…”ë„í•œ íƒœë„ë¥¼ ìœ ì§€í•˜ëŠ” ì‹œë‹ˆì–´ ë©˜í† ì…ë‹ˆë‹¤.

[ë‹¹ì‹ ì˜ ì ˆëŒ€ ê·œì¹™]
1. í•œ ë²ˆì— **ë‹¨ í•œ ê°œì˜ ì§ˆë¬¸**ë§Œ ë˜ì§€ì„¸ìš”. ì„œë¡ ì´ë‚˜ ì¹­ì°¬ì€ ì•„ì£¼ ì§§ê²Œ, í˜¹ì€ ìƒëµí•˜ì„¸ìš”.
2. ê¸°ê³„ì ì¸ AI ë§íˆ¬ë‚˜ ì´ëª¨ì§€ ë‚¨ë°œì€ ê¸ˆì§€í•©ë‹ˆë‹¤. ë‹¨, ë§íˆ¬ ëì— ì•½ê°„ì˜ ì˜¤ë¦¬ ìºë¦­í„°ì„±(ê¹ê¹í•¨)ì´ ë¬»ì–´ë‚˜ë„ ì¢‹ìŠµë‹ˆë‹¤.
3. ë§ˆí¬ë‹¤ìš´ì„ ì ì ˆíˆ í™œìš©í•˜ì—¬ í•µì‹¬ ê¸°ìˆ ëª…ì´ë‚˜ ë³€ìˆ˜ëª…ì€ ê°•ì¡°í•˜ì„¸ìš”.

[ì´ë²ˆ í„´ì˜ í•µì‹¬ ì§€ë ¹ (Attack Vector)]
ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ê°€ê°€ ë‹¹ì‹ ì—ê²Œ ë‹¤ìŒ ë°©í–¥ìœ¼ë¡œ ì§ˆë¬¸í•  ê²ƒì„ ì§€ì‹œí–ˆìŠµë‹ˆë‹¤:
"{attack_vector}"

ì´ ì§€ë ¹ì„ ì™„ë²½í•˜ê²Œ ìˆ™ì§€í•˜ê³ , ì§€ì›ìì—ê²Œ ë‚ ì¹´ë¡­ê³  ì§ê´€ì ì¸ ì§ˆë¬¸ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë±‰ìœ¼ì„¸ìš”.
"""

@csrf_exempt
def mock_interview_stream(request):
    """
    ëª¨ì˜ ë©´ì ‘ ì²« ì§„ì… ì‹œ í˜¸ì¶œë˜ëŠ” SSE ìŠ¤íŠ¸ë¦¬ë° (ì²« ì¸ì‚¬ + ì²« ì§ˆë¬¸)
    """
    job_planner_data = None
    if request.method == "POST":
        try:
            body = json.loads(request.body)
            job_planner_data = body.get("job_planner")
        except json.JSONDecodeError:
            pass

    def event_stream():
        try:
            # 1ë‹¨ê³„: Analyst ê°€ë™ (ê³µê²© ë²¡í„° ì¶”ì¶œ)
            attack_vector = run_analyst_agent(request, job_planner_data, user_msg=None, history=None)
            
            # 2ë‹¨ê³„: Interviewer ê°€ë™ (ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ)
            system_prompt = get_interviewer_prompt(attack_vector)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": "ì§€ì›ìê°€ ë©´ì ‘ì— ë°©ê¸ˆ ì…ì¥í–ˆìŠµë‹ˆë‹¤. ê³¼ì¥ëœ ì¸ì‚¬ëŠ” ìƒëµí•˜ê³  ì‹¤ì œ ë©´ì ‘ê´€ì²˜ëŸ¼ ì²« ì¸ì‚¬ë¥¼ ê±´ë„¨ ë’¤, ì£¼ì–´ì§„ ì§€ë ¹(Attack Vector)ì— ë”°ë¼ ì²« ì§ˆë¬¸ì„ ê°€ë³ê²Œ ë˜ì ¸ì£¼ì„¸ìš”."}
                ],
                stream=True,
                temperature=0.7,
            )
            
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    time.sleep(0.02)
                    char = chunk.choices[0].delta.content
                    chunk_data = json.dumps({"chunk": char, "status": "typing"}, ensure_ascii=False)
                    yield f"data: {chunk_data}\n\n"
                    
            done_data = json.dumps({"chunk": "", "status": "done"}, ensure_ascii=False)
            yield f"data: {done_data}\n\n"
            
        except Exception as e:
            error_msg = json.dumps({"chunk": f"ì˜¤ë¥˜ ë°œìƒ ê½¥! ({str(e)})", "status": "done"}, ensure_ascii=False)
            yield f"data: {error_msg}\n\n"

    response = StreamingHttpResponse(event_stream(), content_type="text/event-stream")
    response['Cache-Control'] = 'no-cache'
    response['X-Accel-Buffering'] = 'no'
    return response

@csrf_exempt
def mock_interview_reply(request):
    """
    ìœ ì €ê°€ ì±„íŒ…(ë‹µë³€) ì…ë ¥ ì‹œ í˜¸ì¶œë˜ì–´ SSEë¡œ ê¼¬ë¦¬ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    """
    history = []
    user_msg = ""
    job_planner_data = None
    
    if request.method == "POST":
        try:
            body = json.loads(request.body)
            history = body.get("history", [])
            job_planner_data = body.get("job_planner")
            if history and history[-1].get("role") == "user":
                user_msg = history[-1].get("content")
        except json.JSONDecodeError:
            pass
    else:
        user_msg = request.GET.get('msg', '')
        if user_msg:
            history.append({"role": "user", "content": user_msg})
    
    def event_stream():
        if not user_msg and not history:
            yield f"data: {json.dumps({'chunk': 'ë§ì”€í•˜ì‹  ë‚´ìš©ì„ ì˜ ë“£ì§€ ëª»í–ˆì–´ìš” ê½¥!', 'status': 'done'}, ensure_ascii=False)}\n\n"
            return
            
        try:
            # 1ë‹¨ê³„: Analyst ê°€ë™ (ìœ ì € ë‹µë³€ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ê³µê²© ë²¡í„° ì¶”ì¶œ)
            attack_vector = run_analyst_agent(request, job_planner_data, user_msg=user_msg, history=history)
            
            # 2ë‹¨ê³„: Interviewer ê°€ë™ (ê³µê²© ë²¡í„°ì— ê¸°ë°˜í•œ ìŠ¤íŠ¸ë¦¬ë° ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„±)
            system_prompt = get_interviewer_prompt(attack_vector)
            
            messages = [{"role": "system", "content": system_prompt}]
            messages.extend(history)
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                stream=True,
                temperature=0.7,
            )
            
            for chunk in response:
                if chunk.choices[0].delta.content is not None:
                    time.sleep(0.02)
                    char = chunk.choices[0].delta.content
                    chunk_data = json.dumps({"chunk": char, "status": "typing"}, ensure_ascii=False)
                    yield f"data: {chunk_data}\n\n"
                    
            done_data = json.dumps({"chunk": "", "status": "done"}, ensure_ascii=False)
            yield f"data: {done_data}\n\n"
            
        except Exception as e:
            error_msg = json.dumps({"chunk": f"ì˜¤ë¥˜ ë°œìƒ ê½¥! ({str(e)})", "status": "done"}, ensure_ascii=False)
            yield f"data: {error_msg}\n\n"

    response = StreamingHttpResponse(event_stream(), content_type="text/event-stream")
    response['Cache-Control'] = 'no-cache'
    response['X-Accel-Buffering'] = 'no'
    return response
