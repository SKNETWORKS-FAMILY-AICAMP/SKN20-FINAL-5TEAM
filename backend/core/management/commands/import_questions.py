# ìƒì„±ì¼: 2026-02-28
# ì„¤ëª…: interview_questions_v3.json â†’ DB ì¼ê´„ ì„í¬íŠ¸ ì»¤ë§¨ë“œ
#
# ì‚¬ìš©ë²•:
#   python manage.py import_questions data/interview_questions_v3.json
#   python manage.py import_questions data/interview_questions_v3.json --clear  # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì„í¬íŠ¸
#   python manage.py import_questions data/interview_questions_v3.json --dry-run # ë¯¸ë¦¬ë³´ê¸°ë§Œ

import json
import time
from django.core.management.base import BaseCommand
from core.models import InterviewQuestion


class Command(BaseCommand):
    help = 'interview_questions_v3.json íŒŒì¼ì„ DBì— ì„í¬íŠ¸í•©ë‹ˆë‹¤'

    def add_arguments(self, parser):
        parser.add_argument('json_file', type=str, help='v3.json íŒŒì¼ ê²½ë¡œ')
        parser.add_argument('--clear', action='store_true', help='ê¸°ì¡´ ë°ì´í„° ì „ì²´ ì‚­ì œ í›„ ì„í¬íŠ¸')
        parser.add_argument('--dry-run', action='store_true', help='ì‹¤ì œ ì €ì¥í•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ')
        parser.add_argument('--batch-size', type=int, default=1000, help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 1000)')

    def handle(self, *args, **options):
        json_file = options['json_file']
        clear = options['clear']
        dry_run = options['dry_run']
        batch_size = options['batch_size']

        # 1. JSON ë¡œë“œ
        self.stdout.write(f'ğŸ“‚ íŒŒì¼ ë¡œë“œ: {json_file}')
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        questions = data.get('questions', [])
        metadata = data.get('metadata', {})
        self.stdout.write(f'  ì´ ì§ˆë¬¸: {len(questions)}ê±´')
        self.stdout.write(f'  ë²„ì „: {metadata.get("version", "?")}')
        self.stdout.write(f'  ì†ŒìŠ¤: {metadata.get("source", "?")}')

        if dry_run:
            self.stdout.write(self.style.WARNING('\nğŸ” DRY RUN ëª¨ë“œ - ì‹¤ì œ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤'))
            self._print_stats(questions)
            return

        # 2. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
        if clear:
            count = InterviewQuestion.objects.count()
            InterviewQuestion.objects.all().delete()
            self.stdout.write(self.style.WARNING(f'\nğŸ—‘ï¸  ê¸°ì¡´ ë°ì´í„° {count}ê±´ ì‚­ì œ'))

        # 3. ë°°ì¹˜ ì„í¬íŠ¸
        self.stdout.write(f'\nğŸ“¥ ì„í¬íŠ¸ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {batch_size})')
        start = time.time()

        objects = []
        skipped = 0

        for q in questions:
            text = q.get('question_text', '').strip()
            if not text or len(text) < 5:
                skipped += 1
                continue

            # source í•„ë“œ ì •ê·œí™”: github_xxx â†’ github
            source_raw = q.get('source', '')
            if source_raw.startswith('github'):
                source_normalized = 'github'
            elif source_raw.startswith('youtube'):
                source_normalized = 'youtube'
            else:
                source_normalized = source_raw

            objects.append(InterviewQuestion(
                question_text=text,
                slot_type=q.get('slot_type', 'general'),
                company=q.get('company', ''),
                job=q.get('job', ''),
                category=q.get('category', ''),
                source=source_normalized,
                language=q.get('language', 'ko'),
                region=q.get('region', 'korea'),
                answer_text=q.get('answer_text', ''),
                answer_summary=q.get('answer_summary', ''),
                period=q.get('period', ''),
                employment_type=q.get('employment_type', ''),
                interview_type=q.get('interview_type', ''),
                is_it_job=q.get('is_it_job'),
                c_idx=q.get('c_idx'),
                difficulty=q.get('difficulty', ''),
                keywords=q.get('keywords', []),
                create_id='system',
                update_id='system',
            ))

        # bulk_createë¡œ ë°°ì¹˜ ì‚½ì…
        created = 0
        for i in range(0, len(objects), batch_size):
            batch = objects[i:i + batch_size]
            InterviewQuestion.objects.bulk_create(batch, batch_size=batch_size)
            created += len(batch)
            self.stdout.write(f'  âœ… {created}/{len(objects)}ê±´ ì™„ë£Œ')

        elapsed = time.time() - start

        self.stdout.write(self.style.SUCCESS(
            f'\nğŸ‰ ì„í¬íŠ¸ ì™„ë£Œ!'
            f'\n  ì €ì¥: {created}ê±´'
            f'\n  ê±´ë„ˆëœ€: {skipped}ê±´'
            f'\n  ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ'
            f'\n  DB ì´ ê±´ìˆ˜: {InterviewQuestion.objects.count()}ê±´'
        ))

    def _print_stats(self, questions):
        """ë¯¸ë¦¬ë³´ê¸° í†µê³„"""
        from collections import Counter

        slots = Counter(q.get('slot_type', '') for q in questions)
        sources = Counter()
        for q in questions:
            s = q.get('source', '')
            sources['github' if s.startswith('github') else s] += 1
        companies = Counter(q.get('company', '') for q in questions if q.get('company'))

        self.stdout.write(f'\nğŸ“Š í†µê³„:')
        self.stdout.write(f'\n  ìŠ¬ë¡¯ë³„:')
        for s, n in slots.most_common():
            self.stdout.write(f'    {s:<18} {n:>6}ê±´')
        self.stdout.write(f'\n  ì†ŒìŠ¤ë³„:')
        for s, n in sources.most_common():
            self.stdout.write(f'    {s:<18} {n:>6}ê±´')
        self.stdout.write(f'\n  ê¸°ì—… ìˆ˜: {len(companies)}ê°œ')
        self.stdout.write(f'\n  ê¸°ì—… TOP 10:')
        for c, n in companies.most_common(10):
            self.stdout.write(f'    {c:<25} {n:>4}ê±´')
